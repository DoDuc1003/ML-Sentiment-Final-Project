{"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"063bab06d1394e289d1a5300f3048d2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0799c717625c4587bf2fd918c8b07dd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c681e9e6aa4469a87a16c14168421c9","placeholder":"​","style":"IPY_MODEL_7fc542de9a9f4268a065d6adf96cb927","value":" 1.14M/1.14M [00:00&lt;00:00, 3.34MB/s]"}},"0c5886c49a114b86b9fbc3345503cff6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c55e536b868141ba8163a101a61d320e","max":557,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40cf64a08a6f48249094e3f7e9b73f18","value":557}},"0d1083f2e8974da1a976808907d0aa4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17113c3846ff4e3c84aea7ccf21ab2fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"177f6e69839f4238a6418c5247367129":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2097eca8a6604d108e03528244efadac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"287a91fc255f4de5a7de1d27dcfce619":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab52c6fccb0e48049c256b7467f2604a","placeholder":"​","style":"IPY_MODEL_938cf653cb9044e191dfb0904135c75a","value":" 557/557 [00:00&lt;00:00, 5.09kB/s]"}},"39ec0e1c6f0f40fa906135f4e387abaf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40cf64a08a6f48249094e3f7e9b73f18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45f1b0212e954b17ad45bd644f2156d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e687c5c54d324dd987c1a92be85ff1e6","placeholder":"​","style":"IPY_MODEL_2097eca8a6604d108e03528244efadac","value":"Downloading: 100%"}},"4c681e9e6aa4469a87a16c14168421c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f02e8c1b65b4385a13c73a993fe2524":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5751619e4df4e0ea474b2ea5a745c32","placeholder":"​","style":"IPY_MODEL_a84de470cfa44f9896cd7572bcb4dd94","value":"Downloading: 100%"}},"609a6a6f6ee04bd78a5c8712b348e585":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb81204063004497a7c3268253418592","IPY_MODEL_cd1089d6426c4f3abdd0c8c4690b9bb9","IPY_MODEL_96fb2603b9064763922efa4ee29bbbb4"],"layout":"IPY_MODEL_e44370231ea5471f8c2dc5ecabc95a95"}},"66a4baa794ce43de807650851ab0bb21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45f1b0212e954b17ad45bd644f2156d4","IPY_MODEL_0c5886c49a114b86b9fbc3345503cff6","IPY_MODEL_287a91fc255f4de5a7de1d27dcfce619"],"layout":"IPY_MODEL_ed27683d14034cc1aac02143a2183101"}},"73f44d88a54a48738ae8aac670fa4b43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7130a6ea9434b2ea816a65277f494e3","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d62182b941e646d89407282009108d95","value":1135173}},"7fc542de9a9f4268a065d6adf96cb927":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c9711a1696c4c1ea2e4f2f9738154dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"938cf653cb9044e191dfb0904135c75a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96fb2603b9064763922efa4ee29bbbb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_063bab06d1394e289d1a5300f3048d2e","placeholder":"​","style":"IPY_MODEL_0d1083f2e8974da1a976808907d0aa4a","value":" 543M/543M [00:11&lt;00:00, 51.8MB/s]"}},"982977287755416db422bd4cd0310b33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2d19092a3804a228d6a1dabde7f6fdd","IPY_MODEL_73f44d88a54a48738ae8aac670fa4b43","IPY_MODEL_0799c717625c4587bf2fd918c8b07dd0"],"layout":"IPY_MODEL_a887ad0607f54f4eb91da36ba8005b53"}},"983e1e7ae73948b6ab8ae4bff150f8ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1797f7fddde43b197b066e16ef80529":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f038db81cac24512b447785c4328fb6b","placeholder":"​","style":"IPY_MODEL_8c9711a1696c4c1ea2e4f2f9738154dc","value":" 895k/895k [00:00&lt;00:00, 5.02MB/s]"}},"a723b5e5b4a54881aa53eefe4d4299d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a84de470cfa44f9896cd7572bcb4dd94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a87986eb716c4b0fb25943399597fabf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a887ad0607f54f4eb91da36ba8005b53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab52c6fccb0e48049c256b7467f2604a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab717eb1ac974d57aed09303ba1c43c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae31045b39bd4677b2c8b14a004c51f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c55e536b868141ba8163a101a61d320e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5751619e4df4e0ea474b2ea5a745c32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb81204063004497a7c3268253418592":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae31045b39bd4677b2c8b14a004c51f0","placeholder":"​","style":"IPY_MODEL_ab717eb1ac974d57aed09303ba1c43c1","value":"Downloading: 100%"}},"cd1089d6426c4f3abdd0c8c4690b9bb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17113c3846ff4e3c84aea7ccf21ab2fb","max":542923308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_177f6e69839f4238a6418c5247367129","value":542923308}},"d2d19092a3804a228d6a1dabde7f6fdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a87986eb716c4b0fb25943399597fabf","placeholder":"​","style":"IPY_MODEL_a723b5e5b4a54881aa53eefe4d4299d1","value":"Downloading: 100%"}},"d62182b941e646d89407282009108d95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7130a6ea9434b2ea816a65277f494e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e44370231ea5471f8c2dc5ecabc95a95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e687c5c54d324dd987c1a92be85ff1e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed27683d14034cc1aac02143a2183101":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f038db81cac24512b447785c4328fb6b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f548078d7dc14acab9d98e41d3f635a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f02e8c1b65b4385a13c73a993fe2524","IPY_MODEL_f91ca80574eb4851bac2ad7f327f777e","IPY_MODEL_a1797f7fddde43b197b066e16ef80529"],"layout":"IPY_MODEL_983e1e7ae73948b6ab8ae4bff150f8ac"}},"f61889b098bc46f3a70a30707f5391c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f91ca80574eb4851bac2ad7f327f777e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39ec0e1c6f0f40fa906135f4e387abaf","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f61889b098bc46f3a70a30707f5391c2","value":895321}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brOS-cI4MJxP","outputId":"488bf825-1321-49dc-e5ca-c212dc9bae4c","execution":{"iopub.status.busy":"2022-12-13T11:51:12.661187Z","iopub.execute_input":"2022-12-13T11:51:12.661550Z","iopub.status.idle":"2022-12-13T11:51:21.958124Z","shell.execute_reply.started":"2022-12-13T11:51:12.661516Z","shell.execute_reply":"2022-12-13T11:51:21.956877Z"},"trusted":true},"execution_count":213,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pip install py_vncorenlp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxQeyBshQrDe","outputId":"0572f695-6702-4a7a-9542-418249319529","execution":{"iopub.status.busy":"2022-12-13T11:51:21.960933Z","iopub.execute_input":"2022-12-13T11:51:21.961340Z","iopub.status.idle":"2022-12-13T11:51:31.276586Z","shell.execute_reply.started":"2022-12-13T11:51:21.961300Z","shell.execute_reply":"2022-12-13T11:51:31.274911Z"},"trusted":true},"execution_count":214,"outputs":[{"name":"stdout","text":"Requirement already satisfied: py_vncorenlp in /opt/conda/lib/python3.7/site-packages (0.1.3)\nRequirement already satisfied: pyjnius in /opt/conda/lib/python3.7/site-packages (from py_vncorenlp) (1.4.2)\nRequirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from pyjnius->py_vncorenlp) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import logging\nlogging.set_verbosity_error()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:51:31.278419Z","iopub.execute_input":"2022-12-13T11:51:31.279152Z","iopub.status.idle":"2022-12-13T11:51:31.286955Z","shell.execute_reply.started":"2022-12-13T11:51:31.279110Z","shell.execute_reply":"2022-12-13T11:51:31.285420Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"/kaggle/input/train-format/trainformat.csv\")\nprint(data['Comment'][0:10])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rloT7v68ti-V","outputId":"09a4162b-8274-4bf4-9f81-b3cfb8436df2","execution":{"iopub.status.busy":"2022-12-13T11:51:31.290410Z","iopub.execute_input":"2022-12-13T11:51:31.290880Z","iopub.status.idle":"2022-12-13T11:51:31.453831Z","shell.execute_reply.started":"2022-12-13T11:51:31.290842Z","shell.execute_reply":"2022-12-13T11:51:31.452861Z"},"trusted":true},"execution_count":216,"outputs":[{"name":"stdout","text":"0    Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trô...\n1    Gọi ship 1 xuất cari gà bánh naan và 3 miếng g...\n2    Thời tiết lạnh như này, cả nhà rủ nhau đến leg...\n3    Em có đọc review thấy mng bảo trà sữa nướng đề...\n4    Đồ ăn rất ngon, nhà hàng cũng rất đẹp, tất cả ...\n5    Đồ ăn ngon, đặt qua now shop để k cẩn thận bị ...\n6    Nhà hàng yêu thích của mình đây nè! Đến đây mì...\n7    🔸Vị trí: mặt đường Trung Yên rất dễ tìm, một d...\n8    Mình đã ăn tại đây và rất ngon,\\r\\nChuẩn vị ph...\n9    Thịt mềm, sốt ngon, dưa góp ăn cùng đỡ ngán\\r\\...\nName: Comment, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"crawled_data = pd.read_csv(\"/kaggle/input/test-crawl/crawler_1567_comments.csv\")\nprint(crawled_data['Comment'][0:10])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:51:31.455059Z","iopub.execute_input":"2022-12-13T11:51:31.455343Z","iopub.status.idle":"2022-12-13T11:51:31.486154Z","shell.execute_reply.started":"2022-12-13T11:51:31.455316Z","shell.execute_reply":"2022-12-13T11:51:31.485116Z"},"trusted":true},"execution_count":217,"outputs":[{"name":"stdout","text":"0    Mình vừa thử trưa nay. Điểm cộng đầu tiên là b...\n1    Trà táo 35k\\nCookie socola 38k \\nNước ở đây bì...\n2    Quá trưa định đi thử Phở Thìn ở Lò Đúc cơ, như...\n3    Bình thường ko hay ăn phở Lý quốc sư đâu nhưng...\n4    Có cô quen cho văn phòng mình voucher giảm giá...\n5    Quá ngon và rẻ cho một cuộc tình chỉ 45k chỗ n...\n6    Trước ở gần nên ăn ở đây suốt. Ngay đối diện t...\n7    Trước đi qua khu BK thì thấy quán nên bọn mình...\n8    Nói chung là ngon nhưng mấy bạn đi ăn lần đầu ...\n9    Trời oi oi thèm uống Smoothie thì rẽ qua Nguyễ...\nName: Comment, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["66a4baa794ce43de807650851ab0bb21","45f1b0212e954b17ad45bd644f2156d4","0c5886c49a114b86b9fbc3345503cff6","287a91fc255f4de5a7de1d27dcfce619","ed27683d14034cc1aac02143a2183101","e687c5c54d324dd987c1a92be85ff1e6","2097eca8a6604d108e03528244efadac","c55e536b868141ba8163a101a61d320e","40cf64a08a6f48249094e3f7e9b73f18","ab52c6fccb0e48049c256b7467f2604a","938cf653cb9044e191dfb0904135c75a","f548078d7dc14acab9d98e41d3f635a8","4f02e8c1b65b4385a13c73a993fe2524","f91ca80574eb4851bac2ad7f327f777e","a1797f7fddde43b197b066e16ef80529","983e1e7ae73948b6ab8ae4bff150f8ac","c5751619e4df4e0ea474b2ea5a745c32","a84de470cfa44f9896cd7572bcb4dd94","39ec0e1c6f0f40fa906135f4e387abaf","f61889b098bc46f3a70a30707f5391c2","f038db81cac24512b447785c4328fb6b","8c9711a1696c4c1ea2e4f2f9738154dc","982977287755416db422bd4cd0310b33","d2d19092a3804a228d6a1dabde7f6fdd","73f44d88a54a48738ae8aac670fa4b43","0799c717625c4587bf2fd918c8b07dd0","a887ad0607f54f4eb91da36ba8005b53","a87986eb716c4b0fb25943399597fabf","a723b5e5b4a54881aa53eefe4d4299d1","d7130a6ea9434b2ea816a65277f494e3","d62182b941e646d89407282009108d95","4c681e9e6aa4469a87a16c14168421c9","7fc542de9a9f4268a065d6adf96cb927"]},"id":"Nat8MjW2L8ki","outputId":"d8811f44-01b2-4c22-9694-8371117d1eb2","execution":{"iopub.status.busy":"2022-12-13T11:51:31.488207Z","iopub.execute_input":"2022-12-13T11:51:31.488654Z","iopub.status.idle":"2022-12-13T11:51:34.360919Z","shell.execute_reply.started":"2022-12-13T11:51:31.488617Z","shell.execute_reply":"2022-12-13T11:51:34.359933Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"len(tokenizer.get_vocab())","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:51:34.362203Z","iopub.execute_input":"2022-12-13T11:51:34.363211Z","iopub.status.idle":"2022-12-13T11:51:34.377600Z","shell.execute_reply.started":"2022-12-13T11:51:34.363173Z","shell.execute_reply":"2022-12-13T11:51:34.376680Z"},"trusted":true},"execution_count":219,"outputs":[{"execution_count":219,"output_type":"execute_result","data":{"text/plain":"64001"},"metadata":{}}]},{"cell_type":"code","source":"corpus = []\nfor tmp in zip(data[\"Comment\"], data[\"Rating\"]):\n  sent, lb = tmp\n  label = 1\n  if lb < 6.0:\n    label = 0\n  corpus.append((str(sent), label))\n#   if(float(lb) == 1):\n#     corpus.append((sent, 1))\n#   if float(lb) == 0:\n#     corpus.append((sent, 0))\nprint(corpus[0])\nprint(len(corpus))\n\n# for tmp in zip(crawled_data[\"Comment\"], crawled_data[\"Rating\"]):\n#   sent, lb = tmp\n#   label = 1\n#   if lb < 6.0:\n#     label = 0\n#   corpus.append((str(sent), label))\n# #   if(float(lb) == 1):\n# #     corpus.append((sent, 1))\n# #   if float(lb) == 0:\n# #     corpus.append((sent, 0))\n# print(corpus[0])\n# print(len(corpus))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSXygf9yLdiL","outputId":"0aa48b93-33b6-448f-b908-74c06eaa8f59","execution":{"iopub.status.busy":"2022-12-13T11:52:22.333369Z","iopub.execute_input":"2022-12-13T11:52:22.333744Z","iopub.status.idle":"2022-12-13T11:52:22.357942Z","shell.execute_reply.started":"2022-12-13T11:52:22.333715Z","shell.execute_reply":"2022-12-13T11:52:22.356807Z"},"trusted":true},"execution_count":220,"outputs":[{"name":"stdout","text":"('Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trông rất thích', 1)\n9071\n","output_type":"stream"}]},{"cell_type":"code","source":"def segment(corpus):\n  ct = []\n  lb = []\n  for content, label in corpus:\n#     if(type(content) == str):\n      ct.append(content)\n      lb.append(label)\n  return ct, lb","metadata":{"id":"3RdqL7LGLxkq","execution":{"iopub.status.busy":"2022-12-13T11:52:24.828198Z","iopub.execute_input":"2022-12-13T11:52:24.828755Z","iopub.status.idle":"2022-12-13T11:52:24.834966Z","shell.execute_reply.started":"2022-12-13T11:52:24.828706Z","shell.execute_reply":"2022-12-13T11:52:24.833884Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"sents, labels = segment(corpus)\nprint(sents[0], \" \", labels[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dn94zZbGMk9I","outputId":"fe64cad2-f0d0-4070-82e3-71423b446000","execution":{"iopub.status.busy":"2022-12-13T11:52:26.263501Z","iopub.execute_input":"2022-12-13T11:52:26.263952Z","iopub.status.idle":"2022-12-13T11:52:26.273498Z","shell.execute_reply.started":"2022-12-13T11:52:26.263907Z","shell.execute_reply":"2022-12-13T11:52:26.272475Z"},"trusted":true},"execution_count":222,"outputs":[{"name":"stdout","text":"Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trông rất thích   1\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(sents))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VuzYD8g92CJ0","outputId":"437a60e2-e891-4a3b-9650-3a7623bc8179","execution":{"iopub.status.busy":"2022-12-13T11:52:28.741803Z","iopub.execute_input":"2022-12-13T11:52:28.742193Z","iopub.status.idle":"2022-12-13T11:52:28.749114Z","shell.execute_reply.started":"2022-12-13T11:52:28.742159Z","shell.execute_reply":"2022-12-13T11:52:28.747747Z"},"trusted":true},"execution_count":224,"outputs":[{"name":"stdout","text":"9071\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"y4VkGCJlN9lb","execution":{"iopub.status.busy":"2022-12-13T11:52:30.599689Z","iopub.execute_input":"2022-12-13T11:52:30.600288Z","iopub.status.idle":"2022-12-13T11:52:30.604925Z","shell.execute_reply.started":"2022-12-13T11:52:30.600250Z","shell.execute_reply":"2022-12-13T11:52:30.603888Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed_value):\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed_everything(86)","metadata":{"id":"iJ5dYHWFN7Mz","execution":{"iopub.status.busy":"2022-12-13T11:52:31.770302Z","iopub.execute_input":"2022-12-13T11:52:31.770650Z","iopub.status.idle":"2022-12-13T11:52:31.777034Z","shell.execute_reply.started":"2022-12-13T11:52:31.770620Z","shell.execute_reply":"2022-12-13T11:52:31.775873Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"k = 0\nfor sent in sents:\n  if(sent.find(\"bình luận không xác định\") != -1):\n    print(sent)\n    k+=1\nk","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQHimiVBQLan","outputId":"279ef0ce-5310-4fcb-bcf2-1de77b98626b","execution":{"iopub.status.busy":"2022-12-13T11:52:33.382748Z","iopub.execute_input":"2022-12-13T11:52:33.383811Z","iopub.status.idle":"2022-12-13T11:52:33.400090Z","shell.execute_reply.started":"2022-12-13T11:52:33.383771Z","shell.execute_reply":"2022-12-13T11:52:33.398984Z"},"trusted":true},"execution_count":227,"outputs":[{"execution_count":227,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"s1 = u'ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚÝàáâãèéêìíòóôõùúýĂăĐđĨĩŨũƠơƯưẠạẢảẤấẦầẨẩẪẫẬậẮắẰằẲẳẴẵẶặẸẹẺẻẼẽẾếỀềỂểỄễỆệỈỉỊịỌọỎỏỐốỒồỔổỖỗỘộỚớỜờỞởỠỡỢợỤụỦủỨứỪừỬửỮữỰựỲỳỴỵỶỷỸỹ'\ndef check_spell(string):\n  for c in string :\n    if c in s1:\n      \n      return True\n  return False\n\nchecked_sents = []\n\nfor sent in sents:\n  if(not check_spell(sent)):\n    checked_sents.append(sent)\n\nprint(len(checked_sents))","metadata":{"id":"545NfWR68QzR","execution":{"iopub.status.busy":"2022-12-13T11:52:34.632020Z","iopub.execute_input":"2022-12-13T11:52:34.632376Z","iopub.status.idle":"2022-12-13T11:52:34.646590Z","shell.execute_reply.started":"2022-12-13T11:52:34.632347Z","shell.execute_reply":"2022-12-13T11:52:34.645502Z"},"trusted":true},"execution_count":228,"outputs":[{"name":"stdout","text":"86\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(10):\n  print(i, checked_sents[i])","metadata":{"id":"twyscBxu8mcO","execution":{"iopub.status.busy":"2022-12-13T11:52:36.890089Z","iopub.execute_input":"2022-12-13T11:52:36.890447Z","iopub.status.idle":"2022-12-13T11:52:36.896835Z","shell.execute_reply.started":"2022-12-13T11:52:36.890416Z","shell.execute_reply":"2022-12-13T11:52:36.895604Z"},"trusted":true},"execution_count":229,"outputs":[{"name":"stdout","text":"0 1st time came here to try and really satisfy with the foods. Fast and nice services from staffs. \nI also love the design of the restaurant, make it so comfortable and relax for people to have meal here.\n1 I personally love indian food and Tandoor Resteraunt offers some really great indian dishes. I decided to go with Gobi Pakora for my starter which came with a mint chutney and spicy veggie chutney (I wasn't too sure what was in it) It's basically cauliflour fritters and it was quite good I can honestly say.\nFor my main I decided on Chicken Biryani which is flavored rice with spiced chicken. Awesome.\n\nHowever the lighting on the second floor was not too good but it was alright.\n2 Abc\n3 Nice place to enjoy and relax. Foods are very delicious and fresh, especially salats. I'm very impressed in cocktails. All staffs are so great and always smile. In here, i have a feeling that i am travelling in Paris. If i have chance to come back Hanoi, i sure come back Ciel ❤❤❤❤❤❤❤❤❤❤❤❤❤\n4 Very decent and nicely decorated restaurant. Service is excellence (except the billing part was slow) \nOnce the crowd come in at 8pm, the service is a little slower. \n\nFirst we order aperitif - follow by on the house appetiser which I don't really appreciate the Duck Meat with Banana. We order lamb rack for main and it was okay. However the duck breast meat - the sauce, the sides do not seems to gel with each other. \n\nDisappointed.\n5 The cafe serves food from around 10.30 to 2pm, beat to go around 11.30 when its not so busy. \nThe place is clean and nicely decorated. The selection of food is great, clearly high quality and very well prepared. \nVND30,000 for a plate of rice and your choice of four sides. \nIve been coming here for almost three years now - i used to live close by and still come back a lot. \nMinh (the owner) speaks really good English and is very friendly. Its a family run thing, and theyre all diamond people. \nAlso the drinks are noticably cheaper than in other cafes. \nHighly recommended.\n6 ⭐⭐⭐⭐⭐\n7 Finally I found an authentic Korean BBQ restaurant just right in my area. The owner is Korean. The staffs are helpful. The price is a bit high but the atmosphere, the flavor and quality of food totally deserve that. I like their pans also, which have a special surface to prevent the meat from being too greasy and burned. \nDefinitely my fave spot!\n8 ハノイ最終日の夜なので綺麗で美味しいレストランで！とコチラに。\n前回品切れしていた豚の角煮が食べれて嬉しい😆\n🎁のような盛り付けも素敵！揚げネギがたっぷりのったスティッキーライスとセットになっていてご飯と一緒に食べるとまた美味しい〜。\n前回も頼んだチキンのグリルと茄子のグリルも安定の美味しさ！茄子の味付けが以前より少し甘味が強く感じました、チキンに添えてあるココナッツ風味の揚げたbanh baoも大好き！\n今回の旅行で鍋を食べてなかったので、海鮮鍋もオーダーしました。ハーフサイズでこのボリュームです😳\n写真に写ってませんが鍋にはたっぷりのブンも付きます。ピリ辛でレモングラスが効いていたのでトムヤムクンを優しくしたような味でした。\nパスターブリューイングのクラフトビールで乾杯して、その後はボトルの白ワインをオーダーしました、\n9 Ngon\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_sents, valid_sents, train_labels, valid_labels = train_test_split(sents, labels, test_size=0.2)\nprint(len(train_sents), \" \", len(valid_sents))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bXi4oeeMzIa","outputId":"721b0269-5571-490c-87a5-5b480f4a476a","execution":{"iopub.status.busy":"2022-12-13T11:52:46.022070Z","iopub.execute_input":"2022-12-13T11:52:46.022945Z","iopub.status.idle":"2022-12-13T11:52:46.034650Z","shell.execute_reply.started":"2022-12-13T11:52:46.022905Z","shell.execute_reply":"2022-12-13T11:52:46.033532Z"},"trusted":true},"execution_count":231,"outputs":[{"name":"stdout","text":"7256   1815\n","output_type":"stream"}]},{"cell_type":"code","source":"tmp_sents = []\ntmp_labels = []\nfor tmp in zip(crawled_data[\"Comment\"], crawled_data[\"Rating\"]):\n  sent, lb = tmp\n  label = 1\n  if lb < 6.0:\n    label = 0\n  \n  tmp_sents.append(str(sent))\n  tmp_labels.append(label)\n#   if(float(lb) == 1):\n#     corpus.append((sent, 1))\n#   if float(lb) == 0:\n#     corpus.append((sent, 0))\nprint(tmp_sents[0])\nprint(len(tmp_sents))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:54:37.345430Z","iopub.execute_input":"2022-12-13T11:54:37.346033Z","iopub.status.idle":"2022-12-13T11:54:37.358688Z","shell.execute_reply.started":"2022-12-13T11:54:37.345987Z","shell.execute_reply":"2022-12-13T11:54:37.357526Z"},"trusted":true},"execution_count":232,"outputs":[{"name":"stdout","text":"Mình vừa thử trưa nay. Điểm cộng đầu tiên là bát bún đầy đặn, rất nhiều cá rán, chả cá, chả tôm. Bề bề cũng to và chắc thịt hơn các quán khác. Giá cả rất hợp lý. 40k/bát bún hải sản. Tuy nhiên nước dùng chưa đậm đà lắm. Nhưng có thể coi là tạm ổn, và gần cơ quan mình. Sẽ quay lại\n1567\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sents = train_sents + tmp_sents\ntrain_labels = train_labels + tmp_labels","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:55:14.034512Z","iopub.execute_input":"2022-12-13T11:55:14.034986Z","iopub.status.idle":"2022-12-13T11:55:14.041690Z","shell.execute_reply.started":"2022-12-13T11:55:14.034941Z","shell.execute_reply":"2022-12-13T11:55:14.040658Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"len(train_sents)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:55:33.133839Z","iopub.execute_input":"2022-12-13T11:55:33.134189Z","iopub.status.idle":"2022-12-13T11:55:33.142918Z","shell.execute_reply.started":"2022-12-13T11:55:33.134158Z","shell.execute_reply":"2022-12-13T11:55:33.141780Z"},"trusted":true},"execution_count":235,"outputs":[{"execution_count":235,"output_type":"execute_result","data":{"text/plain":"8823"},"metadata":{}}]},{"cell_type":"code","source":"sum_1 = 0\nsum_2 = 0\nfor label in train_labels:\n  if label == 0:\n    sum_1 += 1\n  else:\n    sum_2 += 1\nprint(sum_1, \" \", sum_2)\nsum_1 = 0\nsum_2 = 0\nfor label in valid_labels:\n  if label == 0:\n    sum_1 += 1\n  else:\n    sum_2 += 1\nprint(sum_1, sum_2)","metadata":{"id":"rv_KWb4F0fqC","execution":{"iopub.status.busy":"2022-12-13T11:55:35.013117Z","iopub.execute_input":"2022-12-13T11:55:35.013548Z","iopub.status.idle":"2022-12-13T11:55:35.029683Z","shell.execute_reply.started":"2022-12-13T11:55:35.013508Z","shell.execute_reply":"2022-12-13T11:55:35.028861Z"},"trusted":true},"execution_count":236,"outputs":[{"name":"stdout","text":"1890   6933\n379 1436\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_sents[0])\nprint( train_labels[0])","metadata":{"id":"xpz10lXbPLhi","execution":{"iopub.status.busy":"2022-12-13T11:55:37.035539Z","iopub.execute_input":"2022-12-13T11:55:37.036017Z","iopub.status.idle":"2022-12-13T11:55:37.045324Z","shell.execute_reply.started":"2022-12-13T11:55:37.035974Z","shell.execute_reply":"2022-12-13T11:55:37.044108Z"},"trusted":true},"execution_count":237,"outputs":[{"name":"stdout","text":"Hơi buồn một tí là tớ biết quán này lại do một anh bạn người nước ngoài giới thiệu, còn mình là người bàn xứ lại không khám phá ra :( Nhân viên ở đây vô cùng thân thiện, bắn tiếng Anh cứ phải gọi là tằng tằng luôn ấy, giới thiệu các món chuyên nghiệp thật. Mỗi tội cái là quán đông khách nên phục vụ hơi lâu tí, với vả thỉnh thoảng đến bị hết chỗ :( Foody xếp quán này là cafe nhưng thực chất là nhà hàng, mình thấy khách đến đây ăn nhiều hơn là uống. Họ phục vụ cả món Việt lẫn món Âu nhưng món Việt có vẻ ngon hơn. Bún nem ở đây được anh bạn tớ khen lắm, tại nhìn cái nem rất đẹp, vàng đều chứ không bị lem như ở nhà mình. Nhân nem cũng đậm đà, nhuyễn thịt. Nước chấm người ta pha cũng khéo nữa. Nói chung là với các bác tây không thích ăn vỉa hè thì đến đây là chuẩn rồi.\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nfrom keras_preprocessing.sequence import pad_sequences\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom gensim.utils import simple_preprocess","metadata":{"id":"IN37KRu1AX9S","execution":{"iopub.status.busy":"2022-12-13T11:55:52.543680Z","iopub.execute_input":"2022-12-13T11:55:52.544405Z","iopub.status.idle":"2022-12-13T11:55:52.549678Z","shell.execute_reply.started":"2022-12-13T11:55:52.544366Z","shell.execute_reply":"2022-12-13T11:55:52.548298Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"pip install underthesea","metadata":{"id":"TJKwk4J2ZQp2","execution":{"iopub.status.busy":"2022-12-13T11:55:54.254513Z","iopub.execute_input":"2022-12-13T11:55:54.254902Z","iopub.status.idle":"2022-12-13T11:56:03.724690Z","shell.execute_reply.started":"2022-12-13T11:55:54.254868Z","shell.execute_reply":"2022-12-13T11:56:03.723135Z"},"trusted":true},"execution_count":240,"outputs":[{"name":"stdout","text":"Requirement already satisfied: underthesea in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: underthesea-core==0.0.5a2 in /opt/conda/lib/python3.7/site-packages (from underthesea) (0.0.5a2)\nRequirement already satisfied: python-crfsuite>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from underthesea) (0.9.8)\nRequirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.7/site-packages (from underthesea) (8.0.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from underthesea) (2.28.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from underthesea) (6.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from underthesea) (3.7)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from underthesea) (4.64.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click>=6.0->underthesea) (4.13.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->underthesea) (2021.11.10)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (3.1.0)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.21.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (4.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"sw = []\nwith open(\"/kaggle/input/vn-stopword/vn_stopword.txt\", encoding='utf-8') as f:\n    lines = f.readlines()\nfor line in lines:\n    sw.append(line.replace(\"\\n\",\"\"))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:56:03.727386Z","iopub.execute_input":"2022-12-13T11:56:03.727795Z","iopub.status.idle":"2022-12-13T11:56:03.741046Z","shell.execute_reply.started":"2022-12-13T11:56:03.727756Z","shell.execute_reply":"2022-12-13T11:56:03.740094Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"from underthesea import text_normalize","metadata":{"id":"nhv0LlrBZ9Ey","execution":{"iopub.status.busy":"2022-12-13T11:56:03.742604Z","iopub.execute_input":"2022-12-13T11:56:03.742972Z","iopub.status.idle":"2022-12-13T11:56:03.749402Z","shell.execute_reply.started":"2022-12-13T11:56:03.742938Z","shell.execute_reply":"2022-12-13T11:56:03.748460Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"text_normalize(\"quân   khôngđược   thông minh lắm!\")","metadata":{"id":"9p-G-H1XROnY","execution":{"iopub.status.busy":"2022-12-13T11:56:03.751940Z","iopub.execute_input":"2022-12-13T11:56:03.752291Z","iopub.status.idle":"2022-12-13T11:56:03.761685Z","shell.execute_reply.started":"2022-12-13T11:56:03.752257Z","shell.execute_reply":"2022-12-13T11:56:03.760660Z"},"trusted":true},"execution_count":243,"outputs":[{"execution_count":243,"output_type":"execute_result","data":{"text/plain":"'quân khôngđược thông minh lắm !'"},"metadata":{}}]},{"cell_type":"code","source":"def purify(text):\n  vietnamese_characters = \"a-zA-Z0-9ÀÁÂÃÈÉÊÌÍÒÓÔÕÙÚĂĐĨŨƠàáâãèéêìíòóôõùúăđĩũơƯĂẠẢẤẦẨẪẬẮẰẲẴẶẸẺẼỀỀỂẾưăạảấầẩẫậắằẳẵặẹẻẽềềểếỄỆỈỊỌỎỐỒỔỖỘỚỜỞỠỢỤỦỨỪễệỉịọỏốồổỗộớờởỡợụủứừỬỮỰỲỴÝỶỸửữựỳýỵỷỹ\"\n  text = text.lower()\n  text = text.strip()\n  # text = \" \"+ text + \" \"\n  text = re.sub(\"[+]\", ' ', text) #all math-operating characters removed\n  text = re.sub(\" \\\\[a-z]\", ' ', text)# all newline and slash characters removed\n  \n  text = re.sub('[^' + vietnamese_characters + ']+', ' ', text) # all special characters removed\n  text = re.sub(\"([A-Za-z]+[0-9]+)|([0-9]+[A-Za-z]+)\", \" \", text) #150g\n  text = re.sub(\"[0-9]{3,}\", \" \", text) #all too long numbers (>= 3 digits) removed\n  text = re.sub(r'(\\D)\\1{2,}', r'\\1', text) # all consecutive duplicated characters removed\n  text = text.strip()\n\n  #all single-charater words removed\n  tmp_text = []\n  for x in text.split(\" \"):\n    if(len(x) > 1):\n      tmp_text.append(x)\n  \n  text = \" \".join(tmp_text)\n  text = text_normalize(text)\n  return text\n\n# abc = \"Mình order qua Now với giá 55k (xôi + trà quất 10k, mình chỉ áp đc code freeship) mà nhìn còn tệ hơn hộp xôi 20k bình thường! Không biết quán tốn tiền thuê mặt bằng hay sao mà lại cho khách có tẹo xôi + ít ruốc tép + gà xào nấm mà thấy được mấy thịt mấy nấm không? Vị ổn, hộp sạch sẽ, giao hàng rất nhanh nhưng nhận 1 hộp xôi đắt x2 mà chỉ được từng này thì quá thất vọng, chưa kể trà quất uống vị như có xà phòng rất ghê\"\n# abc = \" chả bao giờ quan tâm mấy cái kiểu bình luận như này nhưng phải chấm bút thái độ 10 đ đồ ăn 9 đ nói chung là khá ổn\"\nabc = \"前回も頼んだチキンのグリルと茄子のグリルも安定の美味しさ！茄子の味付けが以前より少し甘味が強く感じました、チキンに添えてあるココナッツ風味の揚げたも大好き！\"\nabc = \"Ngoooooooooooooonnnnnnnnnnnnnnnnnnnnnnnnn nnnnnnnnnnnnnnnnnnnhhhhhhhhhhhhhhhhhheeeeeeeeeeeeeeeee\"\n# abc = \"a b c\"\nabc = purify(abc)\nprint(abc)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ls93vtKZuuMv","outputId":"f929925b-7e91-413b-ec6c-4dafc63c0547","execution":{"iopub.status.busy":"2022-12-13T11:56:04.806364Z","iopub.execute_input":"2022-12-13T11:56:04.806754Z","iopub.status.idle":"2022-12-13T11:56:04.818377Z","shell.execute_reply.started":"2022-12-13T11:56:04.806711Z","shell.execute_reply":"2022-12-13T11:56:04.817261Z"},"trusted":true},"execution_count":244,"outputs":[{"name":"stdout","text":"ngon nhe\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title\nfrom underthesea import word_tokenize","metadata":{"cellView":"form","id":"azJmoZkv4nzq","execution":{"iopub.status.busy":"2022-12-13T11:56:06.373073Z","iopub.execute_input":"2022-12-13T11:56:06.373986Z","iopub.status.idle":"2022-12-13T11:56:06.379171Z","shell.execute_reply.started":"2022-12-13T11:56:06.373939Z","shell.execute_reply":"2022-12-13T11:56:06.377973Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":"def preprocess(purified_sents, max_len=None):\n  preprocessed_sents = []\n  for purified_text in purified_sents:\n\n    #remove all 0-long sents\n    # words = text.split(\" \")\n    # if(len(words) <= 0):\n    #   continue\n\n#     preprocessed by word_tokenize of underthesea\n    text = word_tokenize(purified_text, format = \"text\")\n    tmp_text = text\n    \n#     replace stopword by <pad>\n#     words = tmp_text.split(\" \")\n#     for i, word in enumerate(words):\n#         if word in sw:\n#             words[i] = '<pad>'\n#     tmp_text = \" \".join(words)\n\n    #preprocessed by rdrsegmenter of vncorenlp and bpe\n    # text = rdrsegmenter.word_segment(purified_text)\n    # text = bpe.encode(text)\n    # for x in text:\n    #   print(x)\n    # tmp_text =' '.join([' '.join(x) for x in text])\n\n    # preprocessed by py_rdrsegmenter of py_vncorenlp\n#     text = py_rdrsegmenter.word_segment(purified_text)\n#     tmp_text = \" \".join(text)\n\n    if(max_len is not None):\n      words = tmp_text.split(\" \")\n      if(len(words) > max_len):\n        words = words[0:max_len]\n      tmp_text = \" \".join(words)\n      \n    preprocessed_sents.append(tmp_text)\n  return preprocessed_sents\n","metadata":{"id":"Dcyb4YLMF8vk","execution":{"iopub.status.busy":"2022-12-13T11:56:07.374462Z","iopub.execute_input":"2022-12-13T11:56:07.374844Z","iopub.status.idle":"2022-12-13T11:56:07.382012Z","shell.execute_reply.started":"2022-12-13T11:56:07.374793Z","shell.execute_reply":"2022-12-13T11:56:07.380927Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"def encode_plus(preprocessed_sents,max_len=256):\n  encoded_sents = []\n  masks = []\n  for sent in preprocessed_sents:\n    sent_info = tokenizer.encode_plus(sent,\n                                      padding='max_length',\n                                      truncation=True,\n                                      add_special_tokens=True,\n                                      max_length = max_len,\n                                      return_token_type_ids=False,\n                                      return_attention_mask=True,\n                                     return_tensors='np')\n    encoded_sent = sent_info['input_ids'].flatten()\n    mask =  sent_info['attention_mask'].flatten()\n    encoded_sents.append(encoded_sent)\n    masks.append(mask)\n  return encoded_sents, masks","metadata":{"id":"eExpagxBE_p-","execution":{"iopub.status.busy":"2022-12-13T11:56:09.318792Z","iopub.execute_input":"2022-12-13T11:56:09.319283Z","iopub.status.idle":"2022-12-13T11:56:09.331416Z","shell.execute_reply.started":"2022-12-13T11:56:09.319229Z","shell.execute_reply":"2022-12-13T11:56:09.330306Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"markdown","source":"en","metadata":{"id":"MZqgnr2zmkPS"}},{"cell_type":"code","source":"train_purified_sents = [purify(train_sent) for train_sent in train_sents]\nvalid_purified_sents = [purify(valid_sent) for valid_sent in valid_sents]","metadata":{"id":"cujZj6BZzUhx","execution":{"iopub.status.busy":"2022-12-13T11:56:11.758979Z","iopub.execute_input":"2022-12-13T11:56:11.759379Z","iopub.status.idle":"2022-12-13T11:56:22.743732Z","shell.execute_reply.started":"2022-12-13T11:56:11.759344Z","shell.execute_reply":"2022-12-13T11:56:22.742743Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"# for i, sent in enumerate(train_purified_sents):\n#   if(sent == \"\"):\n#     train_purified_sents[i] = \"bình luận không xác định\"","metadata":{"id":"io-jBgbG3DRp","execution":{"iopub.status.busy":"2022-12-13T08:24:18.734492Z","iopub.execute_input":"2022-12-13T08:24:18.734855Z","iopub.status.idle":"2022-12-13T08:24:18.742608Z","shell.execute_reply.started":"2022-12-13T08:24:18.734819Z","shell.execute_reply":"2022-12-13T08:24:18.741222Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# for i, sent in enumerate(valid_purified_sents):\n#   if(sent == \"\"):\n#     valid_purified_sents[i] = \"bình luận không xác định\"","metadata":{"id":"NZOzWXEUSFJf","execution":{"iopub.status.busy":"2022-12-13T10:29:28.080426Z","iopub.execute_input":"2022-12-13T10:29:28.082607Z","iopub.status.idle":"2022-12-13T10:29:28.089041Z","shell.execute_reply.started":"2022-12-13T10:29:28.082559Z","shell.execute_reply":"2022-12-13T10:29:28.087676Z"},"trusted":true},"execution_count":249,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_22/1899538612.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if(sent == \"\"):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"],"ename":"IndentationError","evalue":"unexpected indent (1899538612.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"train_preprocessed_sents = preprocess(train_purified_sents)\nvalid_preprocessed_sents = preprocess(valid_purified_sents)","metadata":{"id":"yMA7wTyT3CJS","execution":{"iopub.status.busy":"2022-12-13T11:56:22.745893Z","iopub.execute_input":"2022-12-13T11:56:22.746393Z","iopub.status.idle":"2022-12-13T11:57:06.391729Z","shell.execute_reply.started":"2022-12-13T11:56:22.746355Z","shell.execute_reply":"2022-12-13T11:57:06.390643Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"print(valid_preprocessed_sents[535])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IC1rer1-qOJT","outputId":"60c28676-a285-4153-e16d-64a96b590547","execution":{"iopub.status.busy":"2022-12-13T11:57:06.393110Z","iopub.execute_input":"2022-12-13T11:57:06.393885Z","iopub.status.idle":"2022-12-13T11:57:06.400034Z","shell.execute_reply.started":"2022-12-13T11:57:06.393846Z","shell.execute_reply":"2022-12-13T11:57:06.398881Z"},"trusted":true},"execution_count":250,"outputs":[{"name":"stdout","text":"khá ổn nhưng thiếu nước_canh phở ăn khô mồm quá_trời nắng thế này nhai cơm khô sao nổi góp lần sau đừng làm mình that vong\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_ids, train_masks = encode_plus(train_preprocessed_sents, max_len=256)\nvalid_ids, valid_masks = encode_plus(valid_preprocessed_sents, max_len=256)","metadata":{"id":"QEbAswGLn9ka","execution":{"iopub.status.busy":"2022-12-13T11:57:06.402509Z","iopub.execute_input":"2022-12-13T11:57:06.402951Z","iopub.status.idle":"2022-12-13T11:57:12.525337Z","shell.execute_reply.started":"2022-12-13T11:57:06.402915Z","shell.execute_reply":"2022-12-13T11:57:12.524350Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:57:12.526621Z","iopub.execute_input":"2022-12-13T11:57:12.526988Z","iopub.status.idle":"2022-12-13T11:57:12.532253Z","shell.execute_reply.started":"2022-12-13T11:57:12.526955Z","shell.execute_reply":"2022-12-13T11:57:12.531314Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntrain_inputs = torch.tensor(train_ids)\nvalid_inputs = torch.tensor(valid_ids)\ntrain_labels = torch.tensor(train_labels)\nvalid_labels = torch.tensor(valid_labels)\ntrain_masks = torch.tensor(train_masks)\nvalid_masks = torch.tensor(valid_masks)\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nvalid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\nvalid_sampler = RandomSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qD55wmzKF8vG","outputId":"1e802bf1-0eb2-43d9-83a8-bc109416ec1f","execution":{"iopub.status.busy":"2022-12-13T11:57:38.191323Z","iopub.execute_input":"2022-12-13T11:57:38.191683Z","iopub.status.idle":"2022-12-13T11:57:38.400537Z","shell.execute_reply.started":"2022-12-13T11:57:38.191653Z","shell.execute_reply":"2022-12-13T11:57:38.399490Z"},"trusted":true},"execution_count":255,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  after removing the cwd from sys.path.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"\"\"\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"mgcIdNAk8ukx","execution":{"iopub.status.busy":"2022-12-13T11:57:45.494138Z","iopub.execute_input":"2022-12-13T11:57:45.495012Z","iopub.status.idle":"2022-12-13T11:57:45.500050Z","shell.execute_reply.started":"2022-12-13T11:57:45.494973Z","shell.execute_reply":"2022-12-13T11:57:45.498989Z"},"trusted":true},"execution_count":259,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrdASdT6860A","outputId":"53af5cae-0633-4e64-f11c-0fe5291e9d40","execution":{"iopub.status.busy":"2022-12-13T11:57:46.716260Z","iopub.execute_input":"2022-12-13T11:57:46.716613Z","iopub.status.idle":"2022-12-13T11:57:46.722848Z","shell.execute_reply.started":"2022-12-13T11:57:46.716582Z","shell.execute_reply":"2022-12-13T11:57:46.721892Z"},"trusted":true},"execution_count":260,"outputs":[{"execution_count":260,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:57:47.857338Z","iopub.execute_input":"2022-12-13T11:57:47.857732Z","iopub.status.idle":"2022-12-13T11:57:47.862930Z","shell.execute_reply.started":"2022-12-13T11:57:47.857697Z","shell.execute_reply":"2022-12-13T11:57:47.861942Z"},"trusted":true},"execution_count":261,"outputs":[]},{"cell_type":"code","source":"print(count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGGZ_878M80C","outputId":"e19ed751-51a4-4e62-b89c-161c8a0a9cc5","execution":{"iopub.status.busy":"2022-12-13T11:57:48.977247Z","iopub.execute_input":"2022-12-13T11:57:48.977719Z","iopub.status.idle":"2022-12-13T11:57:48.983789Z","shell.execute_reply.started":"2022-12-13T11:57:48.977674Z","shell.execute_reply":"2022-12-13T11:57:48.982635Z"},"trusted":true},"execution_count":262,"outputs":[{"name":"stdout","text":"48\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"id":"UVOKlxhL-h8o","execution":{"iopub.status.busy":"2022-12-13T11:57:50.091186Z","iopub.execute_input":"2022-12-13T11:57:50.091538Z","iopub.status.idle":"2022-12-13T11:57:50.097215Z","shell.execute_reply.started":"2022-12-13T11:57:50.091507Z","shell.execute_reply":"2022-12-13T11:57:50.095902Z"},"trusted":true},"execution_count":263,"outputs":[]},{"cell_type":"code","source":"class textCNN(nn.Module):\n  def __init__(self,seq_len=256, embedding_size=768, output_size=2):\n    super(textCNN, self).__init__()\n    self.embedding_size = embedding_size\n    self.output_size = output_size\n    self.seq_len = seq_len\n\n    kernel_1 = (2, embedding_size)\n    kernel_2 = (3, embedding_size)\n    kernel_3 = (4, embedding_size)\n    kernel_4 = (5, embedding_size)\n    self.convo_1 = nn.Conv2d(1, 256, kernel_1)\n    self.convo_2 = nn.Conv2d(1, 256, kernel_2)\n    self.convo_3 = nn.Conv2d(1, 256, kernel_3)\n    self.convo_4 = nn.Conv2d(1, 256, kernel_4)\n    self.fc1 = nn.Linear(4*self.seq_len, 2, bias=True)\n\n  def forward(self, inputs):\n\n    out_1 = self.convo_1(inputs)\n    out_2 = self.convo_2(inputs)\n    out_3 = self.convo_3(inputs)\n    out_4 = self.convo_4(inputs)\n\n    out_1 = nn.functional.max_pool2d(out_1,(self.seq_len - 1, 1))\n    out_2 = nn.functional.max_pool2d(out_2,(self.seq_len - 2, 1))\n    out_3 = nn.functional.max_pool2d(out_3,(self.seq_len - 3, 1))\n    out_4 = nn.functional.max_pool2d(out_4,(self.seq_len - 4, 1))\n\n    out_1 = torch.squeeze(out_1)\n    out_2 = torch.squeeze(out_2)\n    out_3 = torch.squeeze(out_3)\n    out_4 = torch.squeeze(out_4)\n    \n    # print(out_1.shape)\n    # print(out_2.shape)\n    # print(out_3.shape)\n    # print(out_4.shape)\n    \n    out = torch.cat((out_1, out_2, out_3, out_4), -1)\n    \n    out = self.fc1(out)\n    out = torch.sigmoid(out)\n    return out\n","metadata":{"id":"ecryoJ9kgSTA","execution":{"iopub.status.busy":"2022-12-13T11:57:50.914865Z","iopub.execute_input":"2022-12-13T11:57:50.915234Z","iopub.status.idle":"2022-12-13T11:57:50.927617Z","shell.execute_reply.started":"2022-12-13T11:57:50.915194Z","shell.execute_reply":"2022-12-13T11:57:50.926576Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"code","source":"class simple_textCNN(nn.Module):\n  def __init__(self, seq_len=256, embedding_size=768,kernel_size=3, output_size=2):\n    super(simple_textCNN, self).__init__()\n\n    self.embedding_size = embedding_size\n    self.output_size = output_size\n    self.seq_len = seq_len\n    self.kernel_size = kernel_size\n    kernel = (self.kernel_size, self.embedding_size)\n    \n    self.convo = nn.Conv2d(1, 256, kernel)\n\n    self.fc1 = nn.Linear(self.seq_len, 2, bias=True)\n    \n    nn.init.normal_(self.fc1.weight, std=0.02)\n    nn.init.normal_(self.fc1.bias, 0)\n    nn.init.normal_(self.convo.weight, std=0.02)\n    \n    \n  def forward(self, inputs):\n\n    out = self.convo(inputs)\n    # out = torch.t(out)\n#     print(out.shape)\n    out = F.max_pool2d(out,(self.seq_len - self.kernel_size + 1, 1))\n#     print(out.shape)\n    out = torch.squeeze(out)\n#     print(out.shape)\n    out = self.fc1(out)\n    out = torch.sigmoid(out)\n\n    return out","metadata":{"id":"PW5Mi2Gf2nMM","execution":{"iopub.status.busy":"2022-12-13T11:57:52.693897Z","iopub.execute_input":"2022-12-13T11:57:52.694270Z","iopub.status.idle":"2022-12-13T11:57:52.703701Z","shell.execute_reply.started":"2022-12-13T11:57:52.694239Z","shell.execute_reply":"2022-12-13T11:57:52.702559Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"code","source":"class BERT_for_sentiment(nn.Module):\n  def __init__(self, output_size=2, dropout=0.1):\n    super(BERT_for_sentiment, self).__init__()\n    self.output_size = output_size\n    self.dropout = dropout\n    self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n    self.fc1 = nn.Linear(768, 768, bias=True)\n    self.layernorm_1 = nn.LayerNorm((768,), eps = 1e-05, elementwise_affine=True)\n    self.fc2 = nn.Linear(768, self.output_size, bias=True)\n    nn.init.normal_(self.fc1.weight, std=0.02)\n    nn.init.normal_(self.fc1.bias, 0)\n    nn.init.normal_(self.fc2.weight, std=0.02)\n    nn.init.normal_(self.fc2.bias, 0)\n    \n  def forward(self, inputs, attention_mask):\n    x = self.bert(input_ids=inputs, attention_mask=attention_mask)\n    x = x.pooler_output\n#     x = F.dropout(x, self.dropout, inplace=False)\n#     x = self.fc1(x)\n#     x = self.layernorm_1(x)\n#     x = F.dropout(x, self.dropout, inplace=False)\n    x = self.fc2(x)\n    out = F.softmax(x, dim=-1)\n    \n    return out\n    ","metadata":{"id":"juvEUDwh-6Fz","execution":{"iopub.status.busy":"2022-12-13T11:57:54.095255Z","iopub.execute_input":"2022-12-13T11:57:54.095609Z","iopub.status.idle":"2022-12-13T11:57:54.106130Z","shell.execute_reply.started":"2022-12-13T11:57:54.095577Z","shell.execute_reply":"2022-12-13T11:57:54.105047Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"code","source":"class BERT_for_sentiment_large(nn.Module):\n  def __init__(self, output_size=2, dropout=0.1):\n    super(BERT_for_sentiment_large, self).__init__()\n    self.output_size = output_size\n    self.dropout = dropout\n    self.bert =  AutoModel.from_pretrained(\"vinai/phobert-base\", num_labels=2, output_hidden_states=True)\n    self.fc1 = nn.Linear(768, 768, bias=True)\n    self.layernorm_1 = nn.LayerNorm((768,), eps = 1e-05, elementwise_affine=True)\n    self.fc2 = nn.Linear(4*768, self.output_size, bias=True)\n    nn.init.normal_(self.fc1.weight, std=0.02)\n    nn.init.normal_(self.fc1.bias, 0)\n    nn.init.normal_(self.fc2.weight, std=0.02)\n    nn.init.normal_(self.fc2.bias, 0)\n    \n  def forward(self, inputs, attention_mask):\n    outputs = self.bert(input_ids=inputs, attention_mask=attention_mask)\n    x = torch.cat((outputs[2][-1][:,0, ...],outputs[2][-2][:,0, ...], outputs[2][-3][:,0, ...], outputs[2][-4][:,0, ...]),-1)\n#     x = F.dropout(x, self.dropout, inplace=False)\n#     x = self.fc1(x)\n#     x = self.layernorm_1(x)\n#     x = F.dropout(x, self.dropout, inplace=False)\n    x = self.fc2(x)\n#     out = F.softmax(x, dim=-1)\n    out = x\n    return out\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:57:57.363607Z","iopub.execute_input":"2022-12-13T11:57:57.363996Z","iopub.status.idle":"2022-12-13T11:57:57.375578Z","shell.execute_reply.started":"2022-12-13T11:57:57.363962Z","shell.execute_reply":"2022-12-13T11:57:57.373950Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"id":"HeFHbXN1D3Dp","execution":{"iopub.status.busy":"2022-12-13T11:58:00.748256Z","iopub.execute_input":"2022-12-13T11:58:00.748628Z","iopub.status.idle":"2022-12-13T11:58:00.753292Z","shell.execute_reply.started":"2022-12-13T11:58:00.748595Z","shell.execute_reply":"2022-12-13T11:58:00.752095Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"code","source":"class BERT_plus_LSTM_sentiment(nn.Module):\n  def __init__(self, hidden_size,n_layers=1, output_size=2, bidirectional=True, dropout=0.1):\n    super(BERT_plus_LSTM_sentiment, self).__init__()\n    self.output_size = output_size\n    self.dropout = dropout\n    self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n    self.bidirectional = bidirectional\n    self.hidden_size = hidden_size\n    self.n_layers = n_layers\n    self.LSTM = nn.LSTM(768, self.hidden_size, num_layers=self.n_layers, bidirectional=self.bidirectional, batch_first=True)\n    if self.bidirectional == True:\n      self.hidden_size = hidden_size*2\n    \n    self.fc1 = nn.Linear(self.hidden_size, 64, bias=True)\n    self.fc2 = nn.Linear(64, self.output_size, bias=True)\n    \n    nn.init.normal_(self.fc1.weight, std=0.02)\n    nn.init.normal_(self.fc1.bias, 0)\n    \n    nn.init.normal_(self.fc2.weight, std=0.02)\n    nn.init.normal_(self.fc2.bias, 0)\n    \n  def forward(self, inputs, attention_mask):\n\n    x = self.bert(input_ids=inputs, attention_mask=attention_mask)\n    x = x[0]\n    \n    out_lstm, _ = self.LSTM(x)\n    max_pool, _ = torch.max(out_lstm, 1)\n    linear_out = F.dropout(torch.relu(self.fc1(max_pool)), self.dropout, inplace=False)\n    linear_out = self.fc2(linear_out)\n    out = torch.sigmoid(linear_out)\n    \n    return out","metadata":{"id":"1aStR2QcsTy0","execution":{"iopub.status.busy":"2022-12-13T11:58:01.955596Z","iopub.execute_input":"2022-12-13T11:58:01.955986Z","iopub.status.idle":"2022-12-13T11:58:01.967540Z","shell.execute_reply.started":"2022-12-13T11:58:01.955952Z","shell.execute_reply":"2022-12-13T11:58:01.966424Z"},"trusted":true},"execution_count":269,"outputs":[]},{"cell_type":"code","source":"class BERT_plus_textCNN_sentiment(nn.Module):\n  def __init__(self, output_size=2):\n    super(BERT_plus_textCNN_sentiment, self).__init__()\n    self.output_size = output_size\n    self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n\n    self.CNN = simple_textCNN(kernel_size=3, output_size=self.output_size)\n\n  def forward(self, inputs, attention_mask):\n    x = self.bert(input_ids=inputs, attention_mask=attention_mask)\n    x = x.last_hidden_state\n    \n    x = torch.squeeze(x)\n    x = torch.unsqueeze(x, dim=1)\n    out= self.CNN(x)\n    return out","metadata":{"id":"vLMaS6UQx40H","execution":{"iopub.status.busy":"2022-12-13T11:58:03.203403Z","iopub.execute_input":"2022-12-13T11:58:03.203903Z","iopub.status.idle":"2022-12-13T11:58:03.218132Z","shell.execute_reply.started":"2022-12-13T11:58:03.203829Z","shell.execute_reply":"2022-12-13T11:58:03.216968Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"code","source":"\nmodel = BERT_for_sentiment_large(output_size=2)\n# from transformers import AutoModelForSequenceClassification\n# model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=2)\n# model = BERT_plus_LSTM_sentiment(64, n_layers=1, output_size=2)\n# model = BERT_plus_textCNN_sentiment(output_size=2)\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n\n\n\n","metadata":{"id":"B3_mmYmRTmd7","execution":{"iopub.status.busy":"2022-12-13T11:58:04.374179Z","iopub.execute_input":"2022-12-13T11:58:04.374626Z","iopub.status.idle":"2022-12-13T11:58:06.776347Z","shell.execute_reply.started":"2022-12-13T11:58:04.374584Z","shell.execute_reply":"2022-12-13T11:58:06.775337Z"},"trusted":true},"execution_count":271,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, child in enumerate(model.children()):\n    print(\"i = \", i, \" \", child)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:58:06.778098Z","iopub.execute_input":"2022-12-13T11:58:06.780087Z","iopub.status.idle":"2022-12-13T11:58:06.788228Z","shell.execute_reply.started":"2022-12-13T11:58:06.780048Z","shell.execute_reply":"2022-12-13T11:58:06.787166Z"},"trusted":true},"execution_count":272,"outputs":[{"name":"stdout","text":"i =  0   RobertaModel(\n  (embeddings): RobertaEmbeddings(\n    (word_embeddings): Embedding(64001, 768, padding_idx=1)\n    (position_embeddings): Embedding(258, 768, padding_idx=1)\n    (token_type_embeddings): Embedding(1, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): RobertaEncoder(\n    (layer): ModuleList(\n      (0): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): RobertaPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)\ni =  1   Linear(in_features=768, out_features=768, bias=True)\ni =  2   LayerNorm((768,), eps=1e-05, elementwise_affine=True)\ni =  3   Linear(in_features=3072, out_features=2, bias=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"# for i, child in enumerate(model.bert.embeddings.children()):\n#     print(\"i = \", i, \" \", child)\n#     for params in child.parameters():\n#         params.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:53:41.149234Z","iopub.execute_input":"2022-12-13T03:53:41.149672Z","iopub.status.idle":"2022-12-13T03:53:41.155114Z","shell.execute_reply.started":"2022-12-13T03:53:41.149638Z","shell.execute_reply":"2022-12-13T03:53:41.154064Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# @title\n# # print(model.children())\n# tmp = 0\n# for i, child in enumerate(model.bert.encoder.layer.children()):\n#     if i < 8:\n#         for params in child.parameters():\n#             params.requires_grad = False\n# #     print(\"i =\", i,\" \", child)\n#     tmp += 1\n# print(tmp)","metadata":{"cellView":"form","id":"Pzu7lLu3JPoe","execution":{"iopub.status.busy":"2022-12-13T03:53:41.157799Z","iopub.execute_input":"2022-12-13T03:53:41.158465Z","iopub.status.idle":"2022-12-13T03:53:41.163030Z","shell.execute_reply.started":"2022-12-13T03:53:41.158427Z","shell.execute_reply":"2022-12-13T03:53:41.162064Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor params in model.parameters():\n  count+=1\nprint(count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hE-Ytp9j9Skx","outputId":"a366eee9-0f5a-4025-f28b-fa5846bc23b3","execution":{"iopub.status.busy":"2022-12-13T11:58:10.922224Z","iopub.execute_input":"2022-12-13T11:58:10.922589Z","iopub.status.idle":"2022-12-13T11:58:10.929597Z","shell.execute_reply.started":"2022-12-13T11:58:10.922557Z","shell.execute_reply":"2022-12-13T11:58:10.928339Z"},"trusted":true},"execution_count":273,"outputs":[{"name":"stdout","text":"205\n","output_type":"stream"}]},{"cell_type":"code","source":"count = 0\nfor params in model.parameters():\n  if(params.requires_grad == True):\n    # print(params)\n    count+=1\n\nprint(count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CY5q5STViDGO","outputId":"d4266e17-0d9f-4505-e842-2f44276e3aae","execution":{"iopub.status.busy":"2022-12-13T11:58:12.073398Z","iopub.execute_input":"2022-12-13T11:58:12.073775Z","iopub.status.idle":"2022-12-13T11:58:12.080991Z","shell.execute_reply.started":"2022-12-13T11:58:12.073739Z","shell.execute_reply":"2022-12-13T11:58:12.079863Z"},"trusted":true},"execution_count":274,"outputs":[{"name":"stdout","text":"205\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nfrom transformers import get_linear_schedule_with_warmup\n\nmax_epochs = 10\nlearning_rate = 2*1e-5\n\nweight_decay = 0.01\noptimizing_parameters = filter(lambda p: p.requires_grad, model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.AdamW(\n    optimizing_parameters,\n    lr=learning_rate,\n    weight_decay=weight_decay\n)\nlr_scheduler = get_linear_schedule_with_warmup(\n                optimizer, \n                num_warmup_steps=0, \n                num_training_steps=len(train_dataloader)*max_epochs\n            )","metadata":{"id":"PAYgHw8EgdGI","execution":{"iopub.status.busy":"2022-12-13T11:58:13.400486Z","iopub.execute_input":"2022-12-13T11:58:13.400870Z","iopub.status.idle":"2022-12-13T11:58:13.409301Z","shell.execute_reply.started":"2022-12-13T11:58:13.400826Z","shell.execute_reply":"2022-12-13T11:58:13.408223Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"id":"k_I89RsSMUvD","execution":{"iopub.status.busy":"2022-12-13T11:58:19.412627Z","iopub.execute_input":"2022-12-13T11:58:19.413004Z","iopub.status.idle":"2022-12-13T11:58:19.419210Z","shell.execute_reply.started":"2022-12-13T11:58:19.412971Z","shell.execute_reply":"2022-12-13T11:58:19.418024Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GcY1LBg1S-Fn","outputId":"8c92c01f-0a95-48e7-8720-0152f2f255c1","execution":{"iopub.status.busy":"2022-12-13T11:58:20.742339Z","iopub.execute_input":"2022-12-13T11:58:20.742697Z","iopub.status.idle":"2022-12-13T11:58:20.752049Z","shell.execute_reply.started":"2022-12-13T11:58:20.742665Z","shell.execute_reply":"2022-12-13T11:58:20.751036Z"},"trusted":true},"execution_count":279,"outputs":[{"execution_count":279,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"id":"qmDMNVUArjgC","execution":{"iopub.status.busy":"2022-12-13T11:58:21.788537Z","iopub.execute_input":"2022-12-13T11:58:21.788921Z","iopub.status.idle":"2022-12-13T11:58:21.938838Z","shell.execute_reply.started":"2022-12-13T11:58:21.788888Z","shell.execute_reply":"2022-12-13T11:58:21.937848Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ndef uac(preds, labels):\n  pred_flat = np.argmax(preds, axis=1).flatten()\n  labels_flat = labels.flatten()\n  return roc_auc_score(pred_flat, labels_flat)","metadata":{"id":"okgKTqj3R4N7","execution":{"iopub.status.busy":"2022-12-13T11:58:23.054036Z","iopub.execute_input":"2022-12-13T11:58:23.054404Z","iopub.status.idle":"2022-12-13T11:58:23.060064Z","shell.execute_reply.started":"2022-12-13T11:58:23.054372Z","shell.execute_reply":"2022-12-13T11:58:23.058884Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm, tqdm_notebook","metadata":{"id":"y7cVg9zoQNGE","execution":{"iopub.status.busy":"2022-12-13T11:58:24.700102Z","iopub.execute_input":"2022-12-13T11:58:24.700469Z","iopub.status.idle":"2022-12-13T11:58:24.705663Z","shell.execute_reply.started":"2022-12-13T11:58:24.700437Z","shell.execute_reply":"2022-12-13T11:58:24.704476Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model,criterion, optimizer,scheduler, train_loader):\n  total_loss = 0\n  total_acc = 0\n  total = 0\n  tmp = 0\n  model.train()\n  \n  for batch in tqdm(train_loader):\n    input_ids, input_mask, labels = batch\n\n    input_ids = input_ids.to(device)    \n    input_mask = input_mask.to(device)   \n    labels = labels.to(device)\n\n    optimizer.zero_grad()\n    output = model(input_ids, attention_mask=input_mask)\n#     output = output.logits\n    loss = criterion(output, labels)\n\n    # loss = output[0]\n    # logits = output[1]\n\n    loss.backward()\n    \n    nn.utils.clip_grad_norm_(optimizing_parameters, max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    \n    \n    total_loss += loss.item()\n    total += len(labels)\n\n    logits = output.detach().cpu().numpy()\n    labels = labels.to('cpu').numpy()\n    acc = flat_accuracy(logits, labels)\n\n    total_acc += acc\n\n    tmp += 1\n\n  return total_loss/total, total_acc / tmp ","metadata":{"id":"2ti2-RyT3jth","execution":{"iopub.status.busy":"2022-12-13T11:58:25.696334Z","iopub.execute_input":"2022-12-13T11:58:25.696699Z","iopub.status.idle":"2022-12-13T11:58:25.705740Z","shell.execute_reply.started":"2022-12-13T11:58:25.696668Z","shell.execute_reply":"2022-12-13T11:58:25.704528Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"def validate_epoch(model,criterion,valid_loader):\n    model.eval()\n    total_loss = total = 0\n    accuracy = 0\n    eval_f1 = 0\n    tmp = 0\n    for batch in tqdm(valid_loader):\n      # batch = torch.toTensor(t.to(device) for t in batch)\n      input_ids, input_mask, labels = batch\n\n      input_ids = input_ids.to(device=device)\n      input_mask = input_mask.to(device=device)\n      labels = labels.to(device=device)\n\n          # Forwards pass\n      with torch.no_grad():\n        logits = model(input_ids, attention_mask=input_mask)\n#         logits = logits.logits\n          \n          # Calculate how wrong the model is\n        # loss = logits[0]\n        loss = criterion(logits, labels)\n        \n        # print(loss)\n        logits = logits.detach().cpu().numpy()\n        labels = labels.to('cpu').numpy()\n\n          \n        acc = flat_accuracy(logits, labels)\n        accuracy += acc\n        # Record metrics\n        total_loss += loss.item()\n        total += len(labels)\n        tmp += 1\n    return total_loss / total , accuracy / tmp","metadata":{"id":"XutIx7lrVHUO","execution":{"iopub.status.busy":"2022-12-13T11:58:27.239340Z","iopub.execute_input":"2022-12-13T11:58:27.239699Z","iopub.status.idle":"2022-12-13T11:58:27.248093Z","shell.execute_reply.started":"2022-12-13T11:58:27.239668Z","shell.execute_reply":"2022-12-13T11:58:27.246959Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"max_epochs = 10\nn_epochs = 0\ntrain_losses, valid_losses = [], []\ntrain_acces, valid_acces = [], []\nfor _ in range(max_epochs):\n    train_loss, train_acc = train_epoch(model,criterion, optimizer,lr_scheduler, train_dataloader)\n    valid_loss, valid_acc = validate_epoch(model,criterion, valid_dataloader)\n    \n    tqdm.write(\n        f'epoch #{n_epochs + 1:3d}\\n'\n        f'train_loss: {train_loss:.2e}'\n        f'\\ttrain_acc: {train_acc:.2e}\\n'\n        f'valid_loss: {valid_loss:.2e}'\n        f'\\tvalid_acc: {valid_acc:.2e}\\n',\n    )\n    # print(\"epoch:\", \" \", n_epochs)\n    # print(\"train_loss: \", \" \", train_loss)\n    # print(\"valid_loss: \", \" \", valid_loss)\n    # print(\"valid_acc: \", \" \", valid_acc)\n    # Early stopping if the current valid_loss is greater than the last three valid losses\n#     if len(valid_losses) > 2 and all(valid_loss >= loss\n#                                      for loss in valid_losses[-3:]):\n#         print('Stopping early')\n#         break\n#     if len(valid_losses) == 0:\n#       print(\"saving 1st model:...\")\n#       torch.save(model.state_dict(), '/kaggle/working/phobert_linear_x4.pt')\n#     else:\n#       min_n = 10\n#       max_acc = -1\n#       for loss in valid_losses:\n#         if(min_n > loss):\n#          min_n = loss\n        \n#       if valid_loss < min_n:\n#         print(\"saving the best model for best loss:...\")\n#         torch.save(model.state_dict(), '/kaggle/working/phobert_linear_x4.pt')\n#       elif valid_loss == min_n and abs(train_acc - valid_acc) < 0.02:\n#         print(\"saving the best model for best fit:...\")\n#         torch.save(model.state_dict(), '/kaggle/working/phobert_linear_x4.pt')\n    print(\"saving model:...\")\n    torch.save(model.state_dict(), f'/kaggle/working/phobert_linear_train_crawl_{n_epochs+1}.pt')\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    train_acces.append(train_acc)\n    valid_acces.append(valid_acc)\n    n_epochs += 1","metadata":{"id":"IiTKmnNIWpG_","execution":{"iopub.status.busy":"2022-12-13T11:58:40.963478Z","iopub.execute_input":"2022-12-13T11:58:40.963866Z","iopub.status.idle":"2022-12-13T12:28:12.319882Z","shell.execute_reply.started":"2022-12-13T11:58:40.963811Z","shell.execute_reply":"2022-12-13T12:28:12.317867Z"},"trusted":true},"execution_count":285,"outputs":[{"name":"stderr","text":"100%|██████████| 276/276 [03:23<00:00,  1.35it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  1\ntrain_loss: 8.63e-03\ttrain_acc: 8.94e-01\nvalid_loss: 6.72e-03\tvalid_acc: 9.27e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [03:23<00:00,  1.35it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  2\ntrain_loss: 6.27e-03\ttrain_acc: 9.34e-01\nvalid_loss: 7.29e-03\tvalid_acc: 9.15e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [03:23<00:00,  1.35it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  3\ntrain_loss: 5.24e-03\ttrain_acc: 9.47e-01\nvalid_loss: 6.86e-03\tvalid_acc: 9.26e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [03:24<00:00,  1.35it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  4\ntrain_loss: 4.38e-03\ttrain_acc: 9.57e-01\nvalid_loss: 7.18e-03\tvalid_acc: 9.22e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [03:23<00:00,  1.35it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  5\ntrain_loss: 3.52e-03\ttrain_acc: 9.67e-01\nvalid_loss: 7.81e-03\tvalid_acc: 9.19e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [03:24<00:00,  1.35it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  6\ntrain_loss: 3.02e-03\ttrain_acc: 9.73e-01\nvalid_loss: 8.09e-03\tvalid_acc: 9.21e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [03:23<00:00,  1.35it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  7\ntrain_loss: 2.46e-03\ttrain_acc: 9.79e-01\nvalid_loss: 8.41e-03\tvalid_acc: 9.22e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 276/276 [03:24<00:00,  1.35it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  8\ntrain_loss: 2.02e-03\ttrain_acc: 9.83e-01\nvalid_loss: 8.73e-03\tvalid_acc: 9.23e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 32/276 [00:24<03:05,  1.31it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2958533323.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_acces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1703430222.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, criterion, optimizer, scheduler, train_loader)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# logits = output[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizing_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:29:08.897526Z","iopub.execute_input":"2022-12-13T12:29:08.897922Z","iopub.status.idle":"2022-12-13T12:29:09.426301Z","shell.execute_reply.started":"2022-12-13T12:29:08.897888Z","shell.execute_reply":"2022-12-13T12:29:09.423221Z"},"trusted":true},"execution_count":286,"outputs":[{"execution_count":286,"output_type":"execute_result","data":{"text/plain":"6024"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:29:11.817159Z","iopub.execute_input":"2022-12-13T12:29:11.817529Z","iopub.status.idle":"2022-12-13T12:29:11.823130Z","shell.execute_reply.started":"2022-12-13T12:29:11.817497Z","shell.execute_reply":"2022-12-13T12:29:11.821853Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"code","source":"test_model = BERT_for_sentiment_large()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:29:15.895709Z","iopub.execute_input":"2022-12-13T12:29:15.896331Z","iopub.status.idle":"2022-12-13T12:29:22.822309Z","shell.execute_reply.started":"2022-12-13T12:29:15.896294Z","shell.execute_reply":"2022-12-13T12:29:22.821345Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"test_model.load_state_dict(torch.load(\"/kaggle/working/phobert_linear_train_crawl_3.pt\"))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:30:56.204543Z","iopub.execute_input":"2022-12-13T12:30:56.204946Z","iopub.status.idle":"2022-12-13T12:30:59.544702Z","shell.execute_reply.started":"2022-12-13T12:30:56.204912Z","shell.execute_reply":"2022-12-13T12:30:59.543717Z"},"trusted":true},"execution_count":289,"outputs":[{"execution_count":289,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:20:10.930638Z","iopub.execute_input":"2022-12-13T11:20:10.931014Z","iopub.status.idle":"2022-12-13T11:20:13.258530Z","shell.execute_reply.started":"2022-12-13T11:20:10.930982Z","shell.execute_reply":"2022-12-13T11:20:13.257475Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  1\ntrain_loss: 1.38e-02\ttrain_acc: 8.74e-01\nvalid_loss: 1.27e-02\tvalid_acc: 9.16e-01\n\nsaving 1st model:...\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  2\ntrain_loss: 1.25e-02\ttrain_acc: 9.13e-01\nvalid_loss: 1.25e-02\tvalid_acc: 9.17e-01\n\nsaving the best model for best loss:...\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  3\ntrain_loss: 1.20e-02\ttrain_acc: 9.31e-01\nvalid_loss: 1.24e-02\tvalid_acc: 9.23e-01\n\nsaving the best model for best loss:...\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.28it/s]\nepoch #  4\ntrain_loss: 1.20e-02\ttrain_acc: 9.32e-01\nvalid_loss: 1.24e-02\tvalid_acc: 9.24e-01\n\nsaving the best model for best loss:...\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  5\ntrain_loss: 1.17e-02\ttrain_acc: 9.39e-01\nvalid_loss: 1.26e-02\tvalid_acc: 9.16e-01\n\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  6\ntrain_loss: 1.17e-02\ttrain_acc: 9.41e-01\nvalid_loss: 1.25e-02\tvalid_acc: 9.19e-01\n\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.28it/s]\nepoch #  7\ntrain_loss: 1.14e-02\ttrain_acc: 9.48e-01\nvalid_loss: 1.23e-02\tvalid_acc: 9.27e-01\n\nsaving the best model for best loss:...\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  8\ntrain_loss: 1.14e-02\ttrain_acc: 9.51e-01\nvalid_loss: 1.22e-02\tvalid_acc: 9.29e-01\n\nsaving the best model for best loss:...\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.28it/s]\nepoch #  9\ntrain_loss: 1.13e-02\ttrain_acc: 9.53e-01\nvalid_loss: 1.22e-02\tvalid_acc: 9.33e-01\n\nsaving the best model for best loss:...\n100%|██████████| 256/256 [03:08<00:00,  1.36it/s]\n100%|██████████| 29/29 [00:06<00:00,  4.29it/s]\nepoch # 10\ntrain_loss: 1.13e-02\ttrain_acc: 9.54e-01\nvalid_loss: 1.22e-02\tvalid_acc: 9.30e-01\n","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cat((outputs[2][-1][:,0, ...],outputs[2][-2][:,0, ...], outputs[2][-3][:,0, ...], outputs[2][-4][:,0, ...]),-1).cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:31:12.997745Z","iopub.execute_input":"2022-12-13T12:31:12.998459Z","iopub.status.idle":"2022-12-13T12:31:13.031042Z","shell.execute_reply.started":"2022-12-13T12:31:12.998421Z","shell.execute_reply":"2022-12-13T12:31:13.029763Z"},"trusted":true},"execution_count":290,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2741672996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"],"ename":"NameError","evalue":"name 'outputs' is not defined","output_type":"error"}]},{"cell_type":"code","source":"trained_phobert = test_model.bert\n# trained_phobert = AutoModel.from_pretrained(\"vinai/phobert-base\", num_labels=2, output_hidden_state=True)\ntrained_phobert.to(device)\ntrained_phobert.eval()\ntotal_loss = total = 0\naccuracy = 0\neval_f1 = 0\ntmp = 0\nX_train = []\ny_train = []\nX_test = []\ny_test = []\nfor batch in tqdm(train_dataloader):\n    # batch = torch.toTensor(t.to(device) for t in batch)\n    input_ids, input_mask, labels = batch\n\n    input_ids = input_ids.to(device=device)\n    input_mask = input_mask.to(device=device)\n    labels = labels.to(device=device)\n\n          # Forwards pass\n    with torch.no_grad():\n      logits = trained_phobert(input_ids, attention_mask=input_mask)\n      logits = torch.cat((logits[2][-1][:,0, ...],logits[2][-2][:,0, ...], logits[2][-3][:,0, ...], logits[2][-4][:,0, ...]),-1)\n#       logits = logits.pooler_output\n        \n      logits = logits.detach().cpu().numpy()\n      labels = labels.to('cpu').numpy()\n\n      for logit in logits:\n        X_train.append(logit)\n      for label in labels:\n        y_train.append(label)\n\nfor batch in tqdm(valid_dataloader):\n    # batch = torch.toTensor(t.to(device) for t in batch)\n    input_ids, input_mask, labels = batch\n\n    input_ids = input_ids.to(device=device)\n    input_mask = input_mask.to(device=device)\n    labels = labels.to(device=device)\n\n          # Forwards pass\n    with torch.no_grad():\n      logits = trained_phobert(input_ids, attention_mask=input_mask)\n      logits = torch.cat((logits[2][-1][:,0, ...],logits[2][-2][:,0, ...], logits[2][-3][:,0, ...], logits[2][-4][:,0, ...]),-1)\n#       logits = logits.pooler_output\n          \n        # Calculate how wrong the model is\n        # loss = logits[0]\n        # print(loss)\n      logits = logits.detach().cpu().numpy()\n      labels = labels.to('cpu').numpy()\n\n      for logit in logits:\n        X_test.append(logit)\n      for label in labels:\n        y_test.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:31:19.593711Z","iopub.execute_input":"2022-12-13T12:31:19.594332Z","iopub.status.idle":"2022-12-13T12:32:39.099490Z","shell.execute_reply.started":"2022-12-13T12:31:19.594296Z","shell.execute_reply":"2022-12-13T12:32:39.098415Z"},"trusted":true},"execution_count":291,"outputs":[{"name":"stderr","text":"100%|██████████| 276/276 [01:05<00:00,  4.19it/s]\n100%|██████████| 57/57 [00:13<00:00,  4.21it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# X = X_train + X_test\n# y = y_train + y_test","metadata":{"execution":{"iopub.status.busy":"2022-12-13T07:43:05.309431Z","iopub.execute_input":"2022-12-13T07:43:05.309819Z","iopub.status.idle":"2022-12-13T07:43:05.315168Z","shell.execute_reply.started":"2022-12-13T07:43:05.309784Z","shell.execute_reply":"2022-12-13T07:43:05.314106Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=900)\npca.fit(X_train)\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:34:07.536609Z","iopub.execute_input":"2022-12-13T12:34:07.537394Z","iopub.status.idle":"2022-12-13T12:34:25.628066Z","shell.execute_reply.started":"2022-12-13T12:34:07.537355Z","shell.execute_reply":"2022-12-13T12:34:25.626603Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"code","source":"pca.explained_variance_ratio_.sum()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:34:50.731725Z","iopub.execute_input":"2022-12-13T12:34:50.732428Z","iopub.status.idle":"2022-12-13T12:34:50.738779Z","shell.execute_reply.started":"2022-12-13T12:34:50.732392Z","shell.execute_reply":"2022-12-13T12:34:50.737664Z"},"trusted":true},"execution_count":297,"outputs":[{"execution_count":297,"output_type":"execute_result","data":{"text/plain":"0.9968728644297893"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:34:54.897125Z","iopub.execute_input":"2022-12-13T12:34:54.897501Z","iopub.status.idle":"2022-12-13T12:34:54.902344Z","shell.execute_reply.started":"2022-12-13T12:34:54.897469Z","shell.execute_reply":"2022-12-13T12:34:54.901340Z"},"trusted":true},"execution_count":298,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:34:57.020963Z","iopub.execute_input":"2022-12-13T12:34:57.021324Z","iopub.status.idle":"2022-12-13T12:34:57.026448Z","shell.execute_reply.started":"2022-12-13T12:34:57.021294Z","shell.execute_reply":"2022-12-13T12:34:57.025162Z"},"trusted":true},"execution_count":299,"outputs":[]},{"cell_type":"code","source":"# classifier = DecisionTreeClassifier()\n# classifier.fit(np.array(X_train), np.array(y_train))\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(classifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(classifier.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:43:15.793264Z","iopub.execute_input":"2022-12-12T18:43:15.793632Z","iopub.status.idle":"2022-12-12T18:43:35.807300Z","shell.execute_reply.started":"2022-12-12T18:43:15.793602Z","shell.execute_reply":"2022-12-12T18:43:35.806233Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"Vanilla Implementation : Accuracy score for training data : 0.9995099840744824\nVanilla Implementation : Accuracy score for testing data : 0.7761852260198456\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:04.108757Z","iopub.execute_input":"2022-12-13T12:35:04.109726Z","iopub.status.idle":"2022-12-13T12:35:04.114529Z","shell.execute_reply.started":"2022-12-13T12:35:04.109689Z","shell.execute_reply":"2022-12-13T12:35:04.113520Z"},"trusted":true},"execution_count":300,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# RFclassifier = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0)\n# RFclassifier.fit(X_train, y_train)\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(RFclassifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(RFclassifier.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:05.826786Z","iopub.execute_input":"2022-12-13T12:35:05.827755Z","iopub.status.idle":"2022-12-13T12:35:05.833228Z","shell.execute_reply.started":"2022-12-13T12:35:05.827717Z","shell.execute_reply":"2022-12-13T12:35:05.832114Z"},"trusted":true},"execution_count":301,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n# NUM_CLASSIFIERS = 40\n# MAX_DEPTH = 4\n# GBCclassifier = GradientBoostingClassifier()\n# GBCclassifier.fit(X_train, y_train)\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(GBCclassifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(GBCclassifier.predict(X_test), y_test)))\n# cross_val_score(GBCclassifier, X, y).mean()\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(classifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(classifier.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:07.334992Z","iopub.execute_input":"2022-12-13T12:35:07.335358Z","iopub.status.idle":"2022-12-13T12:35:07.340391Z","shell.execute_reply.started":"2022-12-13T12:35:07.335327Z","shell.execute_reply":"2022-12-13T12:35:07.339279Z"},"trusted":true},"execution_count":302,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n# XGBclassifier = XGBClassifier()\n# XGBclassifier.fit(X_train, y_train)\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(XGBclassifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(XGBclassifier.predict(X_test), y_test)))\n# cross_val_score(XGBclassifier, X, y).mean()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:09.147576Z","iopub.execute_input":"2022-12-13T12:35:09.147956Z","iopub.status.idle":"2022-12-13T12:35:09.152988Z","shell.execute_reply.started":"2022-12-13T12:35:09.147923Z","shell.execute_reply":"2022-12-13T12:35:09.151702Z"},"trusted":true},"execution_count":303,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n# LGBMclassifier = LGBMClassifier()\n# # cross_val_score(LGBMclassifier, X, y).mean()\n# LGBMclassifier.fit(X_train, y_train)\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(LGBMclassifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(LGBMclassifier.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:10.173482Z","iopub.execute_input":"2022-12-13T12:35:10.173869Z","iopub.status.idle":"2022-12-13T12:35:10.184791Z","shell.execute_reply.started":"2022-12-13T12:35:10.173814Z","shell.execute_reply":"2022-12-13T12:35:10.183523Z"},"trusted":true},"execution_count":304,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkSUrcIeKBcQ","outputId":"402f1714-73fe-4c5b-f620-ede3c13104e3","execution":{"iopub.status.busy":"2022-12-13T12:35:11.357005Z","iopub.execute_input":"2022-12-13T12:35:11.357372Z","iopub.status.idle":"2022-12-13T12:35:11.364411Z","shell.execute_reply.started":"2022-12-13T12:35:11.357342Z","shell.execute_reply":"2022-12-13T12:35:11.363425Z"},"trusted":true},"execution_count":305,"outputs":[{"execution_count":305,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\ntmp_vote = VotingClassifier([('clf1', RandomForestClassifier()),\n                        ('clf2', XGBClassifier()),\n                        ('clf3', LGBMClassifier())], voting=\"hard\")\ntmp_vote.fit(X_train_pca, y_train)\nprint(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(tmp_vote.predict(X_train_pca), y_train)))\nprint(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(tmp_vote.predict(X_test_pca), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T07:47:41.735481Z","iopub.execute_input":"2022-12-13T07:47:41.736003Z","iopub.status.idle":"2022-12-13T07:52:21.779851Z","shell.execute_reply.started":"2022-12-13T07:47:41.735959Z","shell.execute_reply":"2022-12-13T07:52:21.778812Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Vanilla Implementation : Accuracy score for training data : 0.9995099840744824\nVanilla Implementation : Accuracy score for testing data : 0.9228224917309813\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:35:02.019588Z","iopub.execute_input":"2022-12-13T11:35:02.020095Z","iopub.status.idle":"2022-12-13T11:35:02.026337Z","shell.execute_reply.started":"2022-12-13T11:35:02.020051Z","shell.execute_reply":"2022-12-13T11:35:02.025083Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\ndcm_vote = VotingClassifier([('clf1', RandomForestClassifier()),\n                        ('clf2', XGBClassifier()),\n                        ('clf3', LGBMClassifier()),\n                        ('clf4', LogisticRegression())], voting=\"soft\")\ndcm_vote.fit(X_train_pca, y_train)\nprint(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(dcm_vote.predict(X_train_pca), y_train)))\nprint(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(dcm_vote.predict(X_test_pca), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:22.834408Z","iopub.execute_input":"2022-12-13T12:35:22.834916Z","iopub.status.idle":"2022-12-13T12:38:38.608145Z","shell.execute_reply.started":"2022-12-13T12:35:22.834869Z","shell.execute_reply":"2022-12-13T12:38:38.602978Z"},"trusted":true},"execution_count":306,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","output_type":"stream"},{"name":"stdout","text":"Vanilla Implementation : Accuracy score for training data : 0.999659979598776\nVanilla Implementation : Accuracy score for testing data : 0.9234159779614325\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\ndcm_vote = VotingClassifier([('clf1', RandomForestClassifier()),\n                        ('clf2', XGBClassifier()),\n                        ('clf3', LGBMClassifier())], voting=\"soft\")\ndcm_vote.fit(X_train, y_train)\nprint(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(dcm_vote.predict(X_train), y_train)))\nprint(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(dcm_vote.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:00:33.601681Z","iopub.execute_input":"2022-12-13T08:00:33.602213Z","iopub.status.idle":"2022-12-13T08:00:33.607552Z","shell.execute_reply.started":"2022-12-13T08:00:33.602173Z","shell.execute_reply":"2022-12-13T08:00:33.606615Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/data-sentiment/test.csv\")\nprint(test_data[\"RevId\"][0:10])","metadata":{"id":"7z9irfsuHmA7","execution":{"iopub.status.busy":"2022-12-13T12:39:09.055172Z","iopub.execute_input":"2022-12-13T12:39:09.055540Z","iopub.status.idle":"2022-12-13T12:39:09.178164Z","shell.execute_reply.started":"2022-12-13T12:39:09.055509Z","shell.execute_reply":"2022-12-13T12:39:09.177149Z"},"trusted":true},"execution_count":307,"outputs":[{"name":"stdout","text":"0     781115\n1    1219481\n2    1703765\n3    4870346\n4    2638711\n5    2288606\n6    2369977\n7    1395037\n8    1388406\n9    2704939\nName: RevId, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"test_corpus = []\nfor id, sent in zip(test_data[\"RevId\"], test_data[\"Comment\"]):\n  if(type(sent) != str):\n    sent = \"bình luận không xác định\"\n  test_corpus.append((id, sent))\n\nprint(len(test_corpus))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iw6uqln66-Wu","outputId":"7522c329-8dda-423b-a5d1-b7ef00482915","execution":{"iopub.status.busy":"2022-12-13T12:39:11.293436Z","iopub.execute_input":"2022-12-13T12:39:11.293787Z","iopub.status.idle":"2022-12-13T12:39:11.310488Z","shell.execute_reply.started":"2022-12-13T12:39:11.293757Z","shell.execute_reply":"2022-12-13T12:39:11.309315Z"},"trusted":true},"execution_count":308,"outputs":[{"name":"stdout","text":"5103\n","output_type":"stream"}]},{"cell_type":"code","source":"revIDs = [id for id,_ in test_corpus]\nsents = [sent for _,sent in test_corpus]\nprint(revIDs[0:10])\n# print(sents[0])","metadata":{"id":"V261k-vT8ow1","execution":{"iopub.status.busy":"2022-12-13T12:39:12.684954Z","iopub.execute_input":"2022-12-13T12:39:12.685320Z","iopub.status.idle":"2022-12-13T12:39:12.694906Z","shell.execute_reply.started":"2022-12-13T12:39:12.685289Z","shell.execute_reply":"2022-12-13T12:39:12.693863Z"},"trusted":true},"execution_count":309,"outputs":[{"name":"stdout","text":"[781115, 1219481, 1703765, 4870346, 2638711, 2288606, 2369977, 1395037, 1388406, 2704939]\n","output_type":"stream"}]},{"cell_type":"code","source":"for sent in test_data[\"Comment\"]:\n  if(type(sent) != str):\n    print(sent)","metadata":{"id":"OucwxZQgFknG","execution":{"iopub.status.busy":"2022-12-13T12:39:14.428853Z","iopub.execute_input":"2022-12-13T12:39:14.429957Z","iopub.status.idle":"2022-12-13T12:39:14.439001Z","shell.execute_reply.started":"2022-12-13T12:39:14.429919Z","shell.execute_reply":"2022-12-13T12:39:14.437625Z"},"trusted":true},"execution_count":310,"outputs":[{"name":"stdout","text":"nan\nnan\nnan\n","output_type":"stream"}]},{"cell_type":"code","source":"checked_sents = []\ncount = 0\nfor i, sent in enumerate(sents):\n  # print(i)\n  if(not check_spell(sent)):\n    print(i, sent)\n    count += 1\n\nprint(count)\n# for sent in checked_sents:\n#   print(sent)","metadata":{"id":"N8NA0k5kFP3m","execution":{"iopub.status.busy":"2022-12-13T12:39:16.498973Z","iopub.execute_input":"2022-12-13T12:39:16.499403Z","iopub.status.idle":"2022-12-13T12:39:16.511761Z","shell.execute_reply.started":"2022-12-13T12:39:16.499299Z","shell.execute_reply":"2022-12-13T12:39:16.510558Z"},"trusted":true},"execution_count":311,"outputs":[{"name":"stdout","text":"39 Quite beautiful place to stay and near everything we need as a customer/tourist. Next to BIDV TOWER and VIETCOMBANK HQ, near the lake, ancient town....\nBreakfast is not as I expected, not that quality for hotel :( quite a shame.\n94 Ngon\n165 I wish I had this roof in my house.\n171 Chilled bar with cheap price in the middle of the famous beer street. If they don't have any special event, you'll need to pay only 100.000 for the entrance ticket (included one drink). \nIts space is quite small but usually crowded. I wonder why there are so many Korean guys around whenever I go here. It seems this bar is the favorite place of Korean people who visit Hanoi. Haha.\n215 コメ麺を使った焼きそば。\n非常に安い。\n470 Like\n476 Siu ngonnnn\n478 I love the bubble tea here.  It's classy and tasty with several well-balanced flavor selections.  I usually get mint but sometimes I will get taro or chocolate.  I was chided the other day by a comment on a review I made at another tea place.  I had complained about being served iced milk tea in a plastic cup and was told that no one serves tea in a glass.  Well, this place does and the tea is for tea lovers.  So here has been my regular stop.\n599 Cafe ngon\n694 👌\n1054 Oke\n1329 Ngon\n1366 I’d be very worried about a coffee shop that stuggles to make something as basic as a black coffee. Certainly tastes like they are using instant coffee rather than freshly ground. Pity. Ground floor stinks of cigarettes would advise using upstairs\n1415 床に座ってお料理を囲む、居酒屋風ベトナム家庭料理レストラン。\n色々オーダーしたかったのですが、料理中にまだ食べていないベトナム料理を中心にチョイスしました。\n海老の唐揚げとシジミのおつまみはおかわりしたいくらい美味しいです！\n何故か？ご飯物をたくさん頼んでしまったけど、揚げたおこわにツルムラサキのスープをかけて食べたら絶品でした！\nシンプルな厚揚げに付けるマムトムがとても美味しい！\nビーツをこの様なスタイルで食べるのは初めてでした、添えてあるオリジナルソースをご飯にもかけて食べたらご飯が進む君でした！\n地酒のリンゴのお酒もとても美味しかったです。\n1471 Waoooo\n1594 Best 👍🏻\n1627 Butter Chicken was not garnished with butter, but with margarine! Rice is no Basmati quality. Chicken is very dry.\n1738 \"Ga nuong xa\" bread here is the best ever I had.I can't put it here for u guys.It's really great.But Green Thai tea is normal,not really good,it's a bit bland and cold.Thank u\n1860 pizza is so delicious\ncarbonara is a little solty..\n2184 👌\n2192 Very delicious and hot food. Would definetely recommend!\n2294 Have a good time  ❤️ wishing you lost of luck next tiem\n2400 Excellent American food. The price is acceptable for the quality of food. I was happy to discover they have a brunch menu!\n\nThe only downside is that it can get hot as it's an open space, and there are only a few fans - or perhaps it's because I'm not used to the high humidity. Great for families.\n2437 初めてハノイ旅行をするお友達にどうしてもチャーカーは食べてもらいたい。けど、私も違うお店にチャレンジしたいと、ハノイ名物のチャーカーを食べにフーディーでも高評価な新しく出来たコチラへ。\n綺麗てオシャレな内装、オリジナルのバッチャン焼、真鍮の鍋にテンション上がります。 \nただ、観光客相手のお店ではない？のでチャーカーの作法のアドバイスや鍋奉行を逐一してもらえないので初めてチャーカーにチャレンジする場合は少し戸惑ってしまうかも。マムトムは出されなかったので、マムトムください！とオーダーして持ってきてもらいました。コチラのマムトムはとても優しい味で臭みは少なく美味しかったです。\nチャーカーもエビのレモングラス焼きも全体的に優しい味つけでした(^O^)\nサッカーのワールドカップ予選の開幕でベトナムvsタイの試合時間のタイミングに来店してしまったので、スタッフの皆さまソワソワしていました笑笑\n2443 Good !\n2475 Ngon\n2586 Nice atmosphere. The DJ was spinning house music on a wednesday night; it was food music for having conversations. Cocktails are pretty good as its hard ro find a plave that can really do cocktails in Vietnam. I would refommend their signature cocktails over the traditional options. There also appears to be a wode selection of wine. Had an appetizer of crab fried soring rolls which was tasty as well.\n2806 Ngonnnnnnnnnmmmmmmnmmmmmmmmmmmmmnnn\n2821 Ngon..\n2822 A unique themed restaurant with the concept of three kingdoms , eating there was a good experience. A beautiful looking dragon head hot pot and lavish wooden design. Dim sum and kim sa are just super amazing , highly recommended to go and try out.  A unique concept of self picking the meat embedded in sticks and a vast range of mushrooms, hand made noodle and sea food to choose from. Give it a try guys . cheers\n2854 Service and food was good. Menu had partial translation, waiter knew basic english which was good, he suggested a couple of dishes instead we opted out for the 'lau bo' being a hot pot fan. The soup broth was really clean, reminded me of the sweet sour soup with hints of tangyness and sweetness of pineapple and tomato.\nThe drinks menu wasnt listed with the main menu. Theres two floors to the restaurant with half of the top floor exposed and overlooks the street. There was also portable airconditioning and fan unit to try keep cool. There was a degree of cleanliness aswell.\n2935 The packaging For drinks needs to be improved. A coffee on the go cup is not ideal. and please do not add plastic straws, especially if the customer requests. I have ordered here several times, each time i add a note to not include plastic straws, each time they deliver with plastic straws.\n3057 Yu Tang number one!!!\n3163 Like\n3166 Lovely ambiance we got at Home Moc today. Food was perfect and staff are very nice and helpfull. Surely, i will recommend it to my friends and i myself will come back regularly.\n3314 ngon\n3322 Nice place to have a light drinks with friends! You can find a good corner to chit chat and stay away from people eyes! Foods here also very nice! You must try green lobster pasta! Don't order too much! You can ask them to make one portion and share if you have only two person! Easy to park your car, that is one reason I love this place since Hanoi is always hard to find a car park!\n3483 모든 식자재를 한국에서 수입하고 있습니다.\n\n가끔 왜 베트남 분을 사용하시냐 컴플레인 하시는 고객분이 계시는데\n\n비빔면에 사용되는 옛날국수 소면입니다.\n\ncho mi bo tron cay\n3680 🤍😊🤍😊❤️‍🔥❤️‍🔥\n3745 My friend and I ventured out for brekkie/brunch and were certainly not disappointed! Beautiful veggie bun rien and probably the best summer rolls I've had in the last five months in Vietnam. Very nice iced tea too! We had the kumquat one, delish. Check it out!\n4221 Okk\n4428 Ngon ❤️\n4583 Hide deep in back of alley, but customers are keep coming in. I tried Banh Duc, I really like their soup. Also, tried Banh Da, tasty too. I definitely come here again.\n4634 good\n4658 Mint Cafe based in Hanoi close to the Cathedral St Joseph. It is very cosy but what I like the most is all the good cocktails made by professionnal bartender. \n\nI recommend it for sure!\n4766 I’ll miss this one! I hope they’ll have this in the Philippines! When I go back to***I’ll sure to go back for you!\n5016 A1\n5091 Good experience here in Ha Noi. I love fresh mango juice no sugar. I'll be back next time. Thank you\n48\n","output_type":"stream"}]},{"cell_type":"code","source":"purified_sents = [purify(str(sent)) for sent in sents]","metadata":{"id":"vPbtMsn09jky","execution":{"iopub.status.busy":"2022-12-13T12:39:22.348421Z","iopub.execute_input":"2022-12-13T12:39:22.348781Z","iopub.status.idle":"2022-12-13T12:39:28.057030Z","shell.execute_reply.started":"2022-12-13T12:39:22.348749Z","shell.execute_reply":"2022-12-13T12:39:28.056036Z"},"trusted":true},"execution_count":312,"outputs":[]},{"cell_type":"code","source":"print(purified_sents[2806])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olia58pSBpMn","outputId":"690cf3a8-15cf-4a03-c949-a3b7c05f726a","execution":{"iopub.status.busy":"2022-12-13T12:39:28.059136Z","iopub.execute_input":"2022-12-13T12:39:28.060004Z","iopub.status.idle":"2022-12-13T12:39:28.065674Z","shell.execute_reply.started":"2022-12-13T12:39:28.059966Z","shell.execute_reply":"2022-12-13T12:39:28.064377Z"},"trusted":true},"execution_count":313,"outputs":[{"name":"stdout","text":"ngonmnmn\n","output_type":"stream"}]},{"cell_type":"code","source":"# for i, sent in enumerate(purified_sents):\n#   if(sent == \"\"):\n#     purified_sents[i] = \"bình luận không xác định\"\n#     print(i)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-xuUfQ8Kh4r","outputId":"1c2524e0-e577-4ef8-8a26-c719717f3f01","execution":{"iopub.status.busy":"2022-12-13T11:39:55.296909Z","iopub.execute_input":"2022-12-13T11:39:55.297506Z","iopub.status.idle":"2022-12-13T11:39:55.310493Z","shell.execute_reply.started":"2022-12-13T11:39:55.297461Z","shell.execute_reply":"2022-12-13T11:39:55.309336Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"preprocessed_sents = preprocess(purified_sents)","metadata":{"id":"___FrYla-3tM","execution":{"iopub.status.busy":"2022-12-13T12:39:28.067414Z","iopub.execute_input":"2022-12-13T12:39:28.067794Z","iopub.status.idle":"2022-12-13T12:39:51.493662Z","shell.execute_reply.started":"2022-12-13T12:39:28.067759Z","shell.execute_reply":"2022-12-13T12:39:51.492685Z"},"trusted":true},"execution_count":314,"outputs":[]},{"cell_type":"code","source":"# encoded_sents = encode(preprocessed_sents, max_len=150, max_seq=256)","metadata":{"id":"mEBqRrR2_ADk","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padded_sents, attention_masks = encode_plus(preprocessed_sents, max_len=256)","metadata":{"id":"wvSG-D4tLEWh","execution":{"iopub.status.busy":"2022-12-13T12:39:51.496232Z","iopub.execute_input":"2022-12-13T12:39:51.496604Z","iopub.status.idle":"2022-12-13T12:39:54.225631Z","shell.execute_reply.started":"2022-12-13T12:39:51.496568Z","shell.execute_reply":"2022-12-13T12:39:54.224662Z"},"trusted":true},"execution_count":315,"outputs":[]},{"cell_type":"code","source":"# padded_sents = padding(encoded_sents, max_len)","metadata":{"id":"fxHzzrC-_c5a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# attention_masks = attention_mask(padded_sents)","metadata":{"id":"wkNPCwcI_-qX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-12-13T07:54:36.316194Z","iopub.execute_input":"2022-12-13T07:54:36.316663Z","iopub.status.idle":"2022-12-13T07:54:36.357966Z","shell.execute_reply.started":"2022-12-13T07:54:36.316623Z","shell.execute_reply":"2022-12-13T07:54:36.355666Z"},"trusted":true},"execution_count":110,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1490779902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"],"ename":"TypeError","evalue":"'str' object is not callable","output_type":"error"}]},{"cell_type":"code","source":"batch_size = 32\n\ninputs = torch.tensor(padded_sents)\nids = torch.tensor(revIDs)\nmasks = torch.tensor(attention_masks)\n\ntest_data = TensorDataset(ids, masks, inputs)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)","metadata":{"id":"qoBxTJmS_rYZ","execution":{"iopub.status.busy":"2022-12-13T12:39:54.227352Z","iopub.execute_input":"2022-12-13T12:39:54.228379Z","iopub.status.idle":"2022-12-13T12:39:54.414088Z","shell.execute_reply.started":"2022-12-13T12:39:54.228324Z","shell.execute_reply":"2022-12-13T12:39:54.412869Z"},"trusted":true},"execution_count":316,"outputs":[]},{"cell_type":"code","source":"inputs.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:40:29.715420Z","iopub.execute_input":"2022-12-13T12:40:29.715940Z","iopub.status.idle":"2022-12-13T12:40:29.732131Z","shell.execute_reply.started":"2022-12-13T12:40:29.715892Z","shell.execute_reply":"2022-12-13T12:40:29.730694Z"},"trusted":true},"execution_count":317,"outputs":[{"execution_count":317,"output_type":"execute_result","data":{"text/plain":"torch.Size([5103, 256])"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"1KNXAMuzywBM","execution":{"iopub.status.busy":"2022-12-13T12:40:31.279242Z","iopub.execute_input":"2022-12-13T12:40:31.279603Z","iopub.status.idle":"2022-12-13T12:40:31.285227Z","shell.execute_reply.started":"2022-12-13T12:40:31.279573Z","shell.execute_reply":"2022-12-13T12:40:31.283884Z"},"trusted":true},"execution_count":318,"outputs":[]},{"cell_type":"code","source":"test_model.to(device)","metadata":{"id":"bkH003m-bVH7","execution":{"iopub.status.busy":"2022-12-13T12:40:33.003241Z","iopub.execute_input":"2022-12-13T12:40:33.003596Z","iopub.status.idle":"2022-12-13T12:40:33.021751Z","shell.execute_reply.started":"2022-12-13T12:40:33.003566Z","shell.execute_reply":"2022-12-13T12:40:33.020873Z"},"trusted":true},"execution_count":319,"outputs":[{"execution_count":319,"output_type":"execute_result","data":{"text/plain":"BERT_for_sentiment_large(\n  (bert): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (fc1): Linear(in_features=768, out_features=768, bias=True)\n  (layernorm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (fc2): Linear(in_features=3072, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"X = []\nIDs = []\nfor batch in tqdm(test_dataloader):\n    # batch = torch.toTensor(t.to(device) for t in batch)\n    ids, input_mask, input_ids = batch\n\n    input_ids = input_ids.to(device)\n    input_mask = input_mask.to(device)\n    ids = ids.to(device=device)\n\n          # Forwards pass\n    with torch.no_grad():\n      logits = trained_phobert(input_ids, attention_mask=input_mask)\n#       logits = logits.pooler_output\n      logits = torch.cat((logits[2][-1][:,0, ...],logits[2][-2][:,0, ...], logits[2][-3][:,0, ...], logits[2][-4][:,0, ...]),-1)\n#       logits = torch.cat((logits[2][-1][:,0, ...],logits[2][-2][:,0, ...], logits[2][-3][:,0, ...], logits[2][-4][:,0, ...]),-1)\n        # Calculate how wrong the model is\n        # loss = logits[0]\n        # print(loss)\n      ids = ids.detach().cpu().numpy()\n      logits = logits.detach().cpu().numpy()\n      for id_ in ids:\n        IDs.append(id_)\n      for logit in logits:\n        X.append(logit)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:40:46.150168Z","iopub.execute_input":"2022-12-13T12:40:46.150525Z","iopub.status.idle":"2022-12-13T12:41:24.222156Z","shell.execute_reply.started":"2022-12-13T12:40:46.150494Z","shell.execute_reply":"2022-12-13T12:41:24.221172Z"},"trusted":true},"execution_count":320,"outputs":[{"name":"stderr","text":"100%|██████████| 160/160 [00:38<00:00,  4.20it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"X_pca = pca.transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:41:30.805247Z","iopub.execute_input":"2022-12-13T12:41:30.805607Z","iopub.status.idle":"2022-12-13T12:41:31.354864Z","shell.execute_reply.started":"2022-12-13T12:41:30.805576Z","shell.execute_reply":"2022-12-13T12:41:31.353434Z"},"trusted":true},"execution_count":321,"outputs":[]},{"cell_type":"code","source":"preds = dcm_vote.predict(X_pca)\n\nsub = []\nfor tmp in zip(IDs, preds):\n    sub.append(tmp)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:41:32.623729Z","iopub.execute_input":"2022-12-13T12:41:32.624438Z","iopub.status.idle":"2022-12-13T12:41:32.913597Z","shell.execute_reply.started":"2022-12-13T12:41:32.624401Z","shell.execute_reply":"2022-12-13T12:41:32.912316Z"},"trusted":true},"execution_count":322,"outputs":[]},{"cell_type":"code","source":"sub = []\ntest_model.eval()\ntotal_loss = total = 0\nfor batch in tqdm(test_dataloader):\n# batch = torch.toTensor(t.to(device) for t in batch)\n  ids, input_mask, input_ids = batch\n\n  input_ids = input_ids.to(device)\n  input_mask = input_mask.to(device)\n  ids = ids.to(device=device)\n          # Forwards pass\n  with torch.no_grad():\n    outputs = test_model(input_ids, attention_mask=input_mask)\n    # loss = outputs[0]\n#     outputs = outputs.logits\n    loss = outputs.detach().cpu().numpy()\n    ids = ids.to('cpu').numpy()\n\n    preds_flat = np.argmax(loss, axis=1).flatten()\n    for tup in zip(ids, preds_flat):\n      sub.append(tup)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzpshVqf_9Uu","outputId":"aedcecb2-cf43-4725-89a5-59461c104a76","execution":{"iopub.status.busy":"2022-12-13T01:12:00.875558Z","iopub.execute_input":"2022-12-13T01:12:00.876236Z","iopub.status.idle":"2022-12-13T01:12:39.469643Z","shell.execute_reply.started":"2022-12-13T01:12:00.876189Z","shell.execute_reply":"2022-12-13T01:12:39.468567Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stderr","text":"100%|██████████| 160/160 [00:38<00:00,  4.15it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sub[0:10])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:41:46.788331Z","iopub.execute_input":"2022-12-13T12:41:46.788740Z","iopub.status.idle":"2022-12-13T12:41:46.795046Z","shell.execute_reply.started":"2022-12-13T12:41:46.788701Z","shell.execute_reply":"2022-12-13T12:41:46.793772Z"},"trusted":true},"execution_count":323,"outputs":[{"name":"stdout","text":"[(781115, 0), (1219481, 0), (1703765, 1), (4870346, 0), (2638711, 1), (2288606, 1), (2369977, 1), (1395037, 1), (1388406, 1), (2704939, 0)]\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = [pr for _, pr in sub]","metadata":{"id":"Oz2EdjU3HRkW","execution":{"iopub.status.busy":"2022-12-13T12:41:48.324983Z","iopub.execute_input":"2022-12-13T12:41:48.325363Z","iopub.status.idle":"2022-12-13T12:41:48.331482Z","shell.execute_reply.started":"2022-12-13T12:41:48.325333Z","shell.execute_reply":"2022-12-13T12:41:48.330345Z"},"trusted":true},"execution_count":324,"outputs":[]},{"cell_type":"code","source":"ids = [id for id,_ in sub]","metadata":{"id":"ygEvKZSDJY7N","execution":{"iopub.status.busy":"2022-12-13T12:41:49.965078Z","iopub.execute_input":"2022-12-13T12:41:49.965559Z","iopub.status.idle":"2022-12-13T12:41:49.975687Z","shell.execute_reply.started":"2022-12-13T12:41:49.965510Z","shell.execute_reply":"2022-12-13T12:41:49.974661Z"},"trusted":true},"execution_count":325,"outputs":[]},{"cell_type":"code","source":"print(len(pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vt-hK4SHwFt","outputId":"705de3f4-1853-49b9-ea76-c207ff4d5479","execution":{"iopub.status.busy":"2022-12-13T12:41:52.349236Z","iopub.execute_input":"2022-12-13T12:41:52.349596Z","iopub.status.idle":"2022-12-13T12:41:52.355074Z","shell.execute_reply.started":"2022-12-13T12:41:52.349566Z","shell.execute_reply":"2022-12-13T12:41:52.354036Z"},"trusted":true},"execution_count":326,"outputs":[{"name":"stdout","text":"5103\n","output_type":"stream"}]},{"cell_type":"code","source":"tmp_ids = np.array(pred)","metadata":{"id":"PUo8zph8MXQf","execution":{"iopub.status.busy":"2022-12-13T12:41:54.073241Z","iopub.execute_input":"2022-12-13T12:41:54.074020Z","iopub.status.idle":"2022-12-13T12:41:54.080151Z","shell.execute_reply.started":"2022-12-13T12:41:54.073979Z","shell.execute_reply":"2022-12-13T12:41:54.079077Z"},"trusted":true},"execution_count":327,"outputs":[]},{"cell_type":"code","source":"print(tmp_ids)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjxE5_H1Mt6j","outputId":"5a96e235-10f0-4f26-bc7e-d82b614d4802","execution":{"iopub.status.busy":"2022-12-13T12:41:55.822929Z","iopub.execute_input":"2022-12-13T12:41:55.823300Z","iopub.status.idle":"2022-12-13T12:41:55.829037Z","shell.execute_reply.started":"2022-12-13T12:41:55.823269Z","shell.execute_reply":"2022-12-13T12:41:55.827969Z"},"trusted":true},"execution_count":328,"outputs":[{"name":"stdout","text":"[0 0 1 ... 0 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sub[0:10])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3DjVlK5Em9x","outputId":"b8953c4f-cfe4-47f3-8989-9dde34e2b8b9","execution":{"iopub.status.busy":"2022-12-13T12:41:57.798948Z","iopub.execute_input":"2022-12-13T12:41:57.801124Z","iopub.status.idle":"2022-12-13T12:41:57.807613Z","shell.execute_reply.started":"2022-12-13T12:41:57.801074Z","shell.execute_reply":"2022-12-13T12:41:57.806387Z"},"trusted":true},"execution_count":329,"outputs":[{"name":"stdout","text":"[(781115, 0), (1219481, 0), (1703765, 1), (4870346, 0), (2638711, 1), (2288606, 1), (2369977, 1), (1395037, 1), (1388406, 1), (2704939, 0)]\n","output_type":"stream"}]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'RevId': np.array(ids).reshape(5103), 'Rating': np.array(pred).reshape(5103)})","metadata":{"id":"vhJ_99xU4zpd","execution":{"iopub.status.busy":"2022-12-13T12:42:03.268621Z","iopub.execute_input":"2022-12-13T12:42:03.269007Z","iopub.status.idle":"2022-12-13T12:42:03.275776Z","shell.execute_reply.started":"2022-12-13T12:42:03.268974Z","shell.execute_reply":"2022-12-13T12:42:03.274666Z"},"trusted":true},"execution_count":330,"outputs":[]},{"cell_type":"code","source":"my_submission.to_csv(\"/kaggle/working/submission_13_12_5.csv\", index=False)","metadata":{"id":"ZStZburmJ_47","execution":{"iopub.status.busy":"2022-12-13T12:42:06.795227Z","iopub.execute_input":"2022-12-13T12:42:06.795586Z","iopub.status.idle":"2022-12-13T12:42:06.809559Z","shell.execute_reply.started":"2022-12-13T12:42:06.795556Z","shell.execute_reply":"2022-12-13T12:42:06.808493Z"},"trusted":true},"execution_count":331,"outputs":[]}]}