{"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"063bab06d1394e289d1a5300f3048d2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0799c717625c4587bf2fd918c8b07dd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c681e9e6aa4469a87a16c14168421c9","placeholder":"‚Äã","style":"IPY_MODEL_7fc542de9a9f4268a065d6adf96cb927","value":" 1.14M/1.14M [00:00&lt;00:00, 3.34MB/s]"}},"0c5886c49a114b86b9fbc3345503cff6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c55e536b868141ba8163a101a61d320e","max":557,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40cf64a08a6f48249094e3f7e9b73f18","value":557}},"0d1083f2e8974da1a976808907d0aa4a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17113c3846ff4e3c84aea7ccf21ab2fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"177f6e69839f4238a6418c5247367129":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2097eca8a6604d108e03528244efadac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"287a91fc255f4de5a7de1d27dcfce619":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab52c6fccb0e48049c256b7467f2604a","placeholder":"‚Äã","style":"IPY_MODEL_938cf653cb9044e191dfb0904135c75a","value":" 557/557 [00:00&lt;00:00, 5.09kB/s]"}},"39ec0e1c6f0f40fa906135f4e387abaf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40cf64a08a6f48249094e3f7e9b73f18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45f1b0212e954b17ad45bd644f2156d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e687c5c54d324dd987c1a92be85ff1e6","placeholder":"‚Äã","style":"IPY_MODEL_2097eca8a6604d108e03528244efadac","value":"Downloading: 100%"}},"4c681e9e6aa4469a87a16c14168421c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f02e8c1b65b4385a13c73a993fe2524":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5751619e4df4e0ea474b2ea5a745c32","placeholder":"‚Äã","style":"IPY_MODEL_a84de470cfa44f9896cd7572bcb4dd94","value":"Downloading: 100%"}},"609a6a6f6ee04bd78a5c8712b348e585":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb81204063004497a7c3268253418592","IPY_MODEL_cd1089d6426c4f3abdd0c8c4690b9bb9","IPY_MODEL_96fb2603b9064763922efa4ee29bbbb4"],"layout":"IPY_MODEL_e44370231ea5471f8c2dc5ecabc95a95"}},"66a4baa794ce43de807650851ab0bb21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45f1b0212e954b17ad45bd644f2156d4","IPY_MODEL_0c5886c49a114b86b9fbc3345503cff6","IPY_MODEL_287a91fc255f4de5a7de1d27dcfce619"],"layout":"IPY_MODEL_ed27683d14034cc1aac02143a2183101"}},"73f44d88a54a48738ae8aac670fa4b43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7130a6ea9434b2ea816a65277f494e3","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d62182b941e646d89407282009108d95","value":1135173}},"7fc542de9a9f4268a065d6adf96cb927":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c9711a1696c4c1ea2e4f2f9738154dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"938cf653cb9044e191dfb0904135c75a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96fb2603b9064763922efa4ee29bbbb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_063bab06d1394e289d1a5300f3048d2e","placeholder":"‚Äã","style":"IPY_MODEL_0d1083f2e8974da1a976808907d0aa4a","value":" 543M/543M [00:11&lt;00:00, 51.8MB/s]"}},"982977287755416db422bd4cd0310b33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d2d19092a3804a228d6a1dabde7f6fdd","IPY_MODEL_73f44d88a54a48738ae8aac670fa4b43","IPY_MODEL_0799c717625c4587bf2fd918c8b07dd0"],"layout":"IPY_MODEL_a887ad0607f54f4eb91da36ba8005b53"}},"983e1e7ae73948b6ab8ae4bff150f8ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1797f7fddde43b197b066e16ef80529":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f038db81cac24512b447785c4328fb6b","placeholder":"‚Äã","style":"IPY_MODEL_8c9711a1696c4c1ea2e4f2f9738154dc","value":" 895k/895k [00:00&lt;00:00, 5.02MB/s]"}},"a723b5e5b4a54881aa53eefe4d4299d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a84de470cfa44f9896cd7572bcb4dd94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a87986eb716c4b0fb25943399597fabf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a887ad0607f54f4eb91da36ba8005b53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab52c6fccb0e48049c256b7467f2604a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab717eb1ac974d57aed09303ba1c43c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae31045b39bd4677b2c8b14a004c51f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c55e536b868141ba8163a101a61d320e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5751619e4df4e0ea474b2ea5a745c32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb81204063004497a7c3268253418592":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae31045b39bd4677b2c8b14a004c51f0","placeholder":"‚Äã","style":"IPY_MODEL_ab717eb1ac974d57aed09303ba1c43c1","value":"Downloading: 100%"}},"cd1089d6426c4f3abdd0c8c4690b9bb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17113c3846ff4e3c84aea7ccf21ab2fb","max":542923308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_177f6e69839f4238a6418c5247367129","value":542923308}},"d2d19092a3804a228d6a1dabde7f6fdd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a87986eb716c4b0fb25943399597fabf","placeholder":"‚Äã","style":"IPY_MODEL_a723b5e5b4a54881aa53eefe4d4299d1","value":"Downloading: 100%"}},"d62182b941e646d89407282009108d95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d7130a6ea9434b2ea816a65277f494e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e44370231ea5471f8c2dc5ecabc95a95":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e687c5c54d324dd987c1a92be85ff1e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed27683d14034cc1aac02143a2183101":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f038db81cac24512b447785c4328fb6b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f548078d7dc14acab9d98e41d3f635a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f02e8c1b65b4385a13c73a993fe2524","IPY_MODEL_f91ca80574eb4851bac2ad7f327f777e","IPY_MODEL_a1797f7fddde43b197b066e16ef80529"],"layout":"IPY_MODEL_983e1e7ae73948b6ab8ae4bff150f8ac"}},"f61889b098bc46f3a70a30707f5391c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f91ca80574eb4851bac2ad7f327f777e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39ec0e1c6f0f40fa906135f4e387abaf","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f61889b098bc46f3a70a30707f5391c2","value":895321}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brOS-cI4MJxP","outputId":"488bf825-1321-49dc-e5ca-c212dc9bae4c","execution":{"iopub.status.busy":"2022-12-13T11:51:12.661187Z","iopub.execute_input":"2022-12-13T11:51:12.661550Z","iopub.status.idle":"2022-12-13T11:51:21.958124Z","shell.execute_reply.started":"2022-12-13T11:51:12.661516Z","shell.execute_reply":"2022-12-13T11:51:21.956877Z"},"trusted":true},"execution_count":213,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pip install py_vncorenlp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxQeyBshQrDe","outputId":"0572f695-6702-4a7a-9542-418249319529","execution":{"iopub.status.busy":"2022-12-13T11:51:21.960933Z","iopub.execute_input":"2022-12-13T11:51:21.961340Z","iopub.status.idle":"2022-12-13T11:51:31.276586Z","shell.execute_reply.started":"2022-12-13T11:51:21.961300Z","shell.execute_reply":"2022-12-13T11:51:31.274911Z"},"trusted":true},"execution_count":214,"outputs":[{"name":"stdout","text":"Requirement already satisfied: py_vncorenlp in /opt/conda/lib/python3.7/site-packages (0.1.3)\nRequirement already satisfied: pyjnius in /opt/conda/lib/python3.7/site-packages (from py_vncorenlp) (1.4.2)\nRequirement already satisfied: six>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from pyjnius->py_vncorenlp) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import logging\nlogging.set_verbosity_error()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:51:31.278419Z","iopub.execute_input":"2022-12-13T11:51:31.279152Z","iopub.status.idle":"2022-12-13T11:51:31.286955Z","shell.execute_reply.started":"2022-12-13T11:51:31.279110Z","shell.execute_reply":"2022-12-13T11:51:31.285420Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"/kaggle/input/train-format/trainformat.csv\")\nprint(data['Comment'][0:10])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rloT7v68ti-V","outputId":"09a4162b-8274-4bf4-9f81-b3cfb8436df2","execution":{"iopub.status.busy":"2022-12-13T11:51:31.290410Z","iopub.execute_input":"2022-12-13T11:51:31.290880Z","iopub.status.idle":"2022-12-13T11:51:31.453831Z","shell.execute_reply.started":"2022-12-13T11:51:31.290842Z","shell.execute_reply":"2022-12-13T11:51:31.452861Z"},"trusted":true},"execution_count":216,"outputs":[{"name":"stdout","text":"0    X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥...\n1    G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g...\n2    Th·ªùi ti·∫øt l·∫°nh nh∆∞ n√†y, c·∫£ nh√† r·ªß nhau ƒë·∫øn leg...\n3    Em c√≥ ƒë·ªçc review th·∫•y mng b·∫£o tr√† s·ªØa n∆∞·ªõng ƒë·ªÅ...\n4    ƒê·ªì ƒÉn r·∫•t ngon, nh√† h√†ng c≈©ng r·∫•t ƒë·∫πp, t·∫•t c·∫£ ...\n5    ƒê·ªì ƒÉn ngon, ƒë·∫∑t qua now shop ƒë·ªÉ k c·∫©n th·∫≠n b·ªã ...\n6    Nh√† h√†ng y√™u th√≠ch c·ªßa m√¨nh ƒë√¢y n√®! ƒê·∫øn ƒë√¢y m√¨...\n7    üî∏V·ªã tr√≠: m·∫∑t ƒë∆∞·ªùng Trung Y√™n r·∫•t d·ªÖ t√¨m, m·ªôt d...\n8    M√¨nh ƒë√£ ƒÉn t·∫°i ƒë√¢y v√† r·∫•t ngon,\\r\\nChu·∫©n v·ªã ph...\n9    Th·ªãt m·ªÅm, s·ªët ngon, d∆∞a g√≥p ƒÉn c√πng ƒë·ª° ng√°n\\r\\...\nName: Comment, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"crawled_data = pd.read_csv(\"/kaggle/input/test-crawl/crawler_1567_comments.csv\")\nprint(crawled_data['Comment'][0:10])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:51:31.455059Z","iopub.execute_input":"2022-12-13T11:51:31.455343Z","iopub.status.idle":"2022-12-13T11:51:31.486154Z","shell.execute_reply.started":"2022-12-13T11:51:31.455316Z","shell.execute_reply":"2022-12-13T11:51:31.485116Z"},"trusted":true},"execution_count":217,"outputs":[{"name":"stdout","text":"0    M√¨nh v·ª´a th·ª≠ tr∆∞a nay. ƒêi·ªÉm c·ªông ƒë·∫ßu ti√™n l√† b...\n1    Tr√† t√°o 35k\\nCookie socola 38k \\nN∆∞·ªõc ·ªü ƒë√¢y b√¨...\n2    Qu√° tr∆∞a ƒë·ªãnh ƒëi th·ª≠ Ph·ªü Th√¨n ·ªü L√≤ ƒê√∫c c∆°, nh∆∞...\n3    B√¨nh th∆∞·ªùng ko hay ƒÉn ph·ªü L√Ω qu·ªëc s∆∞ ƒë√¢u nh∆∞ng...\n4    C√≥ c√¥ quen cho vƒÉn ph√≤ng m√¨nh voucher gi·∫£m gi√°...\n5    Qu√° ngon v√† r·∫ª cho m·ªôt cu·ªôc t√¨nh ch·ªâ 45k ch·ªó n...\n6    Tr∆∞·ªõc ·ªü g·∫ßn n√™n ƒÉn ·ªü ƒë√¢y su·ªët. Ngay ƒë·ªëi di·ªán t...\n7    Tr∆∞·ªõc ƒëi qua khu BK th√¨ th·∫•y qu√°n n√™n b·ªçn m√¨nh...\n8    N√≥i chung l√† ngon nh∆∞ng m·∫•y b·∫°n ƒëi ƒÉn l·∫ßn ƒë·∫ßu ...\n9    Tr·ªùi oi oi th√®m u·ªëng Smoothie th√¨ r·∫Ω qua Nguy·ªÖ...\nName: Comment, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130,"referenced_widgets":["66a4baa794ce43de807650851ab0bb21","45f1b0212e954b17ad45bd644f2156d4","0c5886c49a114b86b9fbc3345503cff6","287a91fc255f4de5a7de1d27dcfce619","ed27683d14034cc1aac02143a2183101","e687c5c54d324dd987c1a92be85ff1e6","2097eca8a6604d108e03528244efadac","c55e536b868141ba8163a101a61d320e","40cf64a08a6f48249094e3f7e9b73f18","ab52c6fccb0e48049c256b7467f2604a","938cf653cb9044e191dfb0904135c75a","f548078d7dc14acab9d98e41d3f635a8","4f02e8c1b65b4385a13c73a993fe2524","f91ca80574eb4851bac2ad7f327f777e","a1797f7fddde43b197b066e16ef80529","983e1e7ae73948b6ab8ae4bff150f8ac","c5751619e4df4e0ea474b2ea5a745c32","a84de470cfa44f9896cd7572bcb4dd94","39ec0e1c6f0f40fa906135f4e387abaf","f61889b098bc46f3a70a30707f5391c2","f038db81cac24512b447785c4328fb6b","8c9711a1696c4c1ea2e4f2f9738154dc","982977287755416db422bd4cd0310b33","d2d19092a3804a228d6a1dabde7f6fdd","73f44d88a54a48738ae8aac670fa4b43","0799c717625c4587bf2fd918c8b07dd0","a887ad0607f54f4eb91da36ba8005b53","a87986eb716c4b0fb25943399597fabf","a723b5e5b4a54881aa53eefe4d4299d1","d7130a6ea9434b2ea816a65277f494e3","d62182b941e646d89407282009108d95","4c681e9e6aa4469a87a16c14168421c9","7fc542de9a9f4268a065d6adf96cb927"]},"id":"Nat8MjW2L8ki","outputId":"d8811f44-01b2-4c22-9694-8371117d1eb2","execution":{"iopub.status.busy":"2022-12-13T11:51:31.488207Z","iopub.execute_input":"2022-12-13T11:51:31.488654Z","iopub.status.idle":"2022-12-13T11:51:34.360919Z","shell.execute_reply.started":"2022-12-13T11:51:31.488617Z","shell.execute_reply":"2022-12-13T11:51:34.359933Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"len(tokenizer.get_vocab())","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:51:34.362203Z","iopub.execute_input":"2022-12-13T11:51:34.363211Z","iopub.status.idle":"2022-12-13T11:51:34.377600Z","shell.execute_reply.started":"2022-12-13T11:51:34.363173Z","shell.execute_reply":"2022-12-13T11:51:34.376680Z"},"trusted":true},"execution_count":219,"outputs":[{"execution_count":219,"output_type":"execute_result","data":{"text/plain":"64001"},"metadata":{}}]},{"cell_type":"code","source":"corpus = []\nfor tmp in zip(data[\"Comment\"], data[\"Rating\"]):\n  sent, lb = tmp\n  label = 1\n  if lb < 6.0:\n    label = 0\n  corpus.append((str(sent), label))\n#   if(float(lb) == 1):\n#     corpus.append((sent, 1))\n#   if float(lb) == 0:\n#     corpus.append((sent, 0))\nprint(corpus[0])\nprint(len(corpus))\n\n# for tmp in zip(crawled_data[\"Comment\"], crawled_data[\"Rating\"]):\n#   sent, lb = tmp\n#   label = 1\n#   if lb < 6.0:\n#     label = 0\n#   corpus.append((str(sent), label))\n# #   if(float(lb) == 1):\n# #     corpus.append((sent, 1))\n# #   if float(lb) == 0:\n# #     corpus.append((sent, 0))\n# print(corpus[0])\n# print(len(corpus))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSXygf9yLdiL","outputId":"0aa48b93-33b6-448f-b908-74c06eaa8f59","execution":{"iopub.status.busy":"2022-12-13T11:52:22.333369Z","iopub.execute_input":"2022-12-13T11:52:22.333744Z","iopub.status.idle":"2022-12-13T11:52:22.357942Z","shell.execute_reply.started":"2022-12-13T11:52:22.333715Z","shell.execute_reply":"2022-12-13T11:52:22.356807Z"},"trusted":true},"execution_count":220,"outputs":[{"name":"stdout","text":"('X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥ng r·∫•t th√≠ch', 1)\n9071\n","output_type":"stream"}]},{"cell_type":"code","source":"def segment(corpus):\n  ct = []\n  lb = []\n  for content, label in corpus:\n#     if(type(content) == str):\n      ct.append(content)\n      lb.append(label)\n  return ct, lb","metadata":{"id":"3RdqL7LGLxkq","execution":{"iopub.status.busy":"2022-12-13T11:52:24.828198Z","iopub.execute_input":"2022-12-13T11:52:24.828755Z","iopub.status.idle":"2022-12-13T11:52:24.834966Z","shell.execute_reply.started":"2022-12-13T11:52:24.828706Z","shell.execute_reply":"2022-12-13T11:52:24.833884Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"sents, labels = segment(corpus)\nprint(sents[0], \" \", labels[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dn94zZbGMk9I","outputId":"fe64cad2-f0d0-4070-82e3-71423b446000","execution":{"iopub.status.busy":"2022-12-13T11:52:26.263501Z","iopub.execute_input":"2022-12-13T11:52:26.263952Z","iopub.status.idle":"2022-12-13T11:52:26.273498Z","shell.execute_reply.started":"2022-12-13T11:52:26.263907Z","shell.execute_reply":"2022-12-13T11:52:26.272475Z"},"trusted":true},"execution_count":222,"outputs":[{"name":"stdout","text":"X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥ng r·∫•t th√≠ch   1\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(sents))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VuzYD8g92CJ0","outputId":"437a60e2-e891-4a3b-9650-3a7623bc8179","execution":{"iopub.status.busy":"2022-12-13T11:52:28.741803Z","iopub.execute_input":"2022-12-13T11:52:28.742193Z","iopub.status.idle":"2022-12-13T11:52:28.749114Z","shell.execute_reply.started":"2022-12-13T11:52:28.742159Z","shell.execute_reply":"2022-12-13T11:52:28.747747Z"},"trusted":true},"execution_count":224,"outputs":[{"name":"stdout","text":"9071\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np","metadata":{"id":"y4VkGCJlN9lb","execution":{"iopub.status.busy":"2022-12-13T11:52:30.599689Z","iopub.execute_input":"2022-12-13T11:52:30.600288Z","iopub.status.idle":"2022-12-13T11:52:30.604925Z","shell.execute_reply.started":"2022-12-13T11:52:30.600250Z","shell.execute_reply":"2022-12-13T11:52:30.603888Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed_value):\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = True\n\nseed_everything(86)","metadata":{"id":"iJ5dYHWFN7Mz","execution":{"iopub.status.busy":"2022-12-13T11:52:31.770302Z","iopub.execute_input":"2022-12-13T11:52:31.770650Z","iopub.status.idle":"2022-12-13T11:52:31.777034Z","shell.execute_reply.started":"2022-12-13T11:52:31.770620Z","shell.execute_reply":"2022-12-13T11:52:31.775873Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"k = 0\nfor sent in sents:\n  if(sent.find(\"b√¨nh lu·∫≠n kh√¥ng x√°c ƒë·ªãnh\") != -1):\n    print(sent)\n    k+=1\nk","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQHimiVBQLan","outputId":"279ef0ce-5310-4fcb-bcf2-1de77b98626b","execution":{"iopub.status.busy":"2022-12-13T11:52:33.382748Z","iopub.execute_input":"2022-12-13T11:52:33.383811Z","iopub.status.idle":"2022-12-13T11:52:33.400090Z","shell.execute_reply.started":"2022-12-13T11:52:33.383771Z","shell.execute_reply":"2022-12-13T11:52:33.398984Z"},"trusted":true},"execution_count":227,"outputs":[{"execution_count":227,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"s1 = u'√Ä√Å√Ç√É√à√â√ä√å√ç√í√ì√î√ï√ô√ö√ù√†√°√¢√£√®√©√™√¨√≠√≤√≥√¥√µ√π√∫√ΩƒÇƒÉƒêƒëƒ®ƒ©≈®≈©∆†∆°∆Ø∆∞·∫†·∫°·∫¢·∫£·∫§·∫•·∫¶·∫ß·∫®·∫©·∫™·∫´·∫¨·∫≠·∫Æ·∫Ø·∫∞·∫±·∫≤·∫≥·∫¥·∫µ·∫∂·∫∑·∫∏·∫π·∫∫·∫ª·∫º·∫Ω·∫æ·∫ø·ªÄ·ªÅ·ªÇ·ªÉ·ªÑ·ªÖ·ªÜ·ªá·ªà·ªâ·ªä·ªã·ªå·ªç·ªé·ªè·ªê·ªë·ªí·ªì·ªî·ªï·ªñ·ªó·ªò·ªô·ªö·ªõ·ªú·ªù·ªû·ªü·ª†·ª°·ª¢·ª£·ª§·ª•·ª¶·ªß·ª®·ª©·ª™·ª´·ª¨·ª≠·ªÆ·ªØ·ª∞·ª±·ª≤·ª≥·ª¥·ªµ·ª∂·ª∑·ª∏·ªπ'\ndef check_spell(string):\n  for c in string :\n    if c in s1:\n      \n      return True\n  return False\n\nchecked_sents = []\n\nfor sent in sents:\n  if(not check_spell(sent)):\n    checked_sents.append(sent)\n\nprint(len(checked_sents))","metadata":{"id":"545NfWR68QzR","execution":{"iopub.status.busy":"2022-12-13T11:52:34.632020Z","iopub.execute_input":"2022-12-13T11:52:34.632376Z","iopub.status.idle":"2022-12-13T11:52:34.646590Z","shell.execute_reply.started":"2022-12-13T11:52:34.632347Z","shell.execute_reply":"2022-12-13T11:52:34.645502Z"},"trusted":true},"execution_count":228,"outputs":[{"name":"stdout","text":"86\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(10):\n  print(i, checked_sents[i])","metadata":{"id":"twyscBxu8mcO","execution":{"iopub.status.busy":"2022-12-13T11:52:36.890089Z","iopub.execute_input":"2022-12-13T11:52:36.890447Z","iopub.status.idle":"2022-12-13T11:52:36.896835Z","shell.execute_reply.started":"2022-12-13T11:52:36.890416Z","shell.execute_reply":"2022-12-13T11:52:36.895604Z"},"trusted":true},"execution_count":229,"outputs":[{"name":"stdout","text":"0 1st time came here to try and really satisfy with the foods. Fast and nice services from staffs. \nI also love the design of the restaurant, make it so comfortable and relax for people to have meal here.\n1 I personally love indian food and Tandoor Resteraunt offers some really great indian dishes. I decided to go with Gobi Pakora for my starter which came with a mint chutney and spicy veggie chutney (I wasn't too sure what was in it) It's basically cauliflour fritters and it was quite good I can honestly say.\nFor my main I decided on Chicken Biryani which is flavored rice with spiced chicken. Awesome.\n\nHowever the lighting on the second floor was not too good but it was alright.\n2 Abc\n3 Nice place to enjoy and relax. Foods are very delicious and fresh, especially salats. I'm very impressed in cocktails. All staffs are so great and always smile. In here, i have a feeling that i am travelling in Paris. If i have chance to come back Hanoi, i sure come back Ciel ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§\n4 Very decent and nicely decorated restaurant. Service is excellence (except the billing part was slow) \nOnce the crowd come in at 8pm, the service is a little slower. \n\nFirst we order aperitif - follow by on the house appetiser which I don't really appreciate the Duck Meat with Banana. We order lamb rack for main and it was okay. However the duck breast meat - the sauce, the sides do not seems to gel with each other. \n\nDisappointed.\n5 The cafe serves food from around 10.30 to 2pm, beat to go around 11.30 when its not so busy. \nThe place is clean and nicely decorated. The selection of food is great, clearly high quality and very well prepared. \nVND30,000 for a plate of rice and your choice of four sides. \nIve been coming here for almost three years now - i used to live close by and still come back a lot. \nMinh (the owner) speaks really good English and is very friendly. Its a family run thing, and theyre all diamond people. \nAlso the drinks are noticably cheaper than in other cafes. \nHighly recommended.\n6 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n7 Finally I found an authentic Korean BBQ restaurant just right in my area. The owner is Korean. The staffs are helpful. The price is a bit high but the atmosphere, the flavor and quality of food totally deserve that. I like their pans also, which have a special surface to prevent the meat from being too greasy and burned. \nDefinitely my fave spot!\n8 „Éè„Éé„Ç§ÊúÄÁµÇÊó•„ÅÆÂ§ú„Å™„ÅÆ„ÅßÁ∂∫È∫ó„ÅßÁæéÂë≥„Åó„ÅÑ„É¨„Çπ„Éà„É©„É≥„ÅßÔºÅ„Å®„Ç≥„ÉÅ„É©„Å´„ÄÇ\nÂâçÂõûÂìÅÂàá„Çå„Åó„Å¶„ÅÑ„ÅüË±ö„ÅÆËßíÁÖÆ„ÅåÈ£ü„Åπ„Çå„Å¶Â¨â„Åó„ÅÑüòÜ\nüéÅ„ÅÆ„Çà„ÅÜ„Å™Áõõ„Çä‰ªò„Åë„ÇÇÁ¥†ÊïµÔºÅÊèö„Åí„Éç„ÇÆ„Åå„Åü„Å£„Å∑„Çä„ÅÆ„Å£„Åü„Çπ„ÉÜ„Ç£„ÉÉ„Ç≠„Éº„É©„Ç§„Çπ„Å®„Çª„ÉÉ„Éà„Å´„Å™„Å£„Å¶„ÅÑ„Å¶„ÅîÈ£Ø„Å®‰∏ÄÁ∑í„Å´È£ü„Åπ„Çã„Å®„Åæ„ÅüÁæéÂë≥„Åó„ÅÑ„Äú„ÄÇ\nÂâçÂõû„ÇÇÈ†º„Çì„Å†„ÉÅ„Ç≠„É≥„ÅÆ„Ç∞„É™„É´„Å®ËåÑÂ≠ê„ÅÆ„Ç∞„É™„É´„ÇÇÂÆâÂÆö„ÅÆÁæéÂë≥„Åó„ÅïÔºÅËåÑÂ≠ê„ÅÆÂë≥‰ªò„Åë„Åå‰ª•Ââç„Çà„ÇäÂ∞ë„ÅóÁîòÂë≥„ÅåÂº∑„ÅèÊÑü„Åò„Åæ„Åó„Åü„ÄÅ„ÉÅ„Ç≠„É≥„Å´Ê∑ª„Åà„Å¶„ÅÇ„Çã„Ç≥„Ç≥„Éä„ÉÉ„ÉÑÈ¢®Âë≥„ÅÆÊèö„Åí„Åübanh bao„ÇÇÂ§ßÂ•Ω„ÅçÔºÅ\n‰ªäÂõû„ÅÆÊóÖË°å„ÅßÈçã„ÇíÈ£ü„Åπ„Å¶„Å™„Åã„Å£„Åü„ÅÆ„Åß„ÄÅÊµ∑ÈÆÆÈçã„ÇÇ„Ç™„Éº„ÉÄ„Éº„Åó„Åæ„Åó„Åü„ÄÇ„Éè„Éº„Éï„Çµ„Ç§„Ç∫„Åß„Åì„ÅÆ„Éú„É™„É•„Éº„É†„Åß„Åôüò≥\nÂÜôÁúü„Å´ÂÜô„Å£„Å¶„Åæ„Åõ„Çì„ÅåÈçã„Å´„ÅØ„Åü„Å£„Å∑„Çä„ÅÆ„Éñ„É≥„ÇÇ‰ªò„Åç„Åæ„Åô„ÄÇ„Éî„É™Ëæõ„Åß„É¨„É¢„É≥„Ç∞„É©„Çπ„ÅåÂäπ„ÅÑ„Å¶„ÅÑ„Åü„ÅÆ„Åß„Éà„É†„É§„É†„ÇØ„É≥„ÇíÂÑ™„Åó„Åè„Åó„Åü„Çà„ÅÜ„Å™Âë≥„Åß„Åó„Åü„ÄÇ\n„Éë„Çπ„Çø„Éº„Éñ„É™„É•„Éº„Ç§„É≥„Ç∞„ÅÆ„ÇØ„É©„Éï„Éà„Éì„Éº„É´„Åß‰πæÊùØ„Åó„Å¶„ÄÅ„Åù„ÅÆÂæå„ÅØ„Éú„Éà„É´„ÅÆÁôΩ„ÉØ„Ç§„É≥„Çí„Ç™„Éº„ÉÄ„Éº„Åó„Åæ„Åó„Åü„ÄÅ\n9 Ngon\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_sents, valid_sents, train_labels, valid_labels = train_test_split(sents, labels, test_size=0.2)\nprint(len(train_sents), \" \", len(valid_sents))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bXi4oeeMzIa","outputId":"721b0269-5571-490c-87a5-5b480f4a476a","execution":{"iopub.status.busy":"2022-12-13T11:52:46.022070Z","iopub.execute_input":"2022-12-13T11:52:46.022945Z","iopub.status.idle":"2022-12-13T11:52:46.034650Z","shell.execute_reply.started":"2022-12-13T11:52:46.022905Z","shell.execute_reply":"2022-12-13T11:52:46.033532Z"},"trusted":true},"execution_count":231,"outputs":[{"name":"stdout","text":"7256   1815\n","output_type":"stream"}]},{"cell_type":"code","source":"tmp_sents = []\ntmp_labels = []\nfor tmp in zip(crawled_data[\"Comment\"], crawled_data[\"Rating\"]):\n  sent, lb = tmp\n  label = 1\n  if lb < 6.0:\n    label = 0\n  \n  tmp_sents.append(str(sent))\n  tmp_labels.append(label)\n#   if(float(lb) == 1):\n#     corpus.append((sent, 1))\n#   if float(lb) == 0:\n#     corpus.append((sent, 0))\nprint(tmp_sents[0])\nprint(len(tmp_sents))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:54:37.345430Z","iopub.execute_input":"2022-12-13T11:54:37.346033Z","iopub.status.idle":"2022-12-13T11:54:37.358688Z","shell.execute_reply.started":"2022-12-13T11:54:37.345987Z","shell.execute_reply":"2022-12-13T11:54:37.357526Z"},"trusted":true},"execution_count":232,"outputs":[{"name":"stdout","text":"M√¨nh v·ª´a th·ª≠ tr∆∞a nay. ƒêi·ªÉm c·ªông ƒë·∫ßu ti√™n l√† b√°t b√∫n ƒë·∫ßy ƒë·∫∑n, r·∫•t nhi·ªÅu c√° r√°n, ch·∫£ c√°, ch·∫£ t√¥m. B·ªÅ b·ªÅ c≈©ng to v√† ch·∫Øc th·ªãt h∆°n c√°c qu√°n kh√°c. Gi√° c·∫£ r·∫•t h·ª£p l√Ω. 40k/b√°t b√∫n h·∫£i s·∫£n. Tuy nhi√™n n∆∞·ªõc d√πng ch∆∞a ƒë·∫≠m ƒë√† l·∫Øm. Nh∆∞ng c√≥ th·ªÉ coi l√† t·∫°m ·ªïn, v√† g·∫ßn c∆° quan m√¨nh. S·∫Ω quay l·∫°i\n1567\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sents = train_sents + tmp_sents\ntrain_labels = train_labels + tmp_labels","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:55:14.034512Z","iopub.execute_input":"2022-12-13T11:55:14.034986Z","iopub.status.idle":"2022-12-13T11:55:14.041690Z","shell.execute_reply.started":"2022-12-13T11:55:14.034941Z","shell.execute_reply":"2022-12-13T11:55:14.040658Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"code","source":"len(train_sents)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:55:33.133839Z","iopub.execute_input":"2022-12-13T11:55:33.134189Z","iopub.status.idle":"2022-12-13T11:55:33.142918Z","shell.execute_reply.started":"2022-12-13T11:55:33.134158Z","shell.execute_reply":"2022-12-13T11:55:33.141780Z"},"trusted":true},"execution_count":235,"outputs":[{"execution_count":235,"output_type":"execute_result","data":{"text/plain":"8823"},"metadata":{}}]},{"cell_type":"code","source":"sum_1 = 0\nsum_2 = 0\nfor label in train_labels:\n  if label == 0:\n    sum_1 += 1\n  else:\n    sum_2 += 1\nprint(sum_1, \" \", sum_2)\nsum_1 = 0\nsum_2 = 0\nfor label in valid_labels:\n  if label == 0:\n    sum_1 += 1\n  else:\n    sum_2 += 1\nprint(sum_1, sum_2)","metadata":{"id":"rv_KWb4F0fqC","execution":{"iopub.status.busy":"2022-12-13T11:55:35.013117Z","iopub.execute_input":"2022-12-13T11:55:35.013548Z","iopub.status.idle":"2022-12-13T11:55:35.029683Z","shell.execute_reply.started":"2022-12-13T11:55:35.013508Z","shell.execute_reply":"2022-12-13T11:55:35.028861Z"},"trusted":true},"execution_count":236,"outputs":[{"name":"stdout","text":"1890   6933\n379 1436\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_sents[0])\nprint( train_labels[0])","metadata":{"id":"xpz10lXbPLhi","execution":{"iopub.status.busy":"2022-12-13T11:55:37.035539Z","iopub.execute_input":"2022-12-13T11:55:37.036017Z","iopub.status.idle":"2022-12-13T11:55:37.045324Z","shell.execute_reply.started":"2022-12-13T11:55:37.035974Z","shell.execute_reply":"2022-12-13T11:55:37.044108Z"},"trusted":true},"execution_count":237,"outputs":[{"name":"stdout","text":"H∆°i bu·ªìn m·ªôt t√≠ l√† t·ªõ bi·∫øt qu√°n n√†y l·∫°i do m·ªôt anh b·∫°n ng∆∞·ªùi n∆∞·ªõc ngo√†i gi·ªõi thi·ªáu, c√≤n m√¨nh l√† ng∆∞·ªùi b√†n x·ª© l·∫°i kh√¥ng kh√°m ph√° ra :( Nh√¢n vi√™n ·ªü ƒë√¢y v√¥ c√πng th√¢n thi·ªán, b·∫Øn ti·∫øng Anh c·ª© ph·∫£i g·ªçi l√† t·∫±ng t·∫±ng lu√¥n ·∫•y, gi·ªõi thi·ªáu c√°c m√≥n chuy√™n nghi·ªáp th·∫≠t. M·ªói t·ªôi c√°i l√† qu√°n ƒë√¥ng kh√°ch n√™n ph·ª•c v·ª• h∆°i l√¢u t√≠, v·ªõi v·∫£ th·ªânh tho·∫£ng ƒë·∫øn b·ªã h·∫øt ch·ªó :( Foody x·∫øp qu√°n n√†y l√† cafe nh∆∞ng th·ª±c ch·∫•t l√† nh√† h√†ng, m√¨nh th·∫•y kh√°ch ƒë·∫øn ƒë√¢y ƒÉn nhi·ªÅu h∆°n l√† u·ªëng. H·ªç ph·ª•c v·ª• c·∫£ m√≥n Vi·ªát l·∫´n m√≥n √Çu nh∆∞ng m√≥n Vi·ªát c√≥ v·∫ª ngon h∆°n. B√∫n nem ·ªü ƒë√¢y ƒë∆∞·ª£c anh b·∫°n t·ªõ khen l·∫Øm, t·∫°i nh√¨n c√°i nem r·∫•t ƒë·∫πp, v√†ng ƒë·ªÅu ch·ª© kh√¥ng b·ªã lem nh∆∞ ·ªü nh√† m√¨nh. Nh√¢n nem c≈©ng ƒë·∫≠m ƒë√†, nhuy·ªÖn th·ªãt. N∆∞·ªõc ch·∫•m ng∆∞·ªùi ta pha c≈©ng kh√©o n·ªØa. N√≥i chung l√† v·ªõi c√°c b√°c t√¢y kh√¥ng th√≠ch ƒÉn v·ªâa h√® th√¨ ƒë·∫øn ƒë√¢y l√† chu·∫©n r·ªìi.\n1\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nfrom keras_preprocessing.sequence import pad_sequences\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom gensim.utils import simple_preprocess","metadata":{"id":"IN37KRu1AX9S","execution":{"iopub.status.busy":"2022-12-13T11:55:52.543680Z","iopub.execute_input":"2022-12-13T11:55:52.544405Z","iopub.status.idle":"2022-12-13T11:55:52.549678Z","shell.execute_reply.started":"2022-12-13T11:55:52.544366Z","shell.execute_reply":"2022-12-13T11:55:52.548298Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"pip install underthesea","metadata":{"id":"TJKwk4J2ZQp2","execution":{"iopub.status.busy":"2022-12-13T11:55:54.254513Z","iopub.execute_input":"2022-12-13T11:55:54.254902Z","iopub.status.idle":"2022-12-13T11:56:03.724690Z","shell.execute_reply.started":"2022-12-13T11:55:54.254868Z","shell.execute_reply":"2022-12-13T11:56:03.723135Z"},"trusted":true},"execution_count":240,"outputs":[{"name":"stdout","text":"Requirement already satisfied: underthesea in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: underthesea-core==0.0.5a2 in /opt/conda/lib/python3.7/site-packages (from underthesea) (0.0.5a2)\nRequirement already satisfied: python-crfsuite>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from underthesea) (0.9.8)\nRequirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.7/site-packages (from underthesea) (8.0.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from underthesea) (2.28.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from underthesea) (6.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from underthesea) (3.7)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from underthesea) (4.64.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click>=6.0->underthesea) (4.13.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->underthesea) (2021.11.10)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.7.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (3.1.0)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.21.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (3.8.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (4.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"sw = []\nwith open(\"/kaggle/input/vn-stopword/vn_stopword.txt\", encoding='utf-8') as f:\n    lines = f.readlines()\nfor line in lines:\n    sw.append(line.replace(\"\\n\",\"\"))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:56:03.727386Z","iopub.execute_input":"2022-12-13T11:56:03.727795Z","iopub.status.idle":"2022-12-13T11:56:03.741046Z","shell.execute_reply.started":"2022-12-13T11:56:03.727756Z","shell.execute_reply":"2022-12-13T11:56:03.740094Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"from underthesea import text_normalize","metadata":{"id":"nhv0LlrBZ9Ey","execution":{"iopub.status.busy":"2022-12-13T11:56:03.742604Z","iopub.execute_input":"2022-12-13T11:56:03.742972Z","iopub.status.idle":"2022-12-13T11:56:03.749402Z","shell.execute_reply.started":"2022-12-13T11:56:03.742938Z","shell.execute_reply":"2022-12-13T11:56:03.748460Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"text_normalize(\"qu√¢n   kh√¥ngƒë∆∞·ª£c   th√¥ng minh l·∫Øm!\")","metadata":{"id":"9p-G-H1XROnY","execution":{"iopub.status.busy":"2022-12-13T11:56:03.751940Z","iopub.execute_input":"2022-12-13T11:56:03.752291Z","iopub.status.idle":"2022-12-13T11:56:03.761685Z","shell.execute_reply.started":"2022-12-13T11:56:03.752257Z","shell.execute_reply":"2022-12-13T11:56:03.760660Z"},"trusted":true},"execution_count":243,"outputs":[{"execution_count":243,"output_type":"execute_result","data":{"text/plain":"'qu√¢n kh√¥ngƒë∆∞·ª£c th√¥ng minh l·∫Øm !'"},"metadata":{}}]},{"cell_type":"code","source":"def purify(text):\n  vietnamese_characters = \"a-zA-Z0-9√Ä√Å√Ç√É√à√â√ä√å√ç√í√ì√î√ï√ô√öƒÇƒêƒ®≈®∆†√†√°√¢√£√®√©√™√¨√≠√≤√≥√¥√µ√π√∫ƒÉƒëƒ©≈©∆°∆ØƒÇ·∫†·∫¢·∫§·∫¶·∫®·∫™·∫¨·∫Æ·∫∞·∫≤·∫¥·∫∂·∫∏·∫∫·∫º·ªÄ·ªÄ·ªÇ·∫æ∆∞ƒÉ·∫°·∫£·∫•·∫ß·∫©·∫´·∫≠·∫Ø·∫±·∫≥·∫µ·∫∑·∫π·∫ª·∫Ω·ªÅ·ªÅ·ªÉ·∫ø·ªÑ·ªÜ·ªà·ªä·ªå·ªé·ªê·ªí·ªî·ªñ·ªò·ªö·ªú·ªû·ª†·ª¢·ª§·ª¶·ª®·ª™·ªÖ·ªá·ªâ·ªã·ªç·ªè·ªë·ªì·ªï·ªó·ªô·ªõ·ªù·ªü·ª°·ª£·ª•·ªß·ª©·ª´·ª¨·ªÆ·ª∞·ª≤·ª¥√ù·ª∂·ª∏·ª≠·ªØ·ª±·ª≥√Ω·ªµ·ª∑·ªπ\"\n  text = text.lower()\n  text = text.strip()\n  # text = \" \"+ text + \" \"\n  text = re.sub(\"[+]\", ' ', text) #all math-operating characters removed\n  text = re.sub(\" \\\\[a-z]\", ' ', text)# all newline and slash characters removed\n  \n  text = re.sub('[^' + vietnamese_characters + ']+', ' ', text) # all special characters removed\n  text = re.sub(\"([A-Za-z]+[0-9]+)|([0-9]+[A-Za-z]+)\", \" \", text) #150g\n  text = re.sub(\"[0-9]{3,}\", \" \", text) #all too long numbers (>= 3 digits) removed\n  text = re.sub(r'(\\D)\\1{2,}', r'\\1', text) # all consecutive duplicated characters removed\n  text = text.strip()\n\n  #all single-charater words removed\n  tmp_text = []\n  for x in text.split(\" \"):\n    if(len(x) > 1):\n      tmp_text.append(x)\n  \n  text = \" \".join(tmp_text)\n  text = text_normalize(text)\n  return text\n\n# abc = \"M√¨nh order qua Now v·ªõi gi√° 55k (x√¥i + tr√† qu·∫•t 10k, m√¨nh ch·ªâ √°p ƒëc code freeship) m√† nh√¨n c√≤n t·ªá h∆°n h·ªôp x√¥i 20k b√¨nh th∆∞·ªùng! Kh√¥ng bi·∫øt qu√°n t·ªën ti·ªÅn thu√™ m·∫∑t b·∫±ng hay sao m√† l·∫°i cho kh√°ch c√≥ t·∫πo x√¥i + √≠t ru·ªëc t√©p + g√† x√†o n·∫•m m√† th·∫•y ƒë∆∞·ª£c m·∫•y th·ªãt m·∫•y n·∫•m kh√¥ng? V·ªã ·ªïn, h·ªôp s·∫°ch s·∫Ω, giao h√†ng r·∫•t nhanh nh∆∞ng nh·∫≠n 1 h·ªôp x√¥i ƒë·∫Øt x2 m√† ch·ªâ ƒë∆∞·ª£c t·ª´ng n√†y th√¨ qu√° th·∫•t v·ªçng, ch∆∞a k·ªÉ tr√† qu·∫•t u·ªëng v·ªã nh∆∞ c√≥ x√† ph√≤ng r·∫•t gh√™\"\n# abc = \" ch·∫£ bao gi·ªù quan t√¢m m·∫•y c√°i ki·ªÉu b√¨nh lu·∫≠n nh∆∞ n√†y nh∆∞ng ph·∫£i ch·∫•m b√∫t th√°i ƒë·ªô 10 ƒë ƒë·ªì ƒÉn 9 ƒë n√≥i chung l√† kh√° ·ªïn\"\nabc = \"ÂâçÂõû„ÇÇÈ†º„Çì„Å†„ÉÅ„Ç≠„É≥„ÅÆ„Ç∞„É™„É´„Å®ËåÑÂ≠ê„ÅÆ„Ç∞„É™„É´„ÇÇÂÆâÂÆö„ÅÆÁæéÂë≥„Åó„ÅïÔºÅËåÑÂ≠ê„ÅÆÂë≥‰ªò„Åë„Åå‰ª•Ââç„Çà„ÇäÂ∞ë„ÅóÁîòÂë≥„ÅåÂº∑„ÅèÊÑü„Åò„Åæ„Åó„Åü„ÄÅ„ÉÅ„Ç≠„É≥„Å´Ê∑ª„Åà„Å¶„ÅÇ„Çã„Ç≥„Ç≥„Éä„ÉÉ„ÉÑÈ¢®Âë≥„ÅÆÊèö„Åí„Åü„ÇÇÂ§ßÂ•Ω„ÅçÔºÅ\"\nabc = \"Ngoooooooooooooonnnnnnnnnnnnnnnnnnnnnnnnn nnnnnnnnnnnnnnnnnnnhhhhhhhhhhhhhhhhhheeeeeeeeeeeeeeeee\"\n# abc = \"a b c\"\nabc = purify(abc)\nprint(abc)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ls93vtKZuuMv","outputId":"f929925b-7e91-413b-ec6c-4dafc63c0547","execution":{"iopub.status.busy":"2022-12-13T11:56:04.806364Z","iopub.execute_input":"2022-12-13T11:56:04.806754Z","iopub.status.idle":"2022-12-13T11:56:04.818377Z","shell.execute_reply.started":"2022-12-13T11:56:04.806711Z","shell.execute_reply":"2022-12-13T11:56:04.817261Z"},"trusted":true},"execution_count":244,"outputs":[{"name":"stdout","text":"ngon nhe\n","output_type":"stream"}]},{"cell_type":"code","source":"#@title\nfrom underthesea import word_tokenize","metadata":{"cellView":"form","id":"azJmoZkv4nzq","execution":{"iopub.status.busy":"2022-12-13T11:56:06.373073Z","iopub.execute_input":"2022-12-13T11:56:06.373986Z","iopub.status.idle":"2022-12-13T11:56:06.379171Z","shell.execute_reply.started":"2022-12-13T11:56:06.373939Z","shell.execute_reply":"2022-12-13T11:56:06.377973Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":"def preprocess(purified_sents, max_len=None):\n  preprocessed_sents = []\n  for purified_text in purified_sents:\n\n    #remove all 0-long sents\n    # words = text.split(\" \")\n    # if(len(words) <= 0):\n    #   continue\n\n#     preprocessed by word_tokenize of underthesea\n    text = word_tokenize(purified_text, format = \"text\")\n    tmp_text = text\n    \n#     replace stopword by <pad>\n#     words = tmp_text.split(\" \")\n#     for i, word in enumerate(words):\n#         if word in sw:\n#             words[i] = '<pad>'\n#     tmp_text = \" \".join(words)\n\n    #preprocessed by rdrsegmenter of vncorenlp and bpe\n    # text = rdrsegmenter.word_segment(purified_text)\n    # text = bpe.encode(text)\n    # for x in text:\n    #   print(x)\n    # tmp_text =' '.join([' '.join(x) for x in text])\n\n    # preprocessed by py_rdrsegmenter of py_vncorenlp\n#     text = py_rdrsegmenter.word_segment(purified_text)\n#     tmp_text = \" \".join(text)\n\n    if(max_len is not None):\n      words = tmp_text.split(\" \")\n      if(len(words) > max_len):\n        words = words[0:max_len]\n      tmp_text = \" \".join(words)\n      \n    preprocessed_sents.append(tmp_text)\n  return preprocessed_sents\n","metadata":{"id":"Dcyb4YLMF8vk","execution":{"iopub.status.busy":"2022-12-13T11:56:07.374462Z","iopub.execute_input":"2022-12-13T11:56:07.374844Z","iopub.status.idle":"2022-12-13T11:56:07.382012Z","shell.execute_reply.started":"2022-12-13T11:56:07.374793Z","shell.execute_reply":"2022-12-13T11:56:07.380927Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"def encode_plus(preprocessed_sents,max_len=256):\n  encoded_sents = []\n  masks = []\n  for sent in preprocessed_sents:\n    sent_info = tokenizer.encode_plus(sent,\n                                      padding='max_length',\n                                      truncation=True,\n                                      add_special_tokens=True,\n                                      max_length = max_len,\n                                      return_token_type_ids=False,\n                                      return_attention_mask=True,\n                                     return_tensors='np')\n    encoded_sent = sent_info['input_ids'].flatten()\n    mask =  sent_info['attention_mask'].flatten()\n    encoded_sents.append(encoded_sent)\n    masks.append(mask)\n  return encoded_sents, masks","metadata":{"id":"eExpagxBE_p-","execution":{"iopub.status.busy":"2022-12-13T11:56:09.318792Z","iopub.execute_input":"2022-12-13T11:56:09.319283Z","iopub.status.idle":"2022-12-13T11:56:09.331416Z","shell.execute_reply.started":"2022-12-13T11:56:09.319229Z","shell.execute_reply":"2022-12-13T11:56:09.330306Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"markdown","source":"en","metadata":{"id":"MZqgnr2zmkPS"}},{"cell_type":"code","source":"train_purified_sents = [purify(train_sent) for train_sent in train_sents]\nvalid_purified_sents = [purify(valid_sent) for valid_sent in valid_sents]","metadata":{"id":"cujZj6BZzUhx","execution":{"iopub.status.busy":"2022-12-13T11:56:11.758979Z","iopub.execute_input":"2022-12-13T11:56:11.759379Z","iopub.status.idle":"2022-12-13T11:56:22.743732Z","shell.execute_reply.started":"2022-12-13T11:56:11.759344Z","shell.execute_reply":"2022-12-13T11:56:22.742743Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"# for i, sent in enumerate(train_purified_sents):\n#   if(sent == \"\"):\n#     train_purified_sents[i] = \"b√¨nh lu·∫≠n kh√¥ng x√°c ƒë·ªãnh\"","metadata":{"id":"io-jBgbG3DRp","execution":{"iopub.status.busy":"2022-12-13T08:24:18.734492Z","iopub.execute_input":"2022-12-13T08:24:18.734855Z","iopub.status.idle":"2022-12-13T08:24:18.742608Z","shell.execute_reply.started":"2022-12-13T08:24:18.734819Z","shell.execute_reply":"2022-12-13T08:24:18.741222Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# for i, sent in enumerate(valid_purified_sents):\n#   if(sent == \"\"):\n#     valid_purified_sents[i] = \"b√¨nh lu·∫≠n kh√¥ng x√°c ƒë·ªãnh\"","metadata":{"id":"NZOzWXEUSFJf","execution":{"iopub.status.busy":"2022-12-13T10:29:28.080426Z","iopub.execute_input":"2022-12-13T10:29:28.082607Z","iopub.status.idle":"2022-12-13T10:29:28.089041Z","shell.execute_reply.started":"2022-12-13T10:29:28.082559Z","shell.execute_reply":"2022-12-13T10:29:28.087676Z"},"trusted":true},"execution_count":249,"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_22/1899538612.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if(sent == \"\"):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"],"ename":"IndentationError","evalue":"unexpected indent (1899538612.py, line 2)","output_type":"error"}]},{"cell_type":"code","source":"train_preprocessed_sents = preprocess(train_purified_sents)\nvalid_preprocessed_sents = preprocess(valid_purified_sents)","metadata":{"id":"yMA7wTyT3CJS","execution":{"iopub.status.busy":"2022-12-13T11:56:22.745893Z","iopub.execute_input":"2022-12-13T11:56:22.746393Z","iopub.status.idle":"2022-12-13T11:57:06.391729Z","shell.execute_reply.started":"2022-12-13T11:56:22.746355Z","shell.execute_reply":"2022-12-13T11:57:06.390643Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"print(valid_preprocessed_sents[535])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IC1rer1-qOJT","outputId":"60c28676-a285-4153-e16d-64a96b590547","execution":{"iopub.status.busy":"2022-12-13T11:57:06.393110Z","iopub.execute_input":"2022-12-13T11:57:06.393885Z","iopub.status.idle":"2022-12-13T11:57:06.400034Z","shell.execute_reply.started":"2022-12-13T11:57:06.393846Z","shell.execute_reply":"2022-12-13T11:57:06.398881Z"},"trusted":true},"execution_count":250,"outputs":[{"name":"stdout","text":"kh√° ·ªïn nh∆∞ng thi·∫øu n∆∞·ªõc_canh ph·ªü ƒÉn kh√¥ m·ªìm qu√°_tr·ªùi n·∫Øng th·∫ø n√†y nhai c∆°m kh√¥ sao n·ªïi g√≥p l·∫ßn sau ƒë·ª´ng l√†m m√¨nh that vong\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_ids, train_masks = encode_plus(train_preprocessed_sents, max_len=256)\nvalid_ids, valid_masks = encode_plus(valid_preprocessed_sents, max_len=256)","metadata":{"id":"QEbAswGLn9ka","execution":{"iopub.status.busy":"2022-12-13T11:57:06.402509Z","iopub.execute_input":"2022-12-13T11:57:06.402951Z","iopub.status.idle":"2022-12-13T11:57:12.525337Z","shell.execute_reply.started":"2022-12-13T11:57:06.402915Z","shell.execute_reply":"2022-12-13T11:57:12.524350Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"code","source":"import numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:57:12.526621Z","iopub.execute_input":"2022-12-13T11:57:12.526988Z","iopub.status.idle":"2022-12-13T11:57:12.532253Z","shell.execute_reply.started":"2022-12-13T11:57:12.526955Z","shell.execute_reply":"2022-12-13T11:57:12.531314Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntrain_inputs = torch.tensor(train_ids)\nvalid_inputs = torch.tensor(valid_ids)\ntrain_labels = torch.tensor(train_labels)\nvalid_labels = torch.tensor(valid_labels)\ntrain_masks = torch.tensor(train_masks)\nvalid_masks = torch.tensor(valid_masks)\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nvalid_data = TensorDataset(valid_inputs, valid_masks, valid_labels)\nvalid_sampler = RandomSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qD55wmzKF8vG","outputId":"1e802bf1-0eb2-43d9-83a8-bc109416ec1f","execution":{"iopub.status.busy":"2022-12-13T11:57:38.191323Z","iopub.execute_input":"2022-12-13T11:57:38.191683Z","iopub.status.idle":"2022-12-13T11:57:38.400537Z","shell.execute_reply.started":"2022-12-13T11:57:38.191653Z","shell.execute_reply":"2022-12-13T11:57:38.399490Z"},"trusted":true},"execution_count":255,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  after removing the cwd from sys.path.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \"\"\"\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"mgcIdNAk8ukx","execution":{"iopub.status.busy":"2022-12-13T11:57:45.494138Z","iopub.execute_input":"2022-12-13T11:57:45.495012Z","iopub.status.idle":"2022-12-13T11:57:45.500050Z","shell.execute_reply.started":"2022-12-13T11:57:45.494973Z","shell.execute_reply":"2022-12-13T11:57:45.498989Z"},"trusted":true},"execution_count":259,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rrdASdT6860A","outputId":"53af5cae-0633-4e64-f11c-0fe5291e9d40","execution":{"iopub.status.busy":"2022-12-13T11:57:46.716260Z","iopub.execute_input":"2022-12-13T11:57:46.716613Z","iopub.status.idle":"2022-12-13T11:57:46.722848Z","shell.execute_reply.started":"2022-12-13T11:57:46.716582Z","shell.execute_reply":"2022-12-13T11:57:46.721892Z"},"trusted":true},"execution_count":260,"outputs":[{"execution_count":260,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"from matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:57:47.857338Z","iopub.execute_input":"2022-12-13T11:57:47.857732Z","iopub.status.idle":"2022-12-13T11:57:47.862930Z","shell.execute_reply.started":"2022-12-13T11:57:47.857697Z","shell.execute_reply":"2022-12-13T11:57:47.861942Z"},"trusted":true},"execution_count":261,"outputs":[]},{"cell_type":"code","source":"print(count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGGZ_878M80C","outputId":"e19ed751-51a4-4e62-b89c-161c8a0a9cc5","execution":{"iopub.status.busy":"2022-12-13T11:57:48.977247Z","iopub.execute_input":"2022-12-13T11:57:48.977719Z","iopub.status.idle":"2022-12-13T11:57:48.983789Z","shell.execute_reply.started":"2022-12-13T11:57:48.977674Z","shell.execute_reply":"2022-12-13T11:57:48.982635Z"},"trusted":true},"execution_count":262,"outputs":[{"name":"stdout","text":"48\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"id":"UVOKlxhL-h8o","execution":{"iopub.status.busy":"2022-12-13T11:57:50.091186Z","iopub.execute_input":"2022-12-13T11:57:50.091538Z","iopub.status.idle":"2022-12-13T11:57:50.097215Z","shell.execute_reply.started":"2022-12-13T11:57:50.091507Z","shell.execute_reply":"2022-12-13T11:57:50.095902Z"},"trusted":true},"execution_count":263,"outputs":[]},{"cell_type":"code","source":"class textCNN(nn.Module):\n  def __init__(self,seq_len=256, embedding_size=768, output_size=2):\n    super(textCNN, self).__init__()\n    self.embedding_size = embedding_size\n    self.output_size = output_size\n    self.seq_len = seq_len\n\n    kernel_1 = (2, embedding_size)\n    kernel_2 = (3, embedding_size)\n    kernel_3 = (4, embedding_size)\n    kernel_4 = (5, embedding_size)\n    self.convo_1 = nn.Conv2d(1, 256, kernel_1)\n    self.convo_2 = nn.Conv2d(1, 256, kernel_2)\n    self.convo_3 = nn.Conv2d(1, 256, kernel_3)\n    self.convo_4 = nn.Conv2d(1, 256, kernel_4)\n    self.fc1 = nn.Linear(4*self.seq_len, 2, bias=True)\n\n  def forward(self, inputs):\n\n    out_1 = self.convo_1(inputs)\n    out_2 = self.convo_2(inputs)\n    out_3 = self.convo_3(inputs)\n    out_4 = self.convo_4(inputs)\n\n    out_1 = nn.functional.max_pool2d(out_1,(self.seq_len - 1, 1))\n    out_2 = nn.functional.max_pool2d(out_2,(self.seq_len - 2, 1))\n    out_3 = nn.functional.max_pool2d(out_3,(self.seq_len - 3, 1))\n    out_4 = nn.functional.max_pool2d(out_4,(self.seq_len - 4, 1))\n\n    out_1 = torch.squeeze(out_1)\n    out_2 = torch.squeeze(out_2)\n    out_3 = torch.squeeze(out_3)\n    out_4 = torch.squeeze(out_4)\n    \n    # print(out_1.shape)\n    # print(out_2.shape)\n    # print(out_3.shape)\n    # print(out_4.shape)\n    \n    out = torch.cat((out_1, out_2, out_3, out_4), -1)\n    \n    out = self.fc1(out)\n    out = torch.sigmoid(out)\n    return out\n","metadata":{"id":"ecryoJ9kgSTA","execution":{"iopub.status.busy":"2022-12-13T11:57:50.914865Z","iopub.execute_input":"2022-12-13T11:57:50.915234Z","iopub.status.idle":"2022-12-13T11:57:50.927617Z","shell.execute_reply.started":"2022-12-13T11:57:50.915194Z","shell.execute_reply":"2022-12-13T11:57:50.926576Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"code","source":"class simple_textCNN(nn.Module):\n  def __init__(self, seq_len=256, embedding_size=768,kernel_size=3, output_size=2):\n    super(simple_textCNN, self).__init__()\n\n    self.embedding_size = embedding_size\n    self.output_size = output_size\n    self.seq_len = seq_len\n    self.kernel_size = kernel_size\n    kernel = (self.kernel_size, self.embedding_size)\n    \n    self.convo = nn.Conv2d(1, 256, kernel)\n\n    self.fc1 = nn.Linear(self.seq_len, 2, bias=True)\n    \n    nn.init.normal_(self.fc1.weight, std=0.02)\n    nn.init.normal_(self.fc1.bias, 0)\n    nn.init.normal_(self.convo.weight, std=0.02)\n    \n    \n  def forward(self, inputs):\n\n    out = self.convo(inputs)\n    # out = torch.t(out)\n#     print(out.shape)\n    out = F.max_pool2d(out,(self.seq_len - self.kernel_size + 1, 1))\n#     print(out.shape)\n    out = torch.squeeze(out)\n#     print(out.shape)\n    out = self.fc1(out)\n    out = torch.sigmoid(out)\n\n    return out","metadata":{"id":"PW5Mi2Gf2nMM","execution":{"iopub.status.busy":"2022-12-13T11:57:52.693897Z","iopub.execute_input":"2022-12-13T11:57:52.694270Z","iopub.status.idle":"2022-12-13T11:57:52.703701Z","shell.execute_reply.started":"2022-12-13T11:57:52.694239Z","shell.execute_reply":"2022-12-13T11:57:52.702559Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"code","source":"class BERT_for_sentiment(nn.Module):\n  def __init__(self, output_size=2, dropout=0.1):\n    super(BERT_for_sentiment, self).__init__()\n    self.output_size = output_size\n    self.dropout = dropout\n    self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n    self.fc1 = nn.Linear(768, 768, bias=True)\n    self.layernorm_1 = nn.LayerNorm((768,), eps = 1e-05, elementwise_affine=True)\n    self.fc2 = nn.Linear(768, self.output_size, bias=True)\n    nn.init.normal_(self.fc1.weight, std=0.02)\n    nn.init.normal_(self.fc1.bias, 0)\n    nn.init.normal_(self.fc2.weight, std=0.02)\n    nn.init.normal_(self.fc2.bias, 0)\n    \n  def forward(self, inputs, attention_mask):\n    x = self.bert(input_ids=inputs, attention_mask=attention_mask)\n    x = x.pooler_output\n#     x = F.dropout(x, self.dropout, inplace=False)\n#     x = self.fc1(x)\n#     x = self.layernorm_1(x)\n#     x = F.dropout(x, self.dropout, inplace=False)\n    x = self.fc2(x)\n    out = F.softmax(x, dim=-1)\n    \n    return out\n    ","metadata":{"id":"juvEUDwh-6Fz","execution":{"iopub.status.busy":"2022-12-13T11:57:54.095255Z","iopub.execute_input":"2022-12-13T11:57:54.095609Z","iopub.status.idle":"2022-12-13T11:57:54.106130Z","shell.execute_reply.started":"2022-12-13T11:57:54.095577Z","shell.execute_reply":"2022-12-13T11:57:54.105047Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"code","source":"class BERT_for_sentiment_large(nn.Module):\n  def __init__(self, output_size=2, dropout=0.1):\n    super(BERT_for_sentiment_large, self).__init__()\n    self.output_size = output_size\n    self.dropout = dropout\n    self.bert =  AutoModel.from_pretrained(\"vinai/phobert-base\", num_labels=2, output_hidden_states=True)\n    self.fc1 = nn.Linear(768, 768, bias=True)\n    self.layernorm_1 = nn.LayerNorm((768,), eps = 1e-05, elementwise_affine=True)\n    self.fc2 = nn.Linear(4*768, self.output_size, bias=True)\n    nn.init.normal_(self.fc1.weight, std=0.02)\n    nn.init.normal_(self.fc1.bias, 0)\n    nn.init.normal_(self.fc2.weight, std=0.02)\n    nn.init.normal_(self.fc2.bias, 0)\n    \n  def forward(self, inputs, attention_mask):\n    outputs = self.bert(input_ids=inputs, attention_mask=attention_mask)\n    x = torch.cat((outputs[2][-1][:,0, ...],outputs[2][-2][:,0, ...], outputs[2][-3][:,0, ...], outputs[2][-4][:,0, ...]),-1)\n#     x = F.dropout(x, self.dropout, inplace=False)\n#     x = self.fc1(x)\n#     x = self.layernorm_1(x)\n#     x = F.dropout(x, self.dropout, inplace=False)\n    x = self.fc2(x)\n#     out = F.softmax(x, dim=-1)\n    out = x\n    return out\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:57:57.363607Z","iopub.execute_input":"2022-12-13T11:57:57.363996Z","iopub.status.idle":"2022-12-13T11:57:57.375578Z","shell.execute_reply.started":"2022-12-13T11:57:57.363962Z","shell.execute_reply":"2022-12-13T11:57:57.373950Z"},"trusted":true},"execution_count":267,"outputs":[]},{"cell_type":"code","source":"import torch","metadata":{"id":"HeFHbXN1D3Dp","execution":{"iopub.status.busy":"2022-12-13T11:58:00.748256Z","iopub.execute_input":"2022-12-13T11:58:00.748628Z","iopub.status.idle":"2022-12-13T11:58:00.753292Z","shell.execute_reply.started":"2022-12-13T11:58:00.748595Z","shell.execute_reply":"2022-12-13T11:58:00.752095Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"code","source":"class BERT_plus_LSTM_sentiment(nn.Module):\n  def __init__(self, hidden_size,n_layers=1, output_size=2, bidirectional=True, dropout=0.1):\n    super(BERT_plus_LSTM_sentiment, self).__init__()\n    self.output_size = output_size\n    self.dropout = dropout\n    self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n    self.bidirectional = bidirectional\n    self.hidden_size = hidden_size\n    self.n_layers = n_layers\n    self.LSTM = nn.LSTM(768, self.hidden_size, num_layers=self.n_layers, bidirectional=self.bidirectional, batch_first=True)\n    if self.bidirectional == True:\n      self.hidden_size = hidden_size*2\n    \n    self.fc1 = nn.Linear(self.hidden_size, 64, bias=True)\n    self.fc2 = nn.Linear(64, self.output_size, bias=True)\n    \n    nn.init.normal_(self.fc1.weight, std=0.02)\n    nn.init.normal_(self.fc1.bias, 0)\n    \n    nn.init.normal_(self.fc2.weight, std=0.02)\n    nn.init.normal_(self.fc2.bias, 0)\n    \n  def forward(self, inputs, attention_mask):\n\n    x = self.bert(input_ids=inputs, attention_mask=attention_mask)\n    x = x[0]\n    \n    out_lstm, _ = self.LSTM(x)\n    max_pool, _ = torch.max(out_lstm, 1)\n    linear_out = F.dropout(torch.relu(self.fc1(max_pool)), self.dropout, inplace=False)\n    linear_out = self.fc2(linear_out)\n    out = torch.sigmoid(linear_out)\n    \n    return out","metadata":{"id":"1aStR2QcsTy0","execution":{"iopub.status.busy":"2022-12-13T11:58:01.955596Z","iopub.execute_input":"2022-12-13T11:58:01.955986Z","iopub.status.idle":"2022-12-13T11:58:01.967540Z","shell.execute_reply.started":"2022-12-13T11:58:01.955952Z","shell.execute_reply":"2022-12-13T11:58:01.966424Z"},"trusted":true},"execution_count":269,"outputs":[]},{"cell_type":"code","source":"class BERT_plus_textCNN_sentiment(nn.Module):\n  def __init__(self, output_size=2):\n    super(BERT_plus_textCNN_sentiment, self).__init__()\n    self.output_size = output_size\n    self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n\n    self.CNN = simple_textCNN(kernel_size=3, output_size=self.output_size)\n\n  def forward(self, inputs, attention_mask):\n    x = self.bert(input_ids=inputs, attention_mask=attention_mask)\n    x = x.last_hidden_state\n    \n    x = torch.squeeze(x)\n    x = torch.unsqueeze(x, dim=1)\n    out= self.CNN(x)\n    return out","metadata":{"id":"vLMaS6UQx40H","execution":{"iopub.status.busy":"2022-12-13T11:58:03.203403Z","iopub.execute_input":"2022-12-13T11:58:03.203903Z","iopub.status.idle":"2022-12-13T11:58:03.218132Z","shell.execute_reply.started":"2022-12-13T11:58:03.203829Z","shell.execute_reply":"2022-12-13T11:58:03.216968Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"code","source":"\nmodel = BERT_for_sentiment_large(output_size=2)\n# from transformers import AutoModelForSequenceClassification\n# model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=2)\n# model = BERT_plus_LSTM_sentiment(64, n_layers=1, output_size=2)\n# model = BERT_plus_textCNN_sentiment(output_size=2)\n# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n\n\n\n","metadata":{"id":"B3_mmYmRTmd7","execution":{"iopub.status.busy":"2022-12-13T11:58:04.374179Z","iopub.execute_input":"2022-12-13T11:58:04.374626Z","iopub.status.idle":"2022-12-13T11:58:06.776347Z","shell.execute_reply.started":"2022-12-13T11:58:04.374584Z","shell.execute_reply":"2022-12-13T11:58:06.775337Z"},"trusted":true},"execution_count":271,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, child in enumerate(model.children()):\n    print(\"i = \", i, \" \", child)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:58:06.778098Z","iopub.execute_input":"2022-12-13T11:58:06.780087Z","iopub.status.idle":"2022-12-13T11:58:06.788228Z","shell.execute_reply.started":"2022-12-13T11:58:06.780048Z","shell.execute_reply":"2022-12-13T11:58:06.787166Z"},"trusted":true},"execution_count":272,"outputs":[{"name":"stdout","text":"i =  0   RobertaModel(\n  (embeddings): RobertaEmbeddings(\n    (word_embeddings): Embedding(64001, 768, padding_idx=1)\n    (position_embeddings): Embedding(258, 768, padding_idx=1)\n    (token_type_embeddings): Embedding(1, 768)\n    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): RobertaEncoder(\n    (layer): ModuleList(\n      (0): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (1): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (2): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (3): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (4): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (5): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (6): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (7): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (8): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (9): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (10): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n      (11): RobertaLayer(\n        (attention): RobertaAttention(\n          (self): RobertaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): RobertaSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): RobertaIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): RobertaOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): RobertaPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)\ni =  1   Linear(in_features=768, out_features=768, bias=True)\ni =  2   LayerNorm((768,), eps=1e-05, elementwise_affine=True)\ni =  3   Linear(in_features=3072, out_features=2, bias=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"# for i, child in enumerate(model.bert.embeddings.children()):\n#     print(\"i = \", i, \" \", child)\n#     for params in child.parameters():\n#         params.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-12-13T03:53:41.149234Z","iopub.execute_input":"2022-12-13T03:53:41.149672Z","iopub.status.idle":"2022-12-13T03:53:41.155114Z","shell.execute_reply.started":"2022-12-13T03:53:41.149638Z","shell.execute_reply":"2022-12-13T03:53:41.154064Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# @title\n# # print(model.children())\n# tmp = 0\n# for i, child in enumerate(model.bert.encoder.layer.children()):\n#     if i < 8:\n#         for params in child.parameters():\n#             params.requires_grad = False\n# #     print(\"i =\", i,\" \", child)\n#     tmp += 1\n# print(tmp)","metadata":{"cellView":"form","id":"Pzu7lLu3JPoe","execution":{"iopub.status.busy":"2022-12-13T03:53:41.157799Z","iopub.execute_input":"2022-12-13T03:53:41.158465Z","iopub.status.idle":"2022-12-13T03:53:41.163030Z","shell.execute_reply.started":"2022-12-13T03:53:41.158427Z","shell.execute_reply":"2022-12-13T03:53:41.162064Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor params in model.parameters():\n  count+=1\nprint(count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hE-Ytp9j9Skx","outputId":"a366eee9-0f5a-4025-f28b-fa5846bc23b3","execution":{"iopub.status.busy":"2022-12-13T11:58:10.922224Z","iopub.execute_input":"2022-12-13T11:58:10.922589Z","iopub.status.idle":"2022-12-13T11:58:10.929597Z","shell.execute_reply.started":"2022-12-13T11:58:10.922557Z","shell.execute_reply":"2022-12-13T11:58:10.928339Z"},"trusted":true},"execution_count":273,"outputs":[{"name":"stdout","text":"205\n","output_type":"stream"}]},{"cell_type":"code","source":"count = 0\nfor params in model.parameters():\n  if(params.requires_grad == True):\n    # print(params)\n    count+=1\n\nprint(count)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CY5q5STViDGO","outputId":"d4266e17-0d9f-4505-e842-2f44276e3aae","execution":{"iopub.status.busy":"2022-12-13T11:58:12.073398Z","iopub.execute_input":"2022-12-13T11:58:12.073775Z","iopub.status.idle":"2022-12-13T11:58:12.080991Z","shell.execute_reply.started":"2022-12-13T11:58:12.073739Z","shell.execute_reply":"2022-12-13T11:58:12.079863Z"},"trusted":true},"execution_count":274,"outputs":[{"name":"stdout","text":"205\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nfrom transformers import get_linear_schedule_with_warmup\n\nmax_epochs = 10\nlearning_rate = 2*1e-5\n\nweight_decay = 0.01\noptimizing_parameters = filter(lambda p: p.requires_grad, model.parameters())\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.AdamW(\n    optimizing_parameters,\n    lr=learning_rate,\n    weight_decay=weight_decay\n)\nlr_scheduler = get_linear_schedule_with_warmup(\n                optimizer, \n                num_warmup_steps=0, \n                num_training_steps=len(train_dataloader)*max_epochs\n            )","metadata":{"id":"PAYgHw8EgdGI","execution":{"iopub.status.busy":"2022-12-13T11:58:13.400486Z","iopub.execute_input":"2022-12-13T11:58:13.400870Z","iopub.status.idle":"2022-12-13T11:58:13.409301Z","shell.execute_reply.started":"2022-12-13T11:58:13.400826Z","shell.execute_reply":"2022-12-13T11:58:13.408223Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"id":"k_I89RsSMUvD","execution":{"iopub.status.busy":"2022-12-13T11:58:19.412627Z","iopub.execute_input":"2022-12-13T11:58:19.413004Z","iopub.status.idle":"2022-12-13T11:58:19.419210Z","shell.execute_reply.started":"2022-12-13T11:58:19.412971Z","shell.execute_reply":"2022-12-13T11:58:19.418024Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GcY1LBg1S-Fn","outputId":"8c92c01f-0a95-48e7-8720-0152f2f255c1","execution":{"iopub.status.busy":"2022-12-13T11:58:20.742339Z","iopub.execute_input":"2022-12-13T11:58:20.742697Z","iopub.status.idle":"2022-12-13T11:58:20.752049Z","shell.execute_reply.started":"2022-12-13T11:58:20.742665Z","shell.execute_reply":"2022-12-13T11:58:20.751036Z"},"trusted":true},"execution_count":279,"outputs":[{"execution_count":279,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"id":"qmDMNVUArjgC","execution":{"iopub.status.busy":"2022-12-13T11:58:21.788537Z","iopub.execute_input":"2022-12-13T11:58:21.788921Z","iopub.status.idle":"2022-12-13T11:58:21.938838Z","shell.execute_reply.started":"2022-12-13T11:58:21.788888Z","shell.execute_reply":"2022-12-13T11:58:21.937848Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ndef uac(preds, labels):\n  pred_flat = np.argmax(preds, axis=1).flatten()\n  labels_flat = labels.flatten()\n  return roc_auc_score(pred_flat, labels_flat)","metadata":{"id":"okgKTqj3R4N7","execution":{"iopub.status.busy":"2022-12-13T11:58:23.054036Z","iopub.execute_input":"2022-12-13T11:58:23.054404Z","iopub.status.idle":"2022-12-13T11:58:23.060064Z","shell.execute_reply.started":"2022-12-13T11:58:23.054372Z","shell.execute_reply":"2022-12-13T11:58:23.058884Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm, tqdm_notebook","metadata":{"id":"y7cVg9zoQNGE","execution":{"iopub.status.busy":"2022-12-13T11:58:24.700102Z","iopub.execute_input":"2022-12-13T11:58:24.700469Z","iopub.status.idle":"2022-12-13T11:58:24.705663Z","shell.execute_reply.started":"2022-12-13T11:58:24.700437Z","shell.execute_reply":"2022-12-13T11:58:24.704476Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model,criterion, optimizer,scheduler, train_loader):\n  total_loss = 0\n  total_acc = 0\n  total = 0\n  tmp = 0\n  model.train()\n  \n  for batch in tqdm(train_loader):\n    input_ids, input_mask, labels = batch\n\n    input_ids = input_ids.to(device)    \n    input_mask = input_mask.to(device)   \n    labels = labels.to(device)\n\n    optimizer.zero_grad()\n    output = model(input_ids, attention_mask=input_mask)\n#     output = output.logits\n    loss = criterion(output, labels)\n\n    # loss = output[0]\n    # logits = output[1]\n\n    loss.backward()\n    \n    nn.utils.clip_grad_norm_(optimizing_parameters, max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    \n    \n    total_loss += loss.item()\n    total += len(labels)\n\n    logits = output.detach().cpu().numpy()\n    labels = labels.to('cpu').numpy()\n    acc = flat_accuracy(logits, labels)\n\n    total_acc += acc\n\n    tmp += 1\n\n  return total_loss/total, total_acc / tmp ","metadata":{"id":"2ti2-RyT3jth","execution":{"iopub.status.busy":"2022-12-13T11:58:25.696334Z","iopub.execute_input":"2022-12-13T11:58:25.696699Z","iopub.status.idle":"2022-12-13T11:58:25.705740Z","shell.execute_reply.started":"2022-12-13T11:58:25.696668Z","shell.execute_reply":"2022-12-13T11:58:25.704528Z"},"trusted":true},"execution_count":283,"outputs":[]},{"cell_type":"code","source":"def validate_epoch(model,criterion,valid_loader):\n    model.eval()\n    total_loss = total = 0\n    accuracy = 0\n    eval_f1 = 0\n    tmp = 0\n    for batch in tqdm(valid_loader):\n      # batch = torch.toTensor(t.to(device) for t in batch)\n      input_ids, input_mask, labels = batch\n\n      input_ids = input_ids.to(device=device)\n      input_mask = input_mask.to(device=device)\n      labels = labels.to(device=device)\n\n          # Forwards pass\n      with torch.no_grad():\n        logits = model(input_ids, attention_mask=input_mask)\n#         logits = logits.logits\n          \n          # Calculate how wrong the model is\n        # loss = logits[0]\n        loss = criterion(logits, labels)\n        \n        # print(loss)\n        logits = logits.detach().cpu().numpy()\n        labels = labels.to('cpu').numpy()\n\n          \n        acc = flat_accuracy(logits, labels)\n        accuracy += acc\n        # Record metrics\n        total_loss += loss.item()\n        total += len(labels)\n        tmp += 1\n    return total_loss / total , accuracy / tmp","metadata":{"id":"XutIx7lrVHUO","execution":{"iopub.status.busy":"2022-12-13T11:58:27.239340Z","iopub.execute_input":"2022-12-13T11:58:27.239699Z","iopub.status.idle":"2022-12-13T11:58:27.248093Z","shell.execute_reply.started":"2022-12-13T11:58:27.239668Z","shell.execute_reply":"2022-12-13T11:58:27.246959Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"max_epochs = 10\nn_epochs = 0\ntrain_losses, valid_losses = [], []\ntrain_acces, valid_acces = [], []\nfor _ in range(max_epochs):\n    train_loss, train_acc = train_epoch(model,criterion, optimizer,lr_scheduler, train_dataloader)\n    valid_loss, valid_acc = validate_epoch(model,criterion, valid_dataloader)\n    \n    tqdm.write(\n        f'epoch #{n_epochs + 1:3d}\\n'\n        f'train_loss: {train_loss:.2e}'\n        f'\\ttrain_acc: {train_acc:.2e}\\n'\n        f'valid_loss: {valid_loss:.2e}'\n        f'\\tvalid_acc: {valid_acc:.2e}\\n',\n    )\n    # print(\"epoch:\", \" \", n_epochs)\n    # print(\"train_loss: \", \" \", train_loss)\n    # print(\"valid_loss: \", \" \", valid_loss)\n    # print(\"valid_acc: \", \" \", valid_acc)\n    # Early stopping if the current valid_loss is greater than the last three valid losses\n#     if len(valid_losses) > 2 and all(valid_loss >= loss\n#                                      for loss in valid_losses[-3:]):\n#         print('Stopping early')\n#         break\n#     if len(valid_losses) == 0:\n#       print(\"saving 1st model:...\")\n#       torch.save(model.state_dict(), '/kaggle/working/phobert_linear_x4.pt')\n#     else:\n#       min_n = 10\n#       max_acc = -1\n#       for loss in valid_losses:\n#         if(min_n > loss):\n#          min_n = loss\n        \n#       if valid_loss < min_n:\n#         print(\"saving the best model for best loss:...\")\n#         torch.save(model.state_dict(), '/kaggle/working/phobert_linear_x4.pt')\n#       elif valid_loss == min_n and abs(train_acc - valid_acc) < 0.02:\n#         print(\"saving the best model for best fit:...\")\n#         torch.save(model.state_dict(), '/kaggle/working/phobert_linear_x4.pt')\n    print(\"saving model:...\")\n    torch.save(model.state_dict(), f'/kaggle/working/phobert_linear_train_crawl_{n_epochs+1}.pt')\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    train_acces.append(train_acc)\n    valid_acces.append(valid_acc)\n    n_epochs += 1","metadata":{"id":"IiTKmnNIWpG_","execution":{"iopub.status.busy":"2022-12-13T11:58:40.963478Z","iopub.execute_input":"2022-12-13T11:58:40.963866Z","iopub.status.idle":"2022-12-13T12:28:12.319882Z","shell.execute_reply.started":"2022-12-13T11:58:40.963811Z","shell.execute_reply":"2022-12-13T12:28:12.317867Z"},"trusted":true},"execution_count":285,"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:23<00:00,  1.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  1\ntrain_loss: 8.63e-03\ttrain_acc: 8.94e-01\nvalid_loss: 6.72e-03\tvalid_acc: 9.27e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:23<00:00,  1.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  2\ntrain_loss: 6.27e-03\ttrain_acc: 9.34e-01\nvalid_loss: 7.29e-03\tvalid_acc: 9.15e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:23<00:00,  1.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  3\ntrain_loss: 5.24e-03\ttrain_acc: 9.47e-01\nvalid_loss: 6.86e-03\tvalid_acc: 9.26e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:24<00:00,  1.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  4\ntrain_loss: 4.38e-03\ttrain_acc: 9.57e-01\nvalid_loss: 7.18e-03\tvalid_acc: 9.22e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:23<00:00,  1.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  5\ntrain_loss: 3.52e-03\ttrain_acc: 9.67e-01\nvalid_loss: 7.81e-03\tvalid_acc: 9.19e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:24<00:00,  1.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  6\ntrain_loss: 3.02e-03\ttrain_acc: 9.73e-01\nvalid_loss: 8.09e-03\tvalid_acc: 9.21e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:23<00:00,  1.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  7\ntrain_loss: 2.46e-03\ttrain_acc: 9.79e-01\nvalid_loss: 8.41e-03\tvalid_acc: 9.22e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [03:24<00:00,  1.35it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch #  8\ntrain_loss: 2.02e-03\ttrain_acc: 9.83e-01\nvalid_loss: 8.73e-03\tvalid_acc: 9.23e-01\n\nsaving model:...\n","output_type":"stream"},{"name":"stderr","text":" 12%|‚ñà‚ñè        | 32/276 [00:24<03:05,  1.31it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2958533323.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_acces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/1703430222.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, criterion, optimizer, scheduler, train_loader)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# logits = output[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizing_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:29:08.897526Z","iopub.execute_input":"2022-12-13T12:29:08.897922Z","iopub.status.idle":"2022-12-13T12:29:09.426301Z","shell.execute_reply.started":"2022-12-13T12:29:08.897888Z","shell.execute_reply":"2022-12-13T12:29:09.423221Z"},"trusted":true},"execution_count":286,"outputs":[{"execution_count":286,"output_type":"execute_result","data":{"text/plain":"6024"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:29:11.817159Z","iopub.execute_input":"2022-12-13T12:29:11.817529Z","iopub.status.idle":"2022-12-13T12:29:11.823130Z","shell.execute_reply.started":"2022-12-13T12:29:11.817497Z","shell.execute_reply":"2022-12-13T12:29:11.821853Z"},"trusted":true},"execution_count":287,"outputs":[]},{"cell_type":"code","source":"test_model = BERT_for_sentiment_large()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:29:15.895709Z","iopub.execute_input":"2022-12-13T12:29:15.896331Z","iopub.status.idle":"2022-12-13T12:29:22.822309Z","shell.execute_reply.started":"2022-12-13T12:29:15.896294Z","shell.execute_reply":"2022-12-13T12:29:22.821345Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"test_model.load_state_dict(torch.load(\"/kaggle/working/phobert_linear_train_crawl_3.pt\"))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:30:56.204543Z","iopub.execute_input":"2022-12-13T12:30:56.204946Z","iopub.status.idle":"2022-12-13T12:30:59.544702Z","shell.execute_reply.started":"2022-12-13T12:30:56.204912Z","shell.execute_reply":"2022-12-13T12:30:59.543717Z"},"trusted":true},"execution_count":289,"outputs":[{"execution_count":289,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:20:10.930638Z","iopub.execute_input":"2022-12-13T11:20:10.931014Z","iopub.status.idle":"2022-12-13T11:20:13.258530Z","shell.execute_reply.started":"2022-12-13T11:20:10.930982Z","shell.execute_reply":"2022-12-13T11:20:13.257475Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  1\ntrain_loss: 1.38e-02\ttrain_acc: 8.74e-01\nvalid_loss: 1.27e-02\tvalid_acc: 9.16e-01\n\nsaving 1st model:...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  2\ntrain_loss: 1.25e-02\ttrain_acc: 9.13e-01\nvalid_loss: 1.25e-02\tvalid_acc: 9.17e-01\n\nsaving the best model for best loss:...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  3\ntrain_loss: 1.20e-02\ttrain_acc: 9.31e-01\nvalid_loss: 1.24e-02\tvalid_acc: 9.23e-01\n\nsaving the best model for best loss:...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.28it/s]\nepoch #  4\ntrain_loss: 1.20e-02\ttrain_acc: 9.32e-01\nvalid_loss: 1.24e-02\tvalid_acc: 9.24e-01\n\nsaving the best model for best loss:...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  5\ntrain_loss: 1.17e-02\ttrain_acc: 9.39e-01\nvalid_loss: 1.26e-02\tvalid_acc: 9.16e-01\n\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  6\ntrain_loss: 1.17e-02\ttrain_acc: 9.41e-01\nvalid_loss: 1.25e-02\tvalid_acc: 9.19e-01\n\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.28it/s]\nepoch #  7\ntrain_loss: 1.14e-02\ttrain_acc: 9.48e-01\nvalid_loss: 1.23e-02\tvalid_acc: 9.27e-01\n\nsaving the best model for best loss:...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.29it/s]\nepoch #  8\ntrain_loss: 1.14e-02\ttrain_acc: 9.51e-01\nvalid_loss: 1.22e-02\tvalid_acc: 9.29e-01\n\nsaving the best model for best loss:...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.28it/s]\nepoch #  9\ntrain_loss: 1.13e-02\ttrain_acc: 9.53e-01\nvalid_loss: 1.22e-02\tvalid_acc: 9.33e-01\n\nsaving the best model for best loss:...\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 256/256 [03:08<00:00,  1.36it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.29it/s]\nepoch # 10\ntrain_loss: 1.13e-02\ttrain_acc: 9.54e-01\nvalid_loss: 1.22e-02\tvalid_acc: 9.30e-01\n","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cat((outputs[2][-1][:,0, ...],outputs[2][-2][:,0, ...], outputs[2][-3][:,0, ...], outputs[2][-4][:,0, ...]),-1).cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:31:12.997745Z","iopub.execute_input":"2022-12-13T12:31:12.998459Z","iopub.status.idle":"2022-12-13T12:31:13.031042Z","shell.execute_reply.started":"2022-12-13T12:31:12.998421Z","shell.execute_reply":"2022-12-13T12:31:13.029763Z"},"trusted":true},"execution_count":290,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2741672996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"],"ename":"NameError","evalue":"name 'outputs' is not defined","output_type":"error"}]},{"cell_type":"code","source":"trained_phobert = test_model.bert\n# trained_phobert = AutoModel.from_pretrained(\"vinai/phobert-base\", num_labels=2, output_hidden_state=True)\ntrained_phobert.to(device)\ntrained_phobert.eval()\ntotal_loss = total = 0\naccuracy = 0\neval_f1 = 0\ntmp = 0\nX_train = []\ny_train = []\nX_test = []\ny_test = []\nfor batch in tqdm(train_dataloader):\n    # batch = torch.toTensor(t.to(device) for t in batch)\n    input_ids, input_mask, labels = batch\n\n    input_ids = input_ids.to(device=device)\n    input_mask = input_mask.to(device=device)\n    labels = labels.to(device=device)\n\n          # Forwards pass\n    with torch.no_grad():\n      logits = trained_phobert(input_ids, attention_mask=input_mask)\n      logits = torch.cat((logits[2][-1][:,0, ...],logits[2][-2][:,0, ...], logits[2][-3][:,0, ...], logits[2][-4][:,0, ...]),-1)\n#       logits = logits.pooler_output\n        \n      logits = logits.detach().cpu().numpy()\n      labels = labels.to('cpu').numpy()\n\n      for logit in logits:\n        X_train.append(logit)\n      for label in labels:\n        y_train.append(label)\n\nfor batch in tqdm(valid_dataloader):\n    # batch = torch.toTensor(t.to(device) for t in batch)\n    input_ids, input_mask, labels = batch\n\n    input_ids = input_ids.to(device=device)\n    input_mask = input_mask.to(device=device)\n    labels = labels.to(device=device)\n\n          # Forwards pass\n    with torch.no_grad():\n      logits = trained_phobert(input_ids, attention_mask=input_mask)\n      logits = torch.cat((logits[2][-1][:,0, ...],logits[2][-2][:,0, ...], logits[2][-3][:,0, ...], logits[2][-4][:,0, ...]),-1)\n#       logits = logits.pooler_output\n          \n        # Calculate how wrong the model is\n        # loss = logits[0]\n        # print(loss)\n      logits = logits.detach().cpu().numpy()\n      labels = labels.to('cpu').numpy()\n\n      for logit in logits:\n        X_test.append(logit)\n      for label in labels:\n        y_test.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:31:19.593711Z","iopub.execute_input":"2022-12-13T12:31:19.594332Z","iopub.status.idle":"2022-12-13T12:32:39.099490Z","shell.execute_reply.started":"2022-12-13T12:31:19.594296Z","shell.execute_reply":"2022-12-13T12:32:39.098415Z"},"trusted":true},"execution_count":291,"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 276/276 [01:05<00:00,  4.19it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:13<00:00,  4.21it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# X = X_train + X_test\n# y = y_train + y_test","metadata":{"execution":{"iopub.status.busy":"2022-12-13T07:43:05.309431Z","iopub.execute_input":"2022-12-13T07:43:05.309819Z","iopub.status.idle":"2022-12-13T07:43:05.315168Z","shell.execute_reply.started":"2022-12-13T07:43:05.309784Z","shell.execute_reply":"2022-12-13T07:43:05.314106Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components=900)\npca.fit(X_train)\nX_train_pca = pca.transform(X_train)\nX_test_pca = pca.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:34:07.536609Z","iopub.execute_input":"2022-12-13T12:34:07.537394Z","iopub.status.idle":"2022-12-13T12:34:25.628066Z","shell.execute_reply.started":"2022-12-13T12:34:07.537355Z","shell.execute_reply":"2022-12-13T12:34:25.626603Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"code","source":"pca.explained_variance_ratio_.sum()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:34:50.731725Z","iopub.execute_input":"2022-12-13T12:34:50.732428Z","iopub.status.idle":"2022-12-13T12:34:50.738779Z","shell.execute_reply.started":"2022-12-13T12:34:50.732392Z","shell.execute_reply":"2022-12-13T12:34:50.737664Z"},"trusted":true},"execution_count":297,"outputs":[{"execution_count":297,"output_type":"execute_result","data":{"text/plain":"0.9968728644297893"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:34:54.897125Z","iopub.execute_input":"2022-12-13T12:34:54.897501Z","iopub.status.idle":"2022-12-13T12:34:54.902344Z","shell.execute_reply.started":"2022-12-13T12:34:54.897469Z","shell.execute_reply":"2022-12-13T12:34:54.901340Z"},"trusted":true},"execution_count":298,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:34:57.020963Z","iopub.execute_input":"2022-12-13T12:34:57.021324Z","iopub.status.idle":"2022-12-13T12:34:57.026448Z","shell.execute_reply.started":"2022-12-13T12:34:57.021294Z","shell.execute_reply":"2022-12-13T12:34:57.025162Z"},"trusted":true},"execution_count":299,"outputs":[]},{"cell_type":"code","source":"# classifier = DecisionTreeClassifier()\n# classifier.fit(np.array(X_train), np.array(y_train))\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(classifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(classifier.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-12T18:43:15.793264Z","iopub.execute_input":"2022-12-12T18:43:15.793632Z","iopub.status.idle":"2022-12-12T18:43:35.807300Z","shell.execute_reply.started":"2022-12-12T18:43:15.793602Z","shell.execute_reply":"2022-12-12T18:43:35.806233Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"Vanilla Implementation : Accuracy score for training data : 0.9995099840744824\nVanilla Implementation : Accuracy score for testing data : 0.7761852260198456\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:04.108757Z","iopub.execute_input":"2022-12-13T12:35:04.109726Z","iopub.status.idle":"2022-12-13T12:35:04.114529Z","shell.execute_reply.started":"2022-12-13T12:35:04.109689Z","shell.execute_reply":"2022-12-13T12:35:04.113520Z"},"trusted":true},"execution_count":300,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# RFclassifier = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0)\n# RFclassifier.fit(X_train, y_train)\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(RFclassifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(RFclassifier.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:05.826786Z","iopub.execute_input":"2022-12-13T12:35:05.827755Z","iopub.status.idle":"2022-12-13T12:35:05.833228Z","shell.execute_reply.started":"2022-12-13T12:35:05.827717Z","shell.execute_reply":"2022-12-13T12:35:05.832114Z"},"trusted":true},"execution_count":301,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n# NUM_CLASSIFIERS = 40\n# MAX_DEPTH = 4\n# GBCclassifier = GradientBoostingClassifier()\n# GBCclassifier.fit(X_train, y_train)\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(GBCclassifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(GBCclassifier.predict(X_test), y_test)))\n# cross_val_score(GBCclassifier, X, y).mean()\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(classifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(classifier.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:07.334992Z","iopub.execute_input":"2022-12-13T12:35:07.335358Z","iopub.status.idle":"2022-12-13T12:35:07.340391Z","shell.execute_reply.started":"2022-12-13T12:35:07.335327Z","shell.execute_reply":"2022-12-13T12:35:07.339279Z"},"trusted":true},"execution_count":302,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\n# XGBclassifier = XGBClassifier()\n# XGBclassifier.fit(X_train, y_train)\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(XGBclassifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(XGBclassifier.predict(X_test), y_test)))\n# cross_val_score(XGBclassifier, X, y).mean()","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:09.147576Z","iopub.execute_input":"2022-12-13T12:35:09.147956Z","iopub.status.idle":"2022-12-13T12:35:09.152988Z","shell.execute_reply.started":"2022-12-13T12:35:09.147923Z","shell.execute_reply":"2022-12-13T12:35:09.151702Z"},"trusted":true},"execution_count":303,"outputs":[]},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\n# LGBMclassifier = LGBMClassifier()\n# # cross_val_score(LGBMclassifier, X, y).mean()\n# LGBMclassifier.fit(X_train, y_train)\n# print(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(LGBMclassifier.predict(X_train), y_train)))\n# print(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(LGBMclassifier.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:10.173482Z","iopub.execute_input":"2022-12-13T12:35:10.173869Z","iopub.status.idle":"2022-12-13T12:35:10.184791Z","shell.execute_reply.started":"2022-12-13T12:35:10.173814Z","shell.execute_reply":"2022-12-13T12:35:10.183523Z"},"trusted":true},"execution_count":304,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DkSUrcIeKBcQ","outputId":"402f1714-73fe-4c5b-f620-ede3c13104e3","execution":{"iopub.status.busy":"2022-12-13T12:35:11.357005Z","iopub.execute_input":"2022-12-13T12:35:11.357372Z","iopub.status.idle":"2022-12-13T12:35:11.364411Z","shell.execute_reply.started":"2022-12-13T12:35:11.357342Z","shell.execute_reply":"2022-12-13T12:35:11.363425Z"},"trusted":true},"execution_count":305,"outputs":[{"execution_count":305,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\ntmp_vote = VotingClassifier([('clf1', RandomForestClassifier()),\n                        ('clf2', XGBClassifier()),\n                        ('clf3', LGBMClassifier())], voting=\"hard\")\ntmp_vote.fit(X_train_pca, y_train)\nprint(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(tmp_vote.predict(X_train_pca), y_train)))\nprint(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(tmp_vote.predict(X_test_pca), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T07:47:41.735481Z","iopub.execute_input":"2022-12-13T07:47:41.736003Z","iopub.status.idle":"2022-12-13T07:52:21.779851Z","shell.execute_reply.started":"2022-12-13T07:47:41.735959Z","shell.execute_reply":"2022-12-13T07:52:21.778812Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Vanilla Implementation : Accuracy score for training data : 0.9995099840744824\nVanilla Implementation : Accuracy score for testing data : 0.9228224917309813\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression","metadata":{"execution":{"iopub.status.busy":"2022-12-13T11:35:02.019588Z","iopub.execute_input":"2022-12-13T11:35:02.020095Z","iopub.status.idle":"2022-12-13T11:35:02.026337Z","shell.execute_reply.started":"2022-12-13T11:35:02.020051Z","shell.execute_reply":"2022-12-13T11:35:02.025083Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\ndcm_vote = VotingClassifier([('clf1', RandomForestClassifier()),\n                        ('clf2', XGBClassifier()),\n                        ('clf3', LGBMClassifier()),\n                        ('clf4', LogisticRegression())], voting=\"soft\")\ndcm_vote.fit(X_train_pca, y_train)\nprint(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(dcm_vote.predict(X_train_pca), y_train)))\nprint(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(dcm_vote.predict(X_test_pca), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:35:22.834408Z","iopub.execute_input":"2022-12-13T12:35:22.834916Z","iopub.status.idle":"2022-12-13T12:38:38.608145Z","shell.execute_reply.started":"2022-12-13T12:35:22.834869Z","shell.execute_reply":"2022-12-13T12:38:38.602978Z"},"trusted":true},"execution_count":306,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n","output_type":"stream"},{"name":"stdout","text":"Vanilla Implementation : Accuracy score for training data : 0.999659979598776\nVanilla Implementation : Accuracy score for testing data : 0.9234159779614325\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\ndcm_vote = VotingClassifier([('clf1', RandomForestClassifier()),\n                        ('clf2', XGBClassifier()),\n                        ('clf3', LGBMClassifier())], voting=\"soft\")\ndcm_vote.fit(X_train, y_train)\nprint(\"Vanilla Implementation : Accuracy score for training data : {}\".format(accuracy_score(dcm_vote.predict(X_train), y_train)))\nprint(\"Vanilla Implementation : Accuracy score for testing data : {}\".format(accuracy_score(dcm_vote.predict(X_test), y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-13T08:00:33.601681Z","iopub.execute_input":"2022-12-13T08:00:33.602213Z","iopub.status.idle":"2022-12-13T08:00:33.607552Z","shell.execute_reply.started":"2022-12-13T08:00:33.602173Z","shell.execute_reply":"2022-12-13T08:00:33.606615Z"},"trusted":true},"execution_count":148,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/data-sentiment/test.csv\")\nprint(test_data[\"RevId\"][0:10])","metadata":{"id":"7z9irfsuHmA7","execution":{"iopub.status.busy":"2022-12-13T12:39:09.055172Z","iopub.execute_input":"2022-12-13T12:39:09.055540Z","iopub.status.idle":"2022-12-13T12:39:09.178164Z","shell.execute_reply.started":"2022-12-13T12:39:09.055509Z","shell.execute_reply":"2022-12-13T12:39:09.177149Z"},"trusted":true},"execution_count":307,"outputs":[{"name":"stdout","text":"0     781115\n1    1219481\n2    1703765\n3    4870346\n4    2638711\n5    2288606\n6    2369977\n7    1395037\n8    1388406\n9    2704939\nName: RevId, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"test_corpus = []\nfor id, sent in zip(test_data[\"RevId\"], test_data[\"Comment\"]):\n  if(type(sent) != str):\n    sent = \"b√¨nh lu·∫≠n kh√¥ng x√°c ƒë·ªãnh\"\n  test_corpus.append((id, sent))\n\nprint(len(test_corpus))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iw6uqln66-Wu","outputId":"7522c329-8dda-423b-a5d1-b7ef00482915","execution":{"iopub.status.busy":"2022-12-13T12:39:11.293436Z","iopub.execute_input":"2022-12-13T12:39:11.293787Z","iopub.status.idle":"2022-12-13T12:39:11.310488Z","shell.execute_reply.started":"2022-12-13T12:39:11.293757Z","shell.execute_reply":"2022-12-13T12:39:11.309315Z"},"trusted":true},"execution_count":308,"outputs":[{"name":"stdout","text":"5103\n","output_type":"stream"}]},{"cell_type":"code","source":"revIDs = [id for id,_ in test_corpus]\nsents = [sent for _,sent in test_corpus]\nprint(revIDs[0:10])\n# print(sents[0])","metadata":{"id":"V261k-vT8ow1","execution":{"iopub.status.busy":"2022-12-13T12:39:12.684954Z","iopub.execute_input":"2022-12-13T12:39:12.685320Z","iopub.status.idle":"2022-12-13T12:39:12.694906Z","shell.execute_reply.started":"2022-12-13T12:39:12.685289Z","shell.execute_reply":"2022-12-13T12:39:12.693863Z"},"trusted":true},"execution_count":309,"outputs":[{"name":"stdout","text":"[781115, 1219481, 1703765, 4870346, 2638711, 2288606, 2369977, 1395037, 1388406, 2704939]\n","output_type":"stream"}]},{"cell_type":"code","source":"for sent in test_data[\"Comment\"]:\n  if(type(sent) != str):\n    print(sent)","metadata":{"id":"OucwxZQgFknG","execution":{"iopub.status.busy":"2022-12-13T12:39:14.428853Z","iopub.execute_input":"2022-12-13T12:39:14.429957Z","iopub.status.idle":"2022-12-13T12:39:14.439001Z","shell.execute_reply.started":"2022-12-13T12:39:14.429919Z","shell.execute_reply":"2022-12-13T12:39:14.437625Z"},"trusted":true},"execution_count":310,"outputs":[{"name":"stdout","text":"nan\nnan\nnan\n","output_type":"stream"}]},{"cell_type":"code","source":"checked_sents = []\ncount = 0\nfor i, sent in enumerate(sents):\n  # print(i)\n  if(not check_spell(sent)):\n    print(i, sent)\n    count += 1\n\nprint(count)\n# for sent in checked_sents:\n#   print(sent)","metadata":{"id":"N8NA0k5kFP3m","execution":{"iopub.status.busy":"2022-12-13T12:39:16.498973Z","iopub.execute_input":"2022-12-13T12:39:16.499403Z","iopub.status.idle":"2022-12-13T12:39:16.511761Z","shell.execute_reply.started":"2022-12-13T12:39:16.499299Z","shell.execute_reply":"2022-12-13T12:39:16.510558Z"},"trusted":true},"execution_count":311,"outputs":[{"name":"stdout","text":"39 Quite beautiful place to stay and near everything we need as a customer/tourist. Next to BIDV TOWER and VIETCOMBANK HQ, near the lake, ancient town....\nBreakfast is not as I expected, not that quality for hotel :( quite a shame.\n94 Ngon\n165 I wish I had this roof in my house.\n171 Chilled bar with cheap price in the middle of the famous beer street. If they don't have any special event, you'll need to pay only 100.000 for the entrance ticket (included one drink). \nIts space is quite small but usually crowded. I wonder why there are so many Korean guys around whenever I go here. It seems this bar is the favorite place of Korean people who visit Hanoi. Haha.\n215 „Ç≥„É°È∫∫„Çí‰Ωø„Å£„ÅüÁÑº„Åç„Åù„Å∞„ÄÇ\nÈùûÂ∏∏„Å´ÂÆâ„ÅÑ„ÄÇ\n470 Like\n476 Siu ngonnnn\n478 I love the bubble tea here.  It's classy and tasty with several well-balanced flavor selections.  I usually get mint but sometimes I will get taro or chocolate.  I was chided the other day by a comment on a review I made at another tea place.  I had complained about being served iced milk tea in a plastic cup and was told that no one serves tea in a glass.  Well, this place does and the tea is for tea lovers.  So here has been my regular stop.\n599 Cafe ngon\n694 üëå\n1054 Oke\n1329 Ngon\n1366 I‚Äôd be very worried about a coffee shop that stuggles to make something as basic as a black coffee. Certainly tastes like they are using instant coffee rather than freshly ground. Pity. Ground floor stinks of cigarettes would advise using upstairs\n1415 Â∫ä„Å´Â∫ß„Å£„Å¶„ÅäÊñôÁêÜ„ÇíÂõ≤„ÇÄ„ÄÅÂ±ÖÈÖíÂ±ãÈ¢®„Éô„Éà„Éä„É†ÂÆ∂Â∫≠ÊñôÁêÜ„É¨„Çπ„Éà„É©„É≥„ÄÇ\nËâ≤„ÄÖ„Ç™„Éº„ÉÄ„Éº„Åó„Åü„Åã„Å£„Åü„ÅÆ„Åß„Åô„Åå„ÄÅÊñôÁêÜ‰∏≠„Å´„Åæ„Å†È£ü„Åπ„Å¶„ÅÑ„Å™„ÅÑ„Éô„Éà„Éä„É†ÊñôÁêÜ„Çí‰∏≠ÂøÉ„Å´„ÉÅ„Éß„Ç§„Çπ„Åó„Åæ„Åó„Åü„ÄÇ\nÊµ∑ËÄÅ„ÅÆÂîêÊèö„Åí„Å®„Ç∑„Ç∏„Éü„ÅÆ„Åä„Å§„Åæ„Åø„ÅØ„Åä„Åã„Çè„Çä„Åó„Åü„ÅÑ„Åè„Çâ„ÅÑÁæéÂë≥„Åó„ÅÑ„Åß„ÅôÔºÅ\n‰ΩïÊïÖ„ÅãÔºü„ÅîÈ£ØÁâ©„Çí„Åü„Åè„Åï„ÇìÈ†º„Çì„Åß„Åó„Åæ„Å£„Åü„Åë„Å©„ÄÅÊèö„Åí„Åü„Åä„Åì„Çè„Å´„ÉÑ„É´„É†„É©„Çµ„Ç≠„ÅÆ„Çπ„Éº„Éó„Çí„Åã„Åë„Å¶È£ü„Åπ„Åü„ÇâÁµ∂ÂìÅ„Åß„Åó„ÅüÔºÅ\n„Ç∑„É≥„Éó„É´„Å™ÂéöÊèö„Åí„Å´‰ªò„Åë„Çã„Éû„É†„Éà„É†„Åå„Å®„Å¶„ÇÇÁæéÂë≥„Åó„ÅÑÔºÅ\n„Éì„Éº„ÉÑ„Çí„Åì„ÅÆÊßò„Å™„Çπ„Çø„Ç§„É´„ÅßÈ£ü„Åπ„Çã„ÅÆ„ÅØÂàù„ÇÅ„Å¶„Åß„Åó„Åü„ÄÅÊ∑ª„Åà„Å¶„ÅÇ„Çã„Ç™„É™„Ç∏„Éä„É´„ÇΩ„Éº„Çπ„Çí„ÅîÈ£Ø„Å´„ÇÇ„Åã„Åë„Å¶È£ü„Åπ„Åü„Çâ„ÅîÈ£Ø„ÅåÈÄ≤„ÇÄÂêõ„Åß„Åó„ÅüÔºÅ\nÂú∞ÈÖí„ÅÆ„É™„É≥„Ç¥„ÅÆ„ÅäÈÖí„ÇÇ„Å®„Å¶„ÇÇÁæéÂë≥„Åó„Åã„Å£„Åü„Åß„Åô„ÄÇ\n1471 Waoooo\n1594 Best üëçüèª\n1627 Butter Chicken was not garnished with butter, but with margarine! Rice is no Basmati quality. Chicken is very dry.\n1738 \"Ga nuong xa\" bread here is the best ever I had.I can't put it here for u guys.It's really great.But Green Thai tea is normal,not really good,it's a bit bland and cold.Thank u\n1860 pizza is so delicious\ncarbonara is a little solty..\n2184 üëå\n2192 Very delicious and hot food. Would definetely recommend!\n2294 Have a good time  ‚ù§Ô∏è wishing you lost of luck next tiem\n2400 Excellent American food. The price is acceptable for the quality of food. I was happy to discover they have a brunch menu!\n\nThe only downside is that it can get hot as it's an open space, and there are only a few fans - or perhaps it's because I'm not used to the high humidity. Great for families.\n2437 Âàù„ÇÅ„Å¶„Éè„Éé„Ç§ÊóÖË°å„Çí„Åô„Çã„ÅäÂèãÈÅî„Å´„Å©„ÅÜ„Åó„Å¶„ÇÇ„ÉÅ„É£„Éº„Ç´„Éº„ÅØÈ£ü„Åπ„Å¶„ÇÇ„Çâ„ÅÑ„Åü„ÅÑ„ÄÇ„Åë„Å©„ÄÅÁßÅ„ÇÇÈÅï„ÅÜ„ÅäÂ∫ó„Å´„ÉÅ„É£„É¨„É≥„Ç∏„Åó„Åü„ÅÑ„Å®„ÄÅ„Éè„Éé„Ç§ÂêçÁâ©„ÅÆ„ÉÅ„É£„Éº„Ç´„Éº„ÇíÈ£ü„Åπ„Å´„Éï„Éº„Éá„Ç£„Éº„Åß„ÇÇÈ´òË©ï‰æ°„Å™Êñ∞„Åó„ÅèÂá∫Êù•„Åü„Ç≥„ÉÅ„É©„Å∏„ÄÇ\nÁ∂∫È∫ó„Å¶„Ç™„Ç∑„É£„É¨„Å™ÂÜÖË£Ö„ÄÅ„Ç™„É™„Ç∏„Éä„É´„ÅÆ„Éê„ÉÉ„ÉÅ„É£„É≥ÁÑº„ÄÅÁúüÈçÆ„ÅÆÈçã„Å´„ÉÜ„É≥„Ç∑„Éß„É≥‰∏ä„Åå„Çä„Åæ„Åô„ÄÇ \n„Åü„Å†„ÄÅË¶≥ÂÖâÂÆ¢Áõ∏Êâã„ÅÆ„ÅäÂ∫ó„Åß„ÅØ„Å™„ÅÑÔºü„ÅÆ„Åß„ÉÅ„É£„Éº„Ç´„Éº„ÅÆ‰ΩúÊ≥ï„ÅÆ„Ç¢„Éâ„Éê„Ç§„Çπ„ÇÑÈçãÂ•âË°å„ÇíÈÄê‰∏Ä„Åó„Å¶„ÇÇ„Çâ„Åà„Å™„ÅÑ„ÅÆ„ÅßÂàù„ÇÅ„Å¶„ÉÅ„É£„Éº„Ç´„Éº„Å´„ÉÅ„É£„É¨„É≥„Ç∏„Åô„ÇãÂ†¥Âêà„ÅØÂ∞ë„ÅóÊà∏ÊÉë„Å£„Å¶„Åó„Åæ„ÅÜ„Åã„ÇÇ„ÄÇ„Éû„É†„Éà„É†„ÅØÂá∫„Åï„Çå„Å™„Åã„Å£„Åü„ÅÆ„Åß„ÄÅ„Éû„É†„Éà„É†„Åè„Å†„Åï„ÅÑÔºÅ„Å®„Ç™„Éº„ÉÄ„Éº„Åó„Å¶ÊåÅ„Å£„Å¶„Åç„Å¶„ÇÇ„Çâ„ÅÑ„Åæ„Åó„Åü„ÄÇ„Ç≥„ÉÅ„É©„ÅÆ„Éû„É†„Éà„É†„ÅØ„Å®„Å¶„ÇÇÂÑ™„Åó„ÅÑÂë≥„ÅßËá≠„Åø„ÅØÂ∞ë„Å™„ÅèÁæéÂë≥„Åó„Åã„Å£„Åü„Åß„Åô„ÄÇ\n„ÉÅ„É£„Éº„Ç´„Éº„ÇÇ„Ç®„Éì„ÅÆ„É¨„É¢„É≥„Ç∞„É©„ÇπÁÑº„Åç„ÇÇÂÖ®‰ΩìÁöÑ„Å´ÂÑ™„Åó„ÅÑÂë≥„Å§„Åë„Åß„Åó„Åü(^O^)\n„Çµ„ÉÉ„Ç´„Éº„ÅÆ„ÉØ„Éº„É´„Éâ„Ç´„ÉÉ„Éó‰∫àÈÅ∏„ÅÆÈñãÂπï„Åß„Éô„Éà„Éä„É†vs„Çø„Ç§„ÅÆË©¶ÂêàÊôÇÈñì„ÅÆ„Çø„Ç§„Éü„É≥„Ç∞„Å´Êù•Â∫ó„Åó„Å¶„Åó„Åæ„Å£„Åü„ÅÆ„Åß„ÄÅ„Çπ„Çø„ÉÉ„Éï„ÅÆÁöÜ„Åï„Åæ„ÇΩ„ÉØ„ÇΩ„ÉØ„Åó„Å¶„ÅÑ„Åæ„Åó„ÅüÁ¨ëÁ¨ë\n2443 Good !\n2475 Ngon\n2586 Nice atmosphere. The DJ was spinning house music on a wednesday night; it was food music for having conversations. Cocktails are pretty good as its hard ro find a plave that can really do cocktails in Vietnam. I would refommend their signature cocktails over the traditional options. There also appears to be a wode selection of wine. Had an appetizer of crab fried soring rolls which was tasty as well.\n2806 Ngonnnnnnnnnmmmmmmnmmmmmmmmmmmmmnnn\n2821 Ngon..\n2822 A unique themed restaurant with the concept of three kingdoms , eating there was a good experience. A beautiful looking dragon head hot pot and lavish wooden design. Dim sum and kim sa are just super amazing , highly recommended to go and try out.  A unique concept of self picking the meat embedded in sticks and a vast range of mushrooms, hand made noodle and sea food to choose from. Give it a try guys . cheers\n2854 Service and food was good. Menu had partial translation, waiter knew basic english which was good, he suggested a couple of dishes instead we opted out for the 'lau bo' being a hot pot fan. The soup broth was really clean, reminded me of the sweet sour soup with hints of tangyness and sweetness of pineapple and tomato.\nThe drinks menu wasnt listed with the main menu. Theres two floors to the restaurant with half of the top floor exposed and overlooks the street. There was also portable airconditioning and fan unit to try keep cool. There was a degree of cleanliness aswell.\n2935 The packaging For drinks needs to be improved. A coffee on the go cup is not ideal. and please do not add plastic straws, especially if the customer requests. I have ordered here several times, each time i add a note to not include plastic straws, each time they deliver with plastic straws.\n3057 Yu Tang number one!!!\n3163 Like\n3166 Lovely ambiance we got at Home Moc today. Food was perfect and staff are very nice and helpfull. Surely, i will recommend it to my friends and i myself will come back regularly.\n3314 ngon\n3322 Nice place to have a light drinks with friends! You can find a good corner to chit chat and stay away from people eyes! Foods here also very nice! You must try green lobster pasta! Don't order too much! You can ask them to make one portion and share if you have only two person! Easy to park your car, that is one reason I love this place since Hanoi is always hard to find a car park!\n3483 Î™®Îì† ÏãùÏûêÏû¨Î•º ÌïúÍµ≠ÏóêÏÑú ÏàòÏûÖÌïòÍ≥† ÏûàÏäµÎãàÎã§.\n\nÍ∞ÄÎÅî Ïôú Î≤†Ìä∏ÎÇ® Î∂ÑÏùÑ ÏÇ¨Ïö©ÌïòÏãúÎÉê Ïª¥ÌîåÎ†àÏù∏ ÌïòÏãúÎäî Í≥†Í∞ùÎ∂ÑÏù¥ Í≥ÑÏãúÎäîÎç∞\n\nÎπÑÎπîÎ©¥Ïóê ÏÇ¨Ïö©ÎêòÎäî ÏòõÎÇ†Íµ≠Ïàò ÏÜåÎ©¥ÏûÖÎãàÎã§.\n\ncho mi bo tron cay\n3680 ü§çüòäü§çüòä‚ù§Ô∏è‚Äçüî•‚ù§Ô∏è‚Äçüî•\n3745 My friend and I ventured out for brekkie/brunch and were certainly not disappointed! Beautiful veggie bun rien and probably the best summer rolls I've had in the last five months in Vietnam. Very nice iced tea too! We had the kumquat one, delish. Check it out!\n4221 Okk\n4428 Ngon ‚ù§Ô∏è\n4583 Hide deep in back of alley, but customers are keep coming in. I tried Banh Duc, I really like their soup. Also, tried Banh Da, tasty too. I definitely come here again.\n4634 good\n4658 Mint Cafe based in Hanoi close to the Cathedral St Joseph. It is very cosy but what I like the most is all the good cocktails made by professionnal bartender. \n\nI recommend it for sure!\n4766 I‚Äôll miss this one! I hope they‚Äôll have this in the Philippines! When I go back to***I‚Äôll sure to go back for you!\n5016 A1\n5091 Good experience here in Ha Noi. I love fresh mango juice no sugar. I'll be back next time. Thank you\n48\n","output_type":"stream"}]},{"cell_type":"code","source":"purified_sents = [purify(str(sent)) for sent in sents]","metadata":{"id":"vPbtMsn09jky","execution":{"iopub.status.busy":"2022-12-13T12:39:22.348421Z","iopub.execute_input":"2022-12-13T12:39:22.348781Z","iopub.status.idle":"2022-12-13T12:39:28.057030Z","shell.execute_reply.started":"2022-12-13T12:39:22.348749Z","shell.execute_reply":"2022-12-13T12:39:28.056036Z"},"trusted":true},"execution_count":312,"outputs":[]},{"cell_type":"code","source":"print(purified_sents[2806])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olia58pSBpMn","outputId":"690cf3a8-15cf-4a03-c949-a3b7c05f726a","execution":{"iopub.status.busy":"2022-12-13T12:39:28.059136Z","iopub.execute_input":"2022-12-13T12:39:28.060004Z","iopub.status.idle":"2022-12-13T12:39:28.065674Z","shell.execute_reply.started":"2022-12-13T12:39:28.059966Z","shell.execute_reply":"2022-12-13T12:39:28.064377Z"},"trusted":true},"execution_count":313,"outputs":[{"name":"stdout","text":"ngonmnmn\n","output_type":"stream"}]},{"cell_type":"code","source":"# for i, sent in enumerate(purified_sents):\n#   if(sent == \"\"):\n#     purified_sents[i] = \"b√¨nh lu·∫≠n kh√¥ng x√°c ƒë·ªãnh\"\n#     print(i)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-xuUfQ8Kh4r","outputId":"1c2524e0-e577-4ef8-8a26-c719717f3f01","execution":{"iopub.status.busy":"2022-12-13T11:39:55.296909Z","iopub.execute_input":"2022-12-13T11:39:55.297506Z","iopub.status.idle":"2022-12-13T11:39:55.310493Z","shell.execute_reply.started":"2022-12-13T11:39:55.297461Z","shell.execute_reply":"2022-12-13T11:39:55.309336Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"preprocessed_sents = preprocess(purified_sents)","metadata":{"id":"___FrYla-3tM","execution":{"iopub.status.busy":"2022-12-13T12:39:28.067414Z","iopub.execute_input":"2022-12-13T12:39:28.067794Z","iopub.status.idle":"2022-12-13T12:39:51.493662Z","shell.execute_reply.started":"2022-12-13T12:39:28.067759Z","shell.execute_reply":"2022-12-13T12:39:51.492685Z"},"trusted":true},"execution_count":314,"outputs":[]},{"cell_type":"code","source":"# encoded_sents = encode(preprocessed_sents, max_len=150, max_seq=256)","metadata":{"id":"mEBqRrR2_ADk","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padded_sents, attention_masks = encode_plus(preprocessed_sents, max_len=256)","metadata":{"id":"wvSG-D4tLEWh","execution":{"iopub.status.busy":"2022-12-13T12:39:51.496232Z","iopub.execute_input":"2022-12-13T12:39:51.496604Z","iopub.status.idle":"2022-12-13T12:39:54.225631Z","shell.execute_reply.started":"2022-12-13T12:39:51.496568Z","shell.execute_reply":"2022-12-13T12:39:54.224662Z"},"trusted":true},"execution_count":315,"outputs":[]},{"cell_type":"code","source":"# padded_sents = padding(encoded_sents, max_len)","metadata":{"id":"fxHzzrC-_c5a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# attention_masks = attention_mask(padded_sents)","metadata":{"id":"wkNPCwcI_-qX","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-12-13T07:54:36.316194Z","iopub.execute_input":"2022-12-13T07:54:36.316663Z","iopub.status.idle":"2022-12-13T07:54:36.357966Z","shell.execute_reply.started":"2022-12-13T07:54:36.316623Z","shell.execute_reply":"2022-12-13T07:54:36.355666Z"},"trusted":true},"execution_count":110,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/1490779902.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"],"ename":"TypeError","evalue":"'str' object is not callable","output_type":"error"}]},{"cell_type":"code","source":"batch_size = 32\n\ninputs = torch.tensor(padded_sents)\nids = torch.tensor(revIDs)\nmasks = torch.tensor(attention_masks)\n\ntest_data = TensorDataset(ids, masks, inputs)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)","metadata":{"id":"qoBxTJmS_rYZ","execution":{"iopub.status.busy":"2022-12-13T12:39:54.227352Z","iopub.execute_input":"2022-12-13T12:39:54.228379Z","iopub.status.idle":"2022-12-13T12:39:54.414088Z","shell.execute_reply.started":"2022-12-13T12:39:54.228324Z","shell.execute_reply":"2022-12-13T12:39:54.412869Z"},"trusted":true},"execution_count":316,"outputs":[]},{"cell_type":"code","source":"inputs.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:40:29.715420Z","iopub.execute_input":"2022-12-13T12:40:29.715940Z","iopub.status.idle":"2022-12-13T12:40:29.732131Z","shell.execute_reply.started":"2022-12-13T12:40:29.715892Z","shell.execute_reply":"2022-12-13T12:40:29.730694Z"},"trusted":true},"execution_count":317,"outputs":[{"execution_count":317,"output_type":"execute_result","data":{"text/plain":"torch.Size([5103, 256])"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"id":"1KNXAMuzywBM","execution":{"iopub.status.busy":"2022-12-13T12:40:31.279242Z","iopub.execute_input":"2022-12-13T12:40:31.279603Z","iopub.status.idle":"2022-12-13T12:40:31.285227Z","shell.execute_reply.started":"2022-12-13T12:40:31.279573Z","shell.execute_reply":"2022-12-13T12:40:31.283884Z"},"trusted":true},"execution_count":318,"outputs":[]},{"cell_type":"code","source":"test_model.to(device)","metadata":{"id":"bkH003m-bVH7","execution":{"iopub.status.busy":"2022-12-13T12:40:33.003241Z","iopub.execute_input":"2022-12-13T12:40:33.003596Z","iopub.status.idle":"2022-12-13T12:40:33.021751Z","shell.execute_reply.started":"2022-12-13T12:40:33.003566Z","shell.execute_reply":"2022-12-13T12:40:33.020873Z"},"trusted":true},"execution_count":319,"outputs":[{"execution_count":319,"output_type":"execute_result","data":{"text/plain":"BERT_for_sentiment_large(\n  (bert): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (fc1): Linear(in_features=768, out_features=768, bias=True)\n  (layernorm_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  (fc2): Linear(in_features=3072, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"X = []\nIDs = []\nfor batch in tqdm(test_dataloader):\n    # batch = torch.toTensor(t.to(device) for t in batch)\n    ids, input_mask, input_ids = batch\n\n    input_ids = input_ids.to(device)\n    input_mask = input_mask.to(device)\n    ids = ids.to(device=device)\n\n          # Forwards pass\n    with torch.no_grad():\n      logits = trained_phobert(input_ids, attention_mask=input_mask)\n#       logits = logits.pooler_output\n      logits = torch.cat((logits[2][-1][:,0, ...],logits[2][-2][:,0, ...], logits[2][-3][:,0, ...], logits[2][-4][:,0, ...]),-1)\n#       logits = torch.cat((logits[2][-1][:,0, ...],logits[2][-2][:,0, ...], logits[2][-3][:,0, ...], logits[2][-4][:,0, ...]),-1)\n        # Calculate how wrong the model is\n        # loss = logits[0]\n        # print(loss)\n      ids = ids.detach().cpu().numpy()\n      logits = logits.detach().cpu().numpy()\n      for id_ in ids:\n        IDs.append(id_)\n      for logit in logits:\n        X.append(logit)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:40:46.150168Z","iopub.execute_input":"2022-12-13T12:40:46.150525Z","iopub.status.idle":"2022-12-13T12:41:24.222156Z","shell.execute_reply.started":"2022-12-13T12:40:46.150494Z","shell.execute_reply":"2022-12-13T12:41:24.221172Z"},"trusted":true},"execution_count":320,"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [00:38<00:00,  4.20it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"X_pca = pca.transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:41:30.805247Z","iopub.execute_input":"2022-12-13T12:41:30.805607Z","iopub.status.idle":"2022-12-13T12:41:31.354864Z","shell.execute_reply.started":"2022-12-13T12:41:30.805576Z","shell.execute_reply":"2022-12-13T12:41:31.353434Z"},"trusted":true},"execution_count":321,"outputs":[]},{"cell_type":"code","source":"preds = dcm_vote.predict(X_pca)\n\nsub = []\nfor tmp in zip(IDs, preds):\n    sub.append(tmp)","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:41:32.623729Z","iopub.execute_input":"2022-12-13T12:41:32.624438Z","iopub.status.idle":"2022-12-13T12:41:32.913597Z","shell.execute_reply.started":"2022-12-13T12:41:32.624401Z","shell.execute_reply":"2022-12-13T12:41:32.912316Z"},"trusted":true},"execution_count":322,"outputs":[]},{"cell_type":"code","source":"sub = []\ntest_model.eval()\ntotal_loss = total = 0\nfor batch in tqdm(test_dataloader):\n# batch = torch.toTensor(t.to(device) for t in batch)\n  ids, input_mask, input_ids = batch\n\n  input_ids = input_ids.to(device)\n  input_mask = input_mask.to(device)\n  ids = ids.to(device=device)\n          # Forwards pass\n  with torch.no_grad():\n    outputs = test_model(input_ids, attention_mask=input_mask)\n    # loss = outputs[0]\n#     outputs = outputs.logits\n    loss = outputs.detach().cpu().numpy()\n    ids = ids.to('cpu').numpy()\n\n    preds_flat = np.argmax(loss, axis=1).flatten()\n    for tup in zip(ids, preds_flat):\n      sub.append(tup)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzpshVqf_9Uu","outputId":"aedcecb2-cf43-4725-89a5-59461c104a76","execution":{"iopub.status.busy":"2022-12-13T01:12:00.875558Z","iopub.execute_input":"2022-12-13T01:12:00.876236Z","iopub.status.idle":"2022-12-13T01:12:39.469643Z","shell.execute_reply.started":"2022-12-13T01:12:00.876189Z","shell.execute_reply":"2022-12-13T01:12:39.468567Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 160/160 [00:38<00:00,  4.15it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sub[0:10])","metadata":{"execution":{"iopub.status.busy":"2022-12-13T12:41:46.788331Z","iopub.execute_input":"2022-12-13T12:41:46.788740Z","iopub.status.idle":"2022-12-13T12:41:46.795046Z","shell.execute_reply.started":"2022-12-13T12:41:46.788701Z","shell.execute_reply":"2022-12-13T12:41:46.793772Z"},"trusted":true},"execution_count":323,"outputs":[{"name":"stdout","text":"[(781115, 0), (1219481, 0), (1703765, 1), (4870346, 0), (2638711, 1), (2288606, 1), (2369977, 1), (1395037, 1), (1388406, 1), (2704939, 0)]\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = [pr for _, pr in sub]","metadata":{"id":"Oz2EdjU3HRkW","execution":{"iopub.status.busy":"2022-12-13T12:41:48.324983Z","iopub.execute_input":"2022-12-13T12:41:48.325363Z","iopub.status.idle":"2022-12-13T12:41:48.331482Z","shell.execute_reply.started":"2022-12-13T12:41:48.325333Z","shell.execute_reply":"2022-12-13T12:41:48.330345Z"},"trusted":true},"execution_count":324,"outputs":[]},{"cell_type":"code","source":"ids = [id for id,_ in sub]","metadata":{"id":"ygEvKZSDJY7N","execution":{"iopub.status.busy":"2022-12-13T12:41:49.965078Z","iopub.execute_input":"2022-12-13T12:41:49.965559Z","iopub.status.idle":"2022-12-13T12:41:49.975687Z","shell.execute_reply.started":"2022-12-13T12:41:49.965510Z","shell.execute_reply":"2022-12-13T12:41:49.974661Z"},"trusted":true},"execution_count":325,"outputs":[]},{"cell_type":"code","source":"print(len(pred))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_vt-hK4SHwFt","outputId":"705de3f4-1853-49b9-ea76-c207ff4d5479","execution":{"iopub.status.busy":"2022-12-13T12:41:52.349236Z","iopub.execute_input":"2022-12-13T12:41:52.349596Z","iopub.status.idle":"2022-12-13T12:41:52.355074Z","shell.execute_reply.started":"2022-12-13T12:41:52.349566Z","shell.execute_reply":"2022-12-13T12:41:52.354036Z"},"trusted":true},"execution_count":326,"outputs":[{"name":"stdout","text":"5103\n","output_type":"stream"}]},{"cell_type":"code","source":"tmp_ids = np.array(pred)","metadata":{"id":"PUo8zph8MXQf","execution":{"iopub.status.busy":"2022-12-13T12:41:54.073241Z","iopub.execute_input":"2022-12-13T12:41:54.074020Z","iopub.status.idle":"2022-12-13T12:41:54.080151Z","shell.execute_reply.started":"2022-12-13T12:41:54.073979Z","shell.execute_reply":"2022-12-13T12:41:54.079077Z"},"trusted":true},"execution_count":327,"outputs":[]},{"cell_type":"code","source":"print(tmp_ids)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjxE5_H1Mt6j","outputId":"5a96e235-10f0-4f26-bc7e-d82b614d4802","execution":{"iopub.status.busy":"2022-12-13T12:41:55.822929Z","iopub.execute_input":"2022-12-13T12:41:55.823300Z","iopub.status.idle":"2022-12-13T12:41:55.829037Z","shell.execute_reply.started":"2022-12-13T12:41:55.823269Z","shell.execute_reply":"2022-12-13T12:41:55.827969Z"},"trusted":true},"execution_count":328,"outputs":[{"name":"stdout","text":"[0 0 1 ... 0 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sub[0:10])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3DjVlK5Em9x","outputId":"b8953c4f-cfe4-47f3-8989-9dde34e2b8b9","execution":{"iopub.status.busy":"2022-12-13T12:41:57.798948Z","iopub.execute_input":"2022-12-13T12:41:57.801124Z","iopub.status.idle":"2022-12-13T12:41:57.807613Z","shell.execute_reply.started":"2022-12-13T12:41:57.801074Z","shell.execute_reply":"2022-12-13T12:41:57.806387Z"},"trusted":true},"execution_count":329,"outputs":[{"name":"stdout","text":"[(781115, 0), (1219481, 0), (1703765, 1), (4870346, 0), (2638711, 1), (2288606, 1), (2369977, 1), (1395037, 1), (1388406, 1), (2704939, 0)]\n","output_type":"stream"}]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'RevId': np.array(ids).reshape(5103), 'Rating': np.array(pred).reshape(5103)})","metadata":{"id":"vhJ_99xU4zpd","execution":{"iopub.status.busy":"2022-12-13T12:42:03.268621Z","iopub.execute_input":"2022-12-13T12:42:03.269007Z","iopub.status.idle":"2022-12-13T12:42:03.275776Z","shell.execute_reply.started":"2022-12-13T12:42:03.268974Z","shell.execute_reply":"2022-12-13T12:42:03.274666Z"},"trusted":true},"execution_count":330,"outputs":[]},{"cell_type":"code","source":"my_submission.to_csv(\"/kaggle/working/submission_13_12_5.csv\", index=False)","metadata":{"id":"ZStZburmJ_47","execution":{"iopub.status.busy":"2022-12-13T12:42:06.795227Z","iopub.execute_input":"2022-12-13T12:42:06.795586Z","iopub.status.idle":"2022-12-13T12:42:06.809559Z","shell.execute_reply.started":"2022-12-13T12:42:06.795556Z","shell.execute_reply":"2022-12-13T12:42:06.808493Z"},"trusted":true},"execution_count":331,"outputs":[]}]}